<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<!-- new favicon config and versions by realfavicongenerator.net -->
<link rel="apple-touch-icon" sizes="180x180" href="https://static.arxiv.org/static/base/0.17.4.post2/images/icons/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://static.arxiv.org/static/base/0.17.4.post2/images/icons/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="https://static.arxiv.org/static/base/0.17.4.post2/images/icons/favicon-16x16.png">
<link rel="manifest" href="https://static.arxiv.org/static/base/0.17.4.post2/images/icons/site.webmanifest">
<link rel="mask-icon" href="https://static.arxiv.org/static/base/0.17.4.post2/images/icons/safari-pinned-tab.svg" color="#b31b1b">
<link rel="shortcut icon" href="https://static.arxiv.org/static/base/0.17.4.post2/images/icons/favicon.ico">
<meta name="msapplication-TileColor" content="#b31b1b">
<meta name="msapplication-config" content="images/icons/browserconfig.xml">
<meta name="theme-color" content="#b31b1b">
<!-- end favicon config -->
<title>Search | arXiv e-print repository</title>
<script defer src="https://static.arxiv.org/static/base/0.17.4.post2/fontawesome-free-5.11.2-web/js/all.js"></script>
<link rel="stylesheet" href="https://static.arxiv.org/static/base/0.17.4.post2/css/arxivstyle.css" />
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    messageStyle: "none",
    extensions: ["tex2jax.js"],
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
      processEscapes: true,
      ignoreClass: '.*',
      processClass: 'mathjax.*'
    },
    TeX: {
        extensions: ["AMSmath.js", "AMSsymbols.js", "noErrors.js"],
        noErrors: {
          inlineDelimiters: ["$","$"],
          multiLine: false,
          style: {
            "font-size": "normal",
            "border": ""
          }
        }
    },
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>
<script src='//static.arxiv.org/MathJax-2.7.3/MathJax.js'></script>
<script src="https://static.arxiv.org/static/base/0.17.4.post2/js/notification.js"></script>

    
  <link rel="stylesheet" href="https://static.arxiv.org/static/search/0.5.6/css/bulma-tooltip.min.css" />
  <link rel="stylesheet" href="https://static.arxiv.org/static/search/0.5.6/css/search.css" />
  <script
    src="https://code.jquery.com/jquery-3.2.1.slim.min.js"
    integrity="sha256-k2WSCIexGzOj3Euiig+TlR8gA0EmPjuc79OEeY5L45g="
    crossorigin="anonymous"></script>

  <script src="https://static.arxiv.org/static/search/0.5.6/js/fieldset.js"></script>
  <style>
  radio#cf-customfield_11400 {
    display: none;
  }
  </style>
  <script type="text/javascript" src="https://arxiv-org.atlassian.net/s/d41d8cd98f00b204e9800998ecf8427e-T/-tqqyqk/b/20/a44af77267a987a660377e5c46e0fb64/_/download/batch/com.atlassian.jira.collector.plugin.jira-issue-collector-plugin:issuecollector/com.atlassian.jira.collector.plugin.jira-issue-collector-plugin:issuecollector.js?locale=en-US&collectorId=3b3dcb4c"></script>

    <script type="text/javascript">
    window.ATL_JQ_PAGE_PROPS =  {
    	"triggerFunction": function(showCollectorDialog) {
    		//Requires that jQuery is available!
    		$("#feedback-button").click(function(e) {
    			e.preventDefault();
    			showCollectorDialog();
    		});
    	},
      fieldValues: {
        "components": ["16000"],  // Search component.
        "versions": ["14260"],  // Release search-0.5.6
        "customfield_11401": window.location.href
      }
    };
    </script>

  </head>
  <body>
  
  
  <header><a href="#main-container" class="is-sr-only">Skip to main content</a>
    
    <!-- contains Cornell logo and sponsor statement -->
<div class="attribution level is-marginless" role="banner">
  <div class="level-left">
    <a class="level-item" href="https://cornell.edu/"><img src="https://static.arxiv.org/static/base/0.17.4.post2/images/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" aria-label="logo" /></a>
  </div>
  <div class="level-right is-marginless"><p class="sponsors level-item is-marginless"><a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a></p></div>
</div>
<!-- contains arXiv identity and search bar -->
<div class="identity level is-marginless">
  <div class="level-left">
    <div class="level-item">
      <a class="arxiv" href="https://arxiv.org/" aria-label="arxiv-logo">
        <img src="https://static.arxiv.org/static/base/0.17.4.post2/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;"/>
      </a>
    </div>
  </div>
  
  <div class="search-block level-right">
    <form class="level-item mini-search" method="GET" action="https://arxiv.org/search">
      <div class="field has-addons">
        <div class="control">
          <input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" />
          <p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
        </div>
        <div class="control">
          <div class="select is-small">
            <select name="searchtype" aria-label="Field to search">
              <option value="all" selected="selected">All fields</option>
              <option value="title">Title</option>
              <option value="author">Author</option>
              <option value="abstract">Abstract</option>
              <option value="comments">Comments</option>
              <option value="journal_ref">Journal reference</option>
              <option value="acm_class">ACM classification</option>
              <option value="msc_class">MSC classification</option>
              <option value="report_num">Report number</option>
              <option value="paper_id">arXiv identifier</option>
              <option value="doi">DOI</option>
              <option value="orcid">ORCID</option>
              <option value="author_id">arXiv author ID</option>
              <option value="help">Help pages</option>
              <option value="full_text">Full text</option>
            </select>
          </div>
        </div>
        <input type="hidden" name="source" value="header">
        <button class="button is-small is-cul-darker">Search</button>
      </div>
    </form>
  </div>
</div> <!-- closes identity -->

<div class="container">
    <div class="user-tools is-size-7 has-text-right has-text-weight-bold" role="navigation" aria-label="User menu">
      <a href="https://arxiv.org/login">Login</a>
    </div>
</div>
    
  </header>
  <main class="container" id="main-container">
    


    
  <div class="level is-marginless">
    <div class="level-left">
      <h1 class="title is-clearfix">
    
        Showing 1&ndash;41 of 41 results for author: <span class="mathjax">Gulcehre, C</span>
    
</h1>
    </div>
    <div class="level-right is-hidden-mobile">
      <!-- feedback for mobile is moved to footer -->
      <span class="help" style="display: inline-block;"><a href="https://github.com/arXiv/arxiv-search/releases">Search v0.5.6 released 2020-02-24</a>&nbsp;&nbsp;</span>
      <button class="button is-small" id="feedback-button">Feedback?</button>
    </div>
  </div>
    <div class="content">
      
  <form method="GET" action="/search/cs"  aria-role="search">
    
      Searching in archive <strong>cs</strong>. <a href="/search/?searchtype=author&amp;query=Gulcehre%2C+C">Search in all archives.</a>
    

    
    <div class="field has-addons-tablet">
      <div class="control is-expanded">
        <label for="query" class="hidden-label">Search term or terms</label>
        
          <input class="input is-medium" id="query" name="query" placeholder="Search term..." type="text" value="Gulcehre, C">
        
        
      </div>
      <div class="select control is-medium">
        <label class="is-hidden" for="searchtype">Field</label>
        <select class="is-medium" id="searchtype" name="searchtype"><option value="all">All fields</option><option value="title">Title</option><option selected value="author">Author(s)</option><option value="abstract">Abstract</option><option value="comments">Comments</option><option value="journal_ref">Journal reference</option><option value="acm_class">ACM classification</option><option value="msc_class">MSC classification</option><option value="report_num">Report number</option><option value="paper_id">arXiv identifier</option><option value="doi">DOI</option><option value="orcid">ORCID</option><option value="license">License (URI)</option><option value="author_id">arXiv author ID</option><option value="help">Help pages</option><option value="full_text">Full text</option></select>
      </div>
      <div class="control">
          <button class="button is-link is-medium">Search</button>
      </div>
    </div>
    <div class="field">
      <div class="control is-size-7">
        
        <label class="radio">
          <input checked id="abstracts-0" name="abstracts" type="radio" value="show"> Show abstracts
        </label>
        
        <label class="radio">
          <input id="abstracts-1" name="abstracts" type="radio" value="hide"> Hide abstracts
        </label>
        
      </div>
    </div>
    <div class="is-clearfix" style="height: 2.5em"> 
      <div class="is-pulled-right">
        
        <a href="/search/advanced?terms-0-term=Gulcehre%2C+C&amp;terms-0-field=author&amp;size=50&amp;order=-announced_date_first">Advanced Search</a>
        
      </div>
    </div>
    <input type="hidden" name="order" value="-announced_date_first">
    <input type="hidden" name="size" value="50">
  </form>

  

  
      
<div class="level breathe-horizontal">
  <div class="level-left">
    <form method="GET" action="/search/">
      <div style="display: none;">
        
          
            <select id="searchtype" name="searchtype"><option value="all">All fields</option><option value="title">Title</option><option selected value="author">Author(s)</option><option value="abstract">Abstract</option><option value="comments">Comments</option><option value="journal_ref">Journal reference</option><option value="acm_class">ACM classification</option><option value="msc_class">MSC classification</option><option value="report_num">Report number</option><option value="paper_id">arXiv identifier</option><option value="doi">DOI</option><option value="orcid">ORCID</option><option value="license">License (URI)</option><option value="author_id">arXiv author ID</option><option value="help">Help pages</option><option value="full_text">Full text</option></select>
          
        
          
            <input id="query" name="query" type="text" value="Gulcehre, C">
          
        
          
        
          
        
          
            <ul id="abstracts"><li><input checked id="abstracts-0" name="abstracts" type="radio" value="show"> <label for="abstracts-0">Show abstracts</label></li><li><input id="abstracts-1" name="abstracts" type="radio" value="hide"> <label for="abstracts-1">Hide abstracts</label></li></ul>
          
        
      </div>
      <div class="box field is-grouped is-grouped-multiline level-item">
        <div class="control">
          <span class="select is-small">
            <select id="size" name="size"><option value="25">25</option><option selected value="50">50</option><option value="100">100</option><option value="200">200</option></select>
          </span>
          <label for="size">results per page</label>.
        </div>
        <div class="control">
          <label for="order">Sort results by</label>
          <span class="select is-small">
            <select id="order" name="order"><option selected value="-announced_date_first">Announcement date (newest first)</option><option value="announced_date_first">Announcement date (oldest first)</option><option value="-submitted_date">Submission date (newest first)</option><option value="submitted_date">Submission date (oldest first)</option><option value="">Relevance</option></select>
          </span>
        </div>
        <div class="control">
          <button class="button is-small is-link">Go</button>
        </div>
      </div>
    </form>
  </div>
</div>
      




<ol class="breathe-horizontal" start="1"> 


  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.10251">arXiv:2106.10251</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.10251">pdf</a>, <a href="https://arxiv.org/format/2106.10251">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Active Offline Policy Selection
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Konyushkova%2C+K">Ksenia Konyushkova</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yutian Chen</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Paine%2C+T+L">Tom Le Paine</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Gulcehre%2C+C">Caglar Gulcehre</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Paduraru%2C+C">Cosmin Paduraru</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Mankowitz%2C+D+J">Daniel J Mankowitz</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Denil%2C+M">Misha Denil</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=de+Freitas%2C+N">Nando de Freitas</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.10251v3-abstract-short" style="display: inline;">
        This paper addresses the problem of policy selection in domains with abundant logged data, but with a restricted interaction budget. Solving this problem would enable safe evaluation and deployment of offline reinforcement learning policies in industry, robotics, and recommendation domains among others. Several off-policy evaluation (OPE) techniques have been proposed to assess the value of polici&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.10251v3-abstract-full').style.display = 'inline'; document.getElementById('2106.10251v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.10251v3-abstract-full" style="display: none;">
        This paper addresses the problem of policy selection in domains with abundant logged data, but with a restricted interaction budget. Solving this problem would enable safe evaluation and deployment of offline reinforcement learning policies in industry, robotics, and recommendation domains among others. Several off-policy evaluation (OPE) techniques have been proposed to assess the value of policies using only logged data. However, there is still a big gap between the evaluation by OPE and the full online evaluation in the real environment. Yet, large amounts of online interactions are often not possible in practice. To overcome this problem, we introduce \emph{active offline policy selection} - a novel sequential decision approach that combines logged data with online interaction to identify the best policy. This approach uses OPE estimates to warm start the online evaluation. Then, in order to utilize the limited environment interactions wisely we decide which policy to evaluate next based on a Bayesian optimization method with a kernel function that represents policy similarity. We use multiple benchmarks with a large number of candidate policies to show that the proposed approach improves upon state-of-the-art OPE estimates and pure online policy evaluation.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.10251v3-abstract-full').style.display = 'none'; document.getElementById('2106.10251v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 3 December, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 18 June, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Presented at NeurIPS 2021</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2105.10148">arXiv:2105.10148</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2105.10148">pdf</a>, <a href="https://arxiv.org/format/2105.10148">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        On Instrumental Variable Regression for Deep Offline Policy Evaluation
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yutian Chen</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Xu%2C+L">Liyuan Xu</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Gulcehre%2C+C">Caglar Gulcehre</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Paine%2C+T+L">Tom Le Paine</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Gretton%2C+A">Arthur Gretton</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=de+Freitas%2C+N">Nando de Freitas</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Doucet%2C+A">Arnaud Doucet</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2105.10148v1-abstract-short" style="display: inline;">
        We show that the popular reinforcement learning (RL) strategy of estimating the state-action value (Q-function) by minimizing the mean squared Bellman error leads to a regression problem with confounding, the inputs and output noise being correlated. Hence, direct minimization of the Bellman error can result in significantly biased Q-function estimates. We explain why fixing the target Q-network i&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.10148v1-abstract-full').style.display = 'inline'; document.getElementById('2105.10148v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2105.10148v1-abstract-full" style="display: none;">
        We show that the popular reinforcement learning (RL) strategy of estimating the state-action value (Q-function) by minimizing the mean squared Bellman error leads to a regression problem with confounding, the inputs and output noise being correlated. Hence, direct minimization of the Bellman error can result in significantly biased Q-function estimates. We explain why fixing the target Q-network in Deep Q-Networks and Fitted Q Evaluation provides a way of overcoming this confounding, thus shedding new light on this popular but not well understood trick in the deep RL literature. An alternative approach to address confounding is to leverage techniques developed in the causality literature, notably instrumental variables (IV). We bring together here the literature on IV and RL by investigating whether IV approaches can lead to improved Q-function estimates. This paper analyzes and compares a wide range of recent IV methods in the context of offline policy evaluation (OPE), where the goal is to estimate the value of a policy using logged data only. By applying different IV techniques to OPE, we are not only able to recover previously proposed OPE methods such as model-based techniques but also to obtain competitive new techniques. We find empirically that state-of-the-art OPE methods are closely matched in performance by some IV methods such as AGMM, which were not developed for OPE. We open-source all our code and datasets at https://github.com/liyuan9988/IVOPEwithACME.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.10148v1-abstract-full').style.display = 'none'; document.getElementById('2105.10148v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 21 May, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.09575">arXiv:2103.09575</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.09575">pdf</a>, <a href="https://arxiv.org/format/2103.09575">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Regularized Behavior Value Estimation
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Gulcehre%2C+C">Caglar Gulcehre</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Colmenarejo%2C+S+G">Sergio Gómez Colmenarejo</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Z">Ziyu Wang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Sygnowski%2C+J">Jakub Sygnowski</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Paine%2C+T">Thomas Paine</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Zolna%2C+K">Konrad Zolna</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yutian Chen</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Hoffman%2C+M">Matthew Hoffman</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Pascanu%2C+R">Razvan Pascanu</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=de+Freitas%2C+N">Nando de Freitas</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.09575v1-abstract-short" style="display: inline;">
        Offline reinforcement learning restricts the learning process to rely only on logged-data without access to an environment. While this enables real-world applications, it also poses unique challenges. One important challenge is dealing with errors caused by the overestimation of values for state-action pairs not well-covered by the training data. Due to bootstrapping, these errors get amplified du&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.09575v1-abstract-full').style.display = 'inline'; document.getElementById('2103.09575v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.09575v1-abstract-full" style="display: none;">
        Offline reinforcement learning restricts the learning process to rely only on logged-data without access to an environment. While this enables real-world applications, it also poses unique challenges. One important challenge is dealing with errors caused by the overestimation of values for state-action pairs not well-covered by the training data. Due to bootstrapping, these errors get amplified during training and can lead to divergence, thereby crippling learning. To overcome this challenge, we introduce Regularized Behavior Value Estimation (R-BVE). Unlike most approaches, which use policy improvement during training, R-BVE estimates the value of the behavior policy during training and only performs policy improvement at deployment time. Further, R-BVE uses a ranking regularisation term that favours actions in the dataset that lead to successful outcomes. We provide ample empirical evidence of R-BVE&#39;s effectiveness, including state-of-the-art performance on the RL Unplugged ATARI dataset. We also test R-BVE on new datasets, from bsuite and a challenging DeepMind Lab task, and show that R-BVE outperforms other state-of-the-art discrete control offline RL methods.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.09575v1-abstract-full').style.display = 'none'; document.getElementById('2103.09575v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 17 March, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2011.13885">arXiv:2011.13885</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2011.13885">pdf</a>, <a href="https://arxiv.org/format/2011.13885">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Offline Learning from Demonstrations and Unlabeled Experience
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Zolna%2C+K">Konrad Zolna</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Novikov%2C+A">Alexander Novikov</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Konyushkova%2C+K">Ksenia Konyushkova</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Gulcehre%2C+C">Caglar Gulcehre</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Z">Ziyu Wang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Aytar%2C+Y">Yusuf Aytar</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Denil%2C+M">Misha Denil</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=de+Freitas%2C+N">Nando de Freitas</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Reed%2C+S">Scott Reed</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2011.13885v1-abstract-short" style="display: inline;">
        Behavior cloning (BC) is often practical for robot learning because it allows a policy to be trained offline without rewards, by supervised learning on expert demonstrations. However, BC does not effectively leverage what we will refer to as unlabeled experience: data of mixed and unknown quality without reward annotations. This unlabeled data can be generated by a variety of sources such as human&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2011.13885v1-abstract-full').style.display = 'inline'; document.getElementById('2011.13885v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2011.13885v1-abstract-full" style="display: none;">
        Behavior cloning (BC) is often practical for robot learning because it allows a policy to be trained offline without rewards, by supervised learning on expert demonstrations. However, BC does not effectively leverage what we will refer to as unlabeled experience: data of mixed and unknown quality without reward annotations. This unlabeled data can be generated by a variety of sources such as human teleoperation, scripted policies and other agents on the same robot. Towards data-driven offline robot learning that can use this unlabeled experience, we introduce Offline Reinforced Imitation Learning (ORIL). ORIL first learns a reward function by contrasting observations from demonstrator and unlabeled trajectories, then annotates all data with the learned reward, and finally trains an agent via offline reinforcement learning. Across a diverse set of continuous control and simulated robotic manipulation tasks, we show that ORIL consistently outperforms comparable BC agents by effectively leveraging unlabeled experience.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2011.13885v1-abstract-full').style.display = 'none'; document.getElementById('2011.13885v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 27 November, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted to Offline Reinforcement Learning Workshop at Neural Information Processing Systems (2020)</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2007.13483">arXiv:2007.13483</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2007.13483">pdf</a>, <a href="https://arxiv.org/format/2007.13483">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Post-Workshop Report on Science meets Engineering in Deep Learning, NeurIPS 2019, Vancouver
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Sagun%2C+L">Levent Sagun</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Gulcehre%2C+C">Caglar Gulcehre</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Romero%2C+A">Adriana Romero</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Rostamzadeh%2C+N">Negar Rostamzadeh</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Mannelli%2C+S+S">Stefano Sarao Mannelli</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2007.13483v2-abstract-short" style="display: inline;">
        Science meets Engineering in Deep Learning took place in Vancouver as part of the Workshop section of NeurIPS 2019. As organizers of the workshop, we created the following report in an attempt to isolate emerging topics and recurring themes that have been presented throughout the event. Deep learning can still be a complex mix of art and engineering despite its tremendous success in recent years.&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2007.13483v2-abstract-full').style.display = 'inline'; document.getElementById('2007.13483v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2007.13483v2-abstract-full" style="display: none;">
        Science meets Engineering in Deep Learning took place in Vancouver as part of the Workshop section of NeurIPS 2019. As organizers of the workshop, we created the following report in an attempt to isolate emerging topics and recurring themes that have been presented throughout the event. Deep learning can still be a complex mix of art and engineering despite its tremendous success in recent years. The workshop aimed at gathering people across the board to address seemingly contrasting challenges in the problems they are working on. As part of the call for the workshop, particular attention has been given to the interdependence of architecture, data, and optimization that gives rise to an enormous landscape of design and performance intricacies that are not well-understood. This year, our goal was to emphasize the following directions in our community: (i) identify obstacles in the way to better models and algorithms; (ii) identify the general trends from which we would like to build scientific and potentially theoretical understanding; and (iii) the rigorous design of scientific experiments and experimental protocols whose purpose is to resolve and pinpoint the origin of mysteries while ensuring reproducibility and robustness of conclusions. In the event, these topics emerged and were broadly discussed, matching our expectations and paving the way for new studies in these directions. While we acknowledge that the text is naturally biased as it comes through our lens, here we present an attempt to do a fair job of highlighting the outcome of the workshop.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2007.13483v2-abstract-full').style.display = 'none'; document.getElementById('2007.13483v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 29 July, 2020; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 25 June, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Report of NeurIPS 2019 workshop SEDL</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2007.09055">arXiv:2007.09055</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2007.09055">pdf</a>, <a href="https://arxiv.org/format/2007.09055">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Hyperparameter Selection for Offline Reinforcement Learning
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Paine%2C+T+L">Tom Le Paine</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Paduraru%2C+C">Cosmin Paduraru</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Michi%2C+A">Andrea Michi</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Gulcehre%2C+C">Caglar Gulcehre</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Zolna%2C+K">Konrad Zolna</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Novikov%2C+A">Alexander Novikov</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Z">Ziyu Wang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=de+Freitas%2C+N">Nando de Freitas</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2007.09055v1-abstract-short" style="display: inline;">
        Offline reinforcement learning (RL purely from logged data) is an important avenue for deploying RL techniques in real-world scenarios. However, existing hyperparameter selection methods for offline RL break the offline assumption by evaluating policies corresponding to each hyperparameter setting in the environment. This online execution is often infeasible and hence undermines the main aim of of&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2007.09055v1-abstract-full').style.display = 'inline'; document.getElementById('2007.09055v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2007.09055v1-abstract-full" style="display: none;">
        Offline reinforcement learning (RL purely from logged data) is an important avenue for deploying RL techniques in real-world scenarios. However, existing hyperparameter selection methods for offline RL break the offline assumption by evaluating policies corresponding to each hyperparameter setting in the environment. This online execution is often infeasible and hence undermines the main aim of offline RL. Therefore, in this work, we focus on \textit{offline hyperparameter selection}, i.e. methods for choosing the best policy from a set of many policies trained using different hyperparameters, given only logged data. Through large-scale empirical evaluation we show that: 1) offline RL algorithms are not robust to hyperparameter choices, 2) factors such as the offline RL algorithm and method for estimating Q values can have a big impact on hyperparameter selection, and 3) when we control those factors carefully, we can reliably rank policies across hyperparameter choices, and therefore choose policies which are close to the best policy in the set. Overall, our results present an optimistic view that offline hyperparameter selection is within reach, even in challenging tasks with pixel observations, high dimensional action spaces, and long horizon.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2007.09055v1-abstract-full').style.display = 'none'; document.getElementById('2007.09055v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 17 July, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2006.15134">arXiv:2006.15134</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2006.15134">pdf</a>, <a href="https://arxiv.org/format/2006.15134">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Critic Regularized Regression
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Z">Ziyu Wang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Novikov%2C+A">Alexander Novikov</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Zolna%2C+K">Konrad Zolna</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Springenberg%2C+J+T">Jost Tobias Springenberg</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Reed%2C+S">Scott Reed</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Shahriari%2C+B">Bobak Shahriari</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Siegel%2C+N">Noah Siegel</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Merel%2C+J">Josh Merel</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Gulcehre%2C+C">Caglar Gulcehre</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Heess%2C+N">Nicolas Heess</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=de+Freitas%2C+N">Nando de Freitas</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2006.15134v3-abstract-short" style="display: inline;">
        Offline reinforcement learning (RL), also known as batch RL, offers the prospect of policy optimization from large pre-recorded datasets without online environment interaction. It addresses challenges with regard to the cost of data collection and safety, both of which are particularly pertinent to real-world applications of RL. Unfortunately, most off-policy algorithms perform poorly when learnin&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2006.15134v3-abstract-full').style.display = 'inline'; document.getElementById('2006.15134v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2006.15134v3-abstract-full" style="display: none;">
        Offline reinforcement learning (RL), also known as batch RL, offers the prospect of policy optimization from large pre-recorded datasets without online environment interaction. It addresses challenges with regard to the cost of data collection and safety, both of which are particularly pertinent to real-world applications of RL. Unfortunately, most off-policy algorithms perform poorly when learning from a fixed dataset. In this paper, we propose a novel offline RL algorithm to learn policies from data using a form of critic-regularized regression (CRR). We find that CRR performs surprisingly well and scales to tasks with high-dimensional state and action spaces -- outperforming several state-of-the-art offline RL algorithms by a significant margin on a wide range of benchmark tasks.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2006.15134v3-abstract-full').style.display = 'none'; document.getElementById('2006.15134v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 22 September, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 26 June, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">24 pages; presented at NeurIPS 2020</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2006.13888">arXiv:2006.13888</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2006.13888">pdf</a>, <a href="https://arxiv.org/format/2006.13888">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        RL Unplugged: A Suite of Benchmarks for Offline Reinforcement Learning
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Gulcehre%2C+C">Caglar Gulcehre</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Z">Ziyu Wang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Novikov%2C+A">Alexander Novikov</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Paine%2C+T+L">Tom Le Paine</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Colmenarejo%2C+S+G">Sergio Gomez Colmenarejo</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Zolna%2C+K">Konrad Zolna</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Agarwal%2C+R">Rishabh Agarwal</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Merel%2C+J">Josh Merel</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Mankowitz%2C+D">Daniel Mankowitz</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Paduraru%2C+C">Cosmin Paduraru</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Dulac-Arnold%2C+G">Gabriel Dulac-Arnold</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Li%2C+J">Jerry Li</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Norouzi%2C+M">Mohammad Norouzi</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Hoffman%2C+M">Matt Hoffman</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Nachum%2C+O">Ofir Nachum</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Tucker%2C+G">George Tucker</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Heess%2C+N">Nicolas Heess</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=de+Freitas%2C+N">Nando de Freitas</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2006.13888v4-abstract-short" style="display: inline;">
        Offline methods for reinforcement learning have a potential to help bridge the gap between reinforcement learning research and real-world applications. They make it possible to learn policies from offline datasets, thus overcoming concerns associated with online data collection in the real-world, including cost, safety, or ethical concerns. In this paper, we propose a benchmark called RL Unplugged&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2006.13888v4-abstract-full').style.display = 'inline'; document.getElementById('2006.13888v4-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2006.13888v4-abstract-full" style="display: none;">
        Offline methods for reinforcement learning have a potential to help bridge the gap between reinforcement learning research and real-world applications. They make it possible to learn policies from offline datasets, thus overcoming concerns associated with online data collection in the real-world, including cost, safety, or ethical concerns. In this paper, we propose a benchmark called RL Unplugged to evaluate and compare offline RL methods. RL Unplugged includes data from a diverse range of domains including games (e.g., Atari benchmark) and simulated motor control problems (e.g., DM Control Suite). The datasets include domains that are partially or fully observable, use continuous or discrete actions, and have stochastic vs. deterministic dynamics. We propose detailed evaluation protocols for each domain in RL Unplugged and provide an extensive analysis of supervised learning and offline RL methods using these protocols. We will release data for all our tasks and open-source all algorithms presented in this paper. We hope that our suite of benchmarks will increase the reproducibility of experiments and make it possible to study challenging tasks with a limited computational budget, thus making RL research both more systematic and more accessible across the community. Moving forward, we view RL Unplugged as a living benchmark suite that will evolve and grow with datasets contributed by the research community and ourselves. Our project page is available on https://git.io/JJUhd.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2006.13888v4-abstract-full').style.display = 'none'; document.getElementById('2006.13888v4-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 12 February, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 24 June, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">NeurIPS paper. 21 pages including supplementary material, the github link for the datasets: https://github.com/deepmind/deepmind-research/rl_unplugged</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2006.00979">arXiv:2006.00979</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2006.00979">pdf</a>, <a href="https://arxiv.org/format/2006.00979">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Acme: A Research Framework for Distributed Reinforcement Learning
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Hoffman%2C+M">Matt Hoffman</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Shahriari%2C+B">Bobak Shahriari</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Aslanides%2C+J">John Aslanides</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Barth-Maron%2C+G">Gabriel Barth-Maron</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Behbahani%2C+F">Feryal Behbahani</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Norman%2C+T">Tamara Norman</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Abdolmaleki%2C+A">Abbas Abdolmaleki</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Cassirer%2C+A">Albin Cassirer</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Yang%2C+F">Fan Yang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Baumli%2C+K">Kate Baumli</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Henderson%2C+S">Sarah Henderson</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Novikov%2C+A">Alex Novikov</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Colmenarejo%2C+S+G">Sergio Gómez Colmenarejo</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Cabi%2C+S">Serkan Cabi</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Gulcehre%2C+C">Caglar Gulcehre</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Paine%2C+T+L">Tom Le Paine</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Cowie%2C+A">Andrew Cowie</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Z">Ziyu Wang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Piot%2C+B">Bilal Piot</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=de+Freitas%2C+N">Nando de Freitas</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2006.00979v1-abstract-short" style="display: inline;">
        Deep reinforcement learning has led to many recent-and groundbreaking-advancements. However, these advances have often come at the cost of both the scale and complexity of the underlying RL algorithms. Increases in complexity have in turn made it more difficult for researchers to reproduce published RL algorithms or rapidly prototype ideas. To address this, we introduce Acme, a tool to simplify th&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2006.00979v1-abstract-full').style.display = 'inline'; document.getElementById('2006.00979v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2006.00979v1-abstract-full" style="display: none;">
        Deep reinforcement learning has led to many recent-and groundbreaking-advancements. However, these advances have often come at the cost of both the scale and complexity of the underlying RL algorithms. Increases in complexity have in turn made it more difficult for researchers to reproduce published RL algorithms or rapidly prototype ideas. To address this, we introduce Acme, a tool to simplify the development of novel RL algorithms that is specifically designed to enable simple agent implementations that can be run at various scales of execution. Our aim is also to make the results of various RL algorithms developed in academia and industrial labs easier to reproduce and extend. To this end we are releasing baseline implementations of various algorithms, created using our framework. In this work we introduce the major design decisions behind Acme and show how these are used to construct these baselines. We also experiment with these agents at different scales of both complexity and computation-including distributed versions. Ultimately, we show that the design decisions behind Acme lead to agents that can be scaled both up and down and that, for the most part, greater levels of parallelization result in agents with equivalent performance, just faster.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2006.00979v1-abstract-full').style.display = 'none'; document.getElementById('2006.00979v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 1 June, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1910.09890">arXiv:1910.09890</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1910.09890">pdf</a>, <a href="https://arxiv.org/format/1910.09890">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Neural and Evolutionary Computing">cs.NE</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Improving the Gating Mechanism of Recurrent Neural Networks
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Gu%2C+A">Albert Gu</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Gulcehre%2C+C">Caglar Gulcehre</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Paine%2C+T+L">Tom Le Paine</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Hoffman%2C+M">Matt Hoffman</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Pascanu%2C+R">Razvan Pascanu</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1910.09890v2-abstract-short" style="display: inline;">
        Gating mechanisms are widely used in neural network models, where they allow gradients to backpropagate more easily through depth or time. However, their saturation property introduces problems of its own. For example, in recurrent models these gates need to have outputs near 1 to propagate information over long time-delays, which requires them to operate in their saturation regime and hinders gra&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1910.09890v2-abstract-full').style.display = 'inline'; document.getElementById('1910.09890v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1910.09890v2-abstract-full" style="display: none;">
        Gating mechanisms are widely used in neural network models, where they allow gradients to backpropagate more easily through depth or time. However, their saturation property introduces problems of its own. For example, in recurrent models these gates need to have outputs near 1 to propagate information over long time-delays, which requires them to operate in their saturation regime and hinders gradient-based learning of the gate mechanism. We address this problem by deriving two synergistic modifications to the standard gating mechanism that are easy to implement, introduce no additional hyperparameters, and improve learnability of the gates when they are close to saturation. We show how these changes are related to and improve on alternative recently proposed gating mechanisms such as chrono initialization and Ordered Neurons. Empirically, our simple gating mechanisms robustly improve the performance of recurrent models on a range of applications, including synthetic memorization tasks, sequential image classification, language modeling, and reinforcement learning, particularly when long-term dependencies are involved.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1910.09890v2-abstract-full').style.display = 'none'; document.getElementById('1910.09890v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 18 June, 2020; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 22 October, 2019;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2019.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">International Conference on Machine Learning 2020</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1910.06764">arXiv:1910.06764</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1910.06764">pdf</a>, <a href="https://arxiv.org/format/1910.06764">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Stabilizing Transformers for Reinforcement Learning
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Parisotto%2C+E">Emilio Parisotto</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Song%2C+H+F">H. Francis Song</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Rae%2C+J+W">Jack W. Rae</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Pascanu%2C+R">Razvan Pascanu</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Gulcehre%2C+C">Caglar Gulcehre</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Jayakumar%2C+S+M">Siddhant M. Jayakumar</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Jaderberg%2C+M">Max Jaderberg</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Kaufman%2C+R+L">Raphael Lopez Kaufman</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Clark%2C+A">Aidan Clark</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Noury%2C+S">Seb Noury</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Botvinick%2C+M+M">Matthew M. Botvinick</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Heess%2C+N">Nicolas Heess</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Hadsell%2C+R">Raia Hadsell</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1910.06764v1-abstract-short" style="display: inline;">
        Owing to their ability to both effectively integrate information over long time horizons and scale to massive amounts of data, self-attention architectures have recently shown breakthrough success in natural language processing (NLP), achieving state-of-the-art results in domains such as language modeling and machine translation. Harnessing the transformer&#39;s ability to process long time horizons o&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1910.06764v1-abstract-full').style.display = 'inline'; document.getElementById('1910.06764v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1910.06764v1-abstract-full" style="display: none;">
        Owing to their ability to both effectively integrate information over long time horizons and scale to massive amounts of data, self-attention architectures have recently shown breakthrough success in natural language processing (NLP), achieving state-of-the-art results in domains such as language modeling and machine translation. Harnessing the transformer&#39;s ability to process long time horizons of information could provide a similar performance boost in partially observable reinforcement learning (RL) domains, but the large-scale transformers used in NLP have yet to be successfully applied to the RL setting. In this work we demonstrate that the standard transformer architecture is difficult to optimize, which was previously observed in the supervised learning setting but becomes especially pronounced with RL objectives. We propose architectural modifications that substantially improve the stability and learning speed of the original Transformer and XL variant. The proposed architecture, the Gated Transformer-XL (GTrXL), surpasses LSTMs on challenging memory environments and achieves state-of-the-art results on the multi-task DMLab-30 benchmark suite, exceeding the performance of an external memory architecture. We show that the GTrXL, trained using the same losses, has stability and performance that consistently matches or exceeds a competitive LSTM baseline, including on more reactive tasks where memory is less critical. GTrXL offers an easy-to-train, simple-to-implement but substantially more expressive architectural alternative to the standard multi-layer LSTM ubiquitously used for RL agents in partially observable environments.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1910.06764v1-abstract-full').style.display = 'none'; document.getElementById('1910.06764v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 13 October, 2019; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2019.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1909.01387">arXiv:1909.01387</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1909.01387">pdf</a>, <a href="https://arxiv.org/format/1909.01387">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Making Efficient Use of Demonstrations to Solve Hard Exploration Problems
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Paine%2C+T+L">Tom Le Paine</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Gulcehre%2C+C">Caglar Gulcehre</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Shahriari%2C+B">Bobak Shahriari</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Denil%2C+M">Misha Denil</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Hoffman%2C+M">Matt Hoffman</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Soyer%2C+H">Hubert Soyer</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Tanburn%2C+R">Richard Tanburn</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Kapturowski%2C+S">Steven Kapturowski</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Rabinowitz%2C+N">Neil Rabinowitz</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Williams%2C+D">Duncan Williams</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Barth-Maron%2C+G">Gabriel Barth-Maron</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Z">Ziyu Wang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=de+Freitas%2C+N">Nando de Freitas</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Team%2C+W">Worlds Team</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1909.01387v1-abstract-short" style="display: inline;">
        This paper introduces R2D3, an agent that makes efficient use of demonstrations to solve hard exploration problems in partially observable environments with highly variable initial conditions. We also introduce a suite of eight tasks that combine these three properties, and show that R2D3 can solve several of the tasks where other state of the art methods (both with and without demonstrations) fai&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1909.01387v1-abstract-full').style.display = 'inline'; document.getElementById('1909.01387v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1909.01387v1-abstract-full" style="display: none;">
        This paper introduces R2D3, an agent that makes efficient use of demonstrations to solve hard exploration problems in partially observable environments with highly variable initial conditions. We also introduce a suite of eight tasks that combine these three properties, and show that R2D3 can solve several of the tasks where other state of the art methods (both with and without demonstrations) fail to see even a single successful trajectory after tens of billions of steps of exploration.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1909.01387v1-abstract-full').style.display = 'none'; document.getElementById('1909.01387v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 3 September, 2019; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2019.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1810.08647">arXiv:1810.08647</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1810.08647">pdf</a>, <a href="https://arxiv.org/format/1810.08647">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Multiagent Systems">cs.MA</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Social Influence as Intrinsic Motivation for Multi-Agent Deep Reinforcement Learning
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Jaques%2C+N">Natasha Jaques</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Lazaridou%2C+A">Angeliki Lazaridou</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Hughes%2C+E">Edward Hughes</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Gulcehre%2C+C">Caglar Gulcehre</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Ortega%2C+P+A">Pedro A. Ortega</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Strouse%2C+D">DJ Strouse</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Leibo%2C+J+Z">Joel Z. Leibo</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=de+Freitas%2C+N">Nando de Freitas</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1810.08647v4-abstract-short" style="display: inline;">
        We propose a unified mechanism for achieving coordination and communication in Multi-Agent Reinforcement Learning (MARL), through rewarding agents for having causal influence over other agents&#39; actions. Causal influence is assessed using counterfactual reasoning. At each timestep, an agent simulates alternate actions that it could have taken, and computes their effect on the behavior of other agen&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1810.08647v4-abstract-full').style.display = 'inline'; document.getElementById('1810.08647v4-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1810.08647v4-abstract-full" style="display: none;">
        We propose a unified mechanism for achieving coordination and communication in Multi-Agent Reinforcement Learning (MARL), through rewarding agents for having causal influence over other agents&#39; actions. Causal influence is assessed using counterfactual reasoning. At each timestep, an agent simulates alternate actions that it could have taken, and computes their effect on the behavior of other agents. Actions that lead to bigger changes in other agents&#39; behavior are considered influential and are rewarded. We show that this is equivalent to rewarding agents for having high mutual information between their actions. Empirical results demonstrate that influence leads to enhanced coordination and communication in challenging social dilemma environments, dramatically increasing the learning curves of the deep RL agents, and leading to more meaningful learned communication protocols. The influence rewards for all agents can be computed in a decentralized way by enabling agents to learn a model of other agents using deep neural networks. In contrast, key previous works on emergent communication in the MARL setting were unable to learn diverse policies in a decentralized manner and had to resort to centralized training. Consequently, the influence reward opens up a window of new opportunities for research in this area.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1810.08647v4-abstract-full').style.display = 'none'; document.getElementById('1810.08647v4-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 18 June, 2019; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 19 October, 2018;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2018.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1809.10460">arXiv:1809.10460</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1809.10460">pdf</a>, <a href="https://arxiv.org/format/1809.10460">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Sound">cs.SD</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Sample Efficient Adaptive Text-to-Speech
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yutian Chen</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Assael%2C+Y">Yannis Assael</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Shillingford%2C+B">Brendan Shillingford</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Budden%2C+D">David Budden</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Reed%2C+S">Scott Reed</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Zen%2C+H">Heiga Zen</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Q">Quan Wang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Cobo%2C+L+C">Luis C. Cobo</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Trask%2C+A">Andrew Trask</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Laurie%2C+B">Ben Laurie</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Gulcehre%2C+C">Caglar Gulcehre</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Oord%2C+A+v+d">Aäron van den Oord</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Vinyals%2C+O">Oriol Vinyals</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=de+Freitas%2C+N">Nando de Freitas</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1809.10460v3-abstract-short" style="display: inline;">
        We present a meta-learning approach for adaptive text-to-speech (TTS) with few data. During training, we learn a multi-speaker model using a shared conditional WaveNet core and independent learned embeddings for each speaker. The aim of training is not to produce a neural network with fixed weights, which is then deployed as a TTS system. Instead, the aim is to produce a network that requires few&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1809.10460v3-abstract-full').style.display = 'inline'; document.getElementById('1809.10460v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1809.10460v3-abstract-full" style="display: none;">
        We present a meta-learning approach for adaptive text-to-speech (TTS) with few data. During training, we learn a multi-speaker model using a shared conditional WaveNet core and independent learned embeddings for each speaker. The aim of training is not to produce a neural network with fixed weights, which is then deployed as a TTS system. Instead, the aim is to produce a network that requires few data at deployment time to rapidly adapt to new speakers. We introduce and benchmark three strategies: (i) learning the speaker embedding while keeping the WaveNet core fixed, (ii) fine-tuning the entire architecture with stochastic gradient descent, and (iii) predicting the speaker embedding with a trained neural network encoder. The experiments show that these approaches are successful at adapting the multi-speaker neural network to new speakers, obtaining state-of-the-art results in both sample naturalness and voice similarity with merely a few minutes of audio data from new speakers.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1809.10460v3-abstract-full').style.display = 'none'; document.getElementById('1809.10460v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 16 January, 2019; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 27 September, 2018;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2018.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted by ICLR 2019</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1806.01261">arXiv:1806.01261</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1806.01261">pdf</a>, <a href="https://arxiv.org/format/1806.01261">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Relational inductive biases, deep learning, and graph networks
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Battaglia%2C+P+W">Peter W. Battaglia</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Hamrick%2C+J+B">Jessica B. Hamrick</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Bapst%2C+V">Victor Bapst</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Sanchez-Gonzalez%2C+A">Alvaro Sanchez-Gonzalez</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Zambaldi%2C+V">Vinicius Zambaldi</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Malinowski%2C+M">Mateusz Malinowski</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Tacchetti%2C+A">Andrea Tacchetti</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Raposo%2C+D">David Raposo</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Santoro%2C+A">Adam Santoro</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Faulkner%2C+R">Ryan Faulkner</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Gulcehre%2C+C">Caglar Gulcehre</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Song%2C+F">Francis Song</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Ballard%2C+A">Andrew Ballard</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Gilmer%2C+J">Justin Gilmer</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Dahl%2C+G">George Dahl</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Vaswani%2C+A">Ashish Vaswani</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Allen%2C+K">Kelsey Allen</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Nash%2C+C">Charles Nash</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Langston%2C+V">Victoria Langston</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Dyer%2C+C">Chris Dyer</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Heess%2C+N">Nicolas Heess</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Wierstra%2C+D">Daan Wierstra</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Kohli%2C+P">Pushmeet Kohli</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Botvinick%2C+M">Matt Botvinick</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Vinyals%2C+O">Oriol Vinyals</a>
      , et al. (2 additional authors not shown)
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1806.01261v3-abstract-short" style="display: inline;">
        Artificial intelligence (AI) has undergone a renaissance recently, making major progress in key domains such as vision, language, control, and decision-making. This has been due, in part, to cheap data and cheap compute resources, which have fit the natural strengths of deep learning. However, many defining characteristics of human intelligence, which developed under much different pressures, rema&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1806.01261v3-abstract-full').style.display = 'inline'; document.getElementById('1806.01261v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1806.01261v3-abstract-full" style="display: none;">
        Artificial intelligence (AI) has undergone a renaissance recently, making major progress in key domains such as vision, language, control, and decision-making. This has been due, in part, to cheap data and cheap compute resources, which have fit the natural strengths of deep learning. However, many defining characteristics of human intelligence, which developed under much different pressures, remain out of reach for current approaches. In particular, generalizing beyond one&#39;s experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI.
  The following is part position paper, part review, and part unification. We argue that combinatorial generalization must be a top priority for AI to achieve human-like abilities, and that structured representations and computations are key to realizing this objective. Just as biology uses nature and nurture cooperatively, we reject the false choice between &#34;hand-engineering&#34; and &#34;end-to-end&#34; learning, and instead advocate for an approach which benefits from their complementary strengths. We explore how using relational inductive biases within deep learning architectures can facilitate learning about entities, relations, and rules for composing them. We present a new building block for the AI toolkit with a strong relational inductive bias--the graph network--which generalizes and extends various approaches for neural networks that operate on graphs, and provides a straightforward interface for manipulating structured knowledge and producing structured behaviors. We discuss how graph networks can support relational reasoning and combinatorial generalization, laying the foundation for more sophisticated, interpretable, and flexible patterns of reasoning. As a companion to this paper, we have released an open-source software library for building graph networks, with demonstrations of how to use them in practice.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1806.01261v3-abstract-full').style.display = 'none'; document.getElementById('1806.01261v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 17 October, 2018; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 4 June, 2018;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2018.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1805.09786">arXiv:1805.09786</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1805.09786">pdf</a>, <a href="https://arxiv.org/format/1805.09786">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Neural and Evolutionary Computing">cs.NE</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Hyperbolic Attention Networks
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Gulcehre%2C+C">Caglar Gulcehre</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Denil%2C+M">Misha Denil</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Malinowski%2C+M">Mateusz Malinowski</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Razavi%2C+A">Ali Razavi</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Pascanu%2C+R">Razvan Pascanu</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Hermann%2C+K+M">Karl Moritz Hermann</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Battaglia%2C+P">Peter Battaglia</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Bapst%2C+V">Victor Bapst</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Raposo%2C+D">David Raposo</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Santoro%2C+A">Adam Santoro</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=de+Freitas%2C+N">Nando de Freitas</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1805.09786v1-abstract-short" style="display: inline;">
        We introduce hyperbolic attention networks to endow neural networks with enough capacity to match the complexity of data with hierarchical and power-law structure. A few recent approaches have successfully demonstrated the benefits of imposing hyperbolic geometry on the parameters of shallow networks. We extend this line of work by imposing hyperbolic geometry on the activations of neural networks&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1805.09786v1-abstract-full').style.display = 'inline'; document.getElementById('1805.09786v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1805.09786v1-abstract-full" style="display: none;">
        We introduce hyperbolic attention networks to endow neural networks with enough capacity to match the complexity of data with hierarchical and power-law structure. A few recent approaches have successfully demonstrated the benefits of imposing hyperbolic geometry on the parameters of shallow networks. We extend this line of work by imposing hyperbolic geometry on the activations of neural networks. This allows us to exploit hyperbolic geometry to reason about embeddings produced by deep networks. We achieve this by re-expressing the ubiquitous mechanism of soft attention in terms of operations defined for hyperboloid and Klein models. Our method shows improvements in terms of generalization on neural machine translation, learning on graphs and visual question answering tasks while keeping the neural representations compact.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1805.09786v1-abstract-full').style.display = 'none'; document.getElementById('1805.09786v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 24 May, 2018; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2018.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1711.10462">arXiv:1711.10462</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1711.10462">pdf</a>, <a href="https://arxiv.org/format/1711.10462">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Plan, Attend, Generate: Planning for Sequence-to-Sequence Models
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Dutil%2C+F">Francis Dutil</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Gulcehre%2C+C">Caglar Gulcehre</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Trischler%2C+A">Adam Trischler</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Bengio%2C+Y">Yoshua Bengio</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1711.10462v1-abstract-short" style="display: inline;">
        We investigate the integration of a planning mechanism into sequence-to-sequence models using attention. We develop a model which can plan ahead in the future when it computes its alignments between input and output sequences, constructing a matrix of proposed future alignments and a commitment vector that governs whether to follow or recompute the plan. This mechanism is inspired by the recently&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1711.10462v1-abstract-full').style.display = 'inline'; document.getElementById('1711.10462v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1711.10462v1-abstract-full" style="display: none;">
        We investigate the integration of a planning mechanism into sequence-to-sequence models using attention. We develop a model which can plan ahead in the future when it computes its alignments between input and output sequences, constructing a matrix of proposed future alignments and a commitment vector that governs whether to follow or recompute the plan. This mechanism is inspired by the recently proposed strategic attentive reader and writer (STRAW) model for Reinforcement Learning. Our proposed model is end-to-end trainable using primarily differentiable operations. We show that it outperforms a strong baseline on character-level translation tasks from WMT&#39;15, the algorithmic task of finding Eulerian circuits of graphs, and question generation from the text. Our analysis demonstrates that the model computes qualitatively intuitive alignments, converges faster than the baselines, and achieves superior performance with fewer parameters.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1711.10462v1-abstract-full').style.display = 'none'; document.getElementById('1711.10462v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 28 November, 2017; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2017.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">NIPS 2017</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1706.05087">arXiv:1706.05087</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1706.05087">pdf</a>, <a href="https://arxiv.org/format/1706.05087">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Neural and Evolutionary Computing">cs.NE</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Plan, Attend, Generate: Character-level Neural Machine Translation with Planning in the Decoder
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Gulcehre%2C+C">Caglar Gulcehre</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Dutil%2C+F">Francis Dutil</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Trischler%2C+A">Adam Trischler</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Bengio%2C+Y">Yoshua Bengio</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1706.05087v2-abstract-short" style="display: inline;">
        We investigate the integration of a planning mechanism into an encoder-decoder architecture with an explicit alignment for character-level machine translation. We develop a model that plans ahead when it computes alignments between the source and target sequences, constructing a matrix of proposed future alignments and a commitment vector that governs whether to follow or recompute the plan. This&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1706.05087v2-abstract-full').style.display = 'inline'; document.getElementById('1706.05087v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1706.05087v2-abstract-full" style="display: none;">
        We investigate the integration of a planning mechanism into an encoder-decoder architecture with an explicit alignment for character-level machine translation. We develop a model that plans ahead when it computes alignments between the source and target sequences, constructing a matrix of proposed future alignments and a commitment vector that governs whether to follow or recompute the plan. This mechanism is inspired by the strategic attentive reader and writer (STRAW) model. Our proposed model is end-to-end trainable with fully differentiable operations. We show that it outperforms a strong baseline on three character-level decoder neural machine translation on WMT&#39;15 corpus. Our analysis demonstrates that our model can compute qualitatively intuitive alignments and achieves superior performance with fewer parameters.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1706.05087v2-abstract-full').style.display = 'none'; document.getElementById('1706.05087v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 23 June, 2017; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 13 June, 2017;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2017.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted to Rep4NLP 2017 Workshop at ACL 2017 Conference</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1706.02761">arXiv:1706.02761</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1706.02761">pdf</a>, <a href="https://arxiv.org/format/1706.02761">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Neural and Evolutionary Computing">cs.NE</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Gated Orthogonal Recurrent Units: On Learning to Forget
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Jing%2C+L">Li Jing</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Gulcehre%2C+C">Caglar Gulcehre</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Peurifoy%2C+J">John Peurifoy</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Shen%2C+Y">Yichen Shen</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Tegmark%2C+M">Max Tegmark</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Solja%C4%8Di%C4%87%2C+M">Marin Soljačić</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Bengio%2C+Y">Yoshua Bengio</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1706.02761v3-abstract-short" style="display: inline;">
        We present a novel recurrent neural network (RNN) based model that combines the remembering ability of unitary RNNs with the ability of gated RNNs to effectively forget redundant/irrelevant information in its memory. We achieve this by extending unitary RNNs with a gating mechanism. Our model is able to outperform LSTMs, GRUs and Unitary RNNs on several long-term dependency benchmark tasks. We emp&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1706.02761v3-abstract-full').style.display = 'inline'; document.getElementById('1706.02761v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1706.02761v3-abstract-full" style="display: none;">
        We present a novel recurrent neural network (RNN) based model that combines the remembering ability of unitary RNNs with the ability of gated RNNs to effectively forget redundant/irrelevant information in its memory. We achieve this by extending unitary RNNs with a gating mechanism. Our model is able to outperform LSTMs, GRUs and Unitary RNNs on several long-term dependency benchmark tasks. We empirically both show the orthogonal/unitary RNNs lack the ability to forget and also the ability of GORU to simultaneously remember long term dependencies while forgetting irrelevant information. This plays an important role in recurrent neural networks. We provide competitive results along with an analysis of our model on many natural sequential tasks including the bAbI Question Answering, TIMIT speech spectrum prediction, Penn TreeBank, and synthetic tasks that involve long-term dependencies such as algorithmic, parenthesis, denoising and copying tasks.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1706.02761v3-abstract-full').style.display = 'none'; document.getElementById('1706.02761v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 25 October, 2017; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 8 June, 2017;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2017.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1705.02012">arXiv:1705.02012</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1705.02012">pdf</a>, <a href="https://arxiv.org/ps/1705.02012">ps</a>, <a href="https://arxiv.org/format/1705.02012">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Machine Comprehension by Text-to-Text Neural Question Generation
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Yuan%2C+X">Xingdi Yuan</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Wang%2C+T">Tong Wang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Gulcehre%2C+C">Caglar Gulcehre</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Sordoni%2C+A">Alessandro Sordoni</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Bachman%2C+P">Philip Bachman</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Subramanian%2C+S">Sandeep Subramanian</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+S">Saizheng Zhang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Trischler%2C+A">Adam Trischler</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1705.02012v2-abstract-short" style="display: inline;">
        We propose a recurrent neural model that generates natural-language questions from documents, conditioned on answers. We show how to train the model using a combination of supervised and reinforcement learning. After teacher forcing for standard maximum likelihood training, we fine-tune the model using policy gradient techniques to maximize several rewards that measure question quality. Most notab&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1705.02012v2-abstract-full').style.display = 'inline'; document.getElementById('1705.02012v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1705.02012v2-abstract-full" style="display: none;">
        We propose a recurrent neural model that generates natural-language questions from documents, conditioned on answers. We show how to train the model using a combination of supervised and reinforcement learning. After teacher forcing for standard maximum likelihood training, we fine-tune the model using policy gradient techniques to maximize several rewards that measure question quality. Most notably, one of these rewards is the performance of a question-answering system. We motivate question generation as a means to improve the performance of question answering systems. Our model is trained and evaluated on the recent question-answering dataset SQuAD.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1705.02012v2-abstract-full').style.display = 'none'; document.getElementById('1705.02012v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 May, 2017; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 4 May, 2017;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2017.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1703.00788">arXiv:1703.00788</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1703.00788">pdf</a>, <a href="https://arxiv.org/format/1703.00788">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        A Robust Adaptive Stochastic Gradient Method for Deep Learning
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Gulcehre%2C+C">Caglar Gulcehre</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Sotelo%2C+J">Jose Sotelo</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Moczulski%2C+M">Marcin Moczulski</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Bengio%2C+Y">Yoshua Bengio</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1703.00788v1-abstract-short" style="display: inline;">
        Stochastic gradient algorithms are the main focus of large-scale optimization problems and led to important successes in the recent advancement of the deep learning algorithms. The convergence of SGD depends on the careful choice of learning rate and the amount of the noise in stochastic estimates of the gradients. In this paper, we propose an adaptive learning rate algorithm, which utilizes stoch&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1703.00788v1-abstract-full').style.display = 'inline'; document.getElementById('1703.00788v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1703.00788v1-abstract-full" style="display: none;">
        Stochastic gradient algorithms are the main focus of large-scale optimization problems and led to important successes in the recent advancement of the deep learning algorithms. The convergence of SGD depends on the careful choice of learning rate and the amount of the noise in stochastic estimates of the gradients. In this paper, we propose an adaptive learning rate algorithm, which utilizes stochastic curvature information of the loss function for automatically tuning the learning rates. The information about the element-wise curvature of the loss function is estimated from the local statistics of the stochastic first order gradients. We further propose a new variance reduction technique to speed up the convergence. In our experiments with deep neural networks, we obtained better performance compared to the popular stochastic gradient algorithms.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1703.00788v1-abstract-full').style.display = 'none'; document.getElementById('1703.00788v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 2 March, 2017; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2017.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">IJCNN 2017 Accepted Paper, An extension of our paper, &#34;ADASECANT: Robust Adaptive Secant Method for Stochastic Gradient&#34;</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1701.08718">arXiv:1701.08718</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1701.08718">pdf</a>, <a href="https://arxiv.org/format/1701.08718">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Neural and Evolutionary Computing">cs.NE</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Memory Augmented Neural Networks with Wormhole Connections
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Gulcehre%2C+C">Caglar Gulcehre</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Chandar%2C+S">Sarath Chandar</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Bengio%2C+Y">Yoshua Bengio</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1701.08718v1-abstract-short" style="display: inline;">
        Recent empirical results on long-term dependency tasks have shown that neural networks augmented with an external memory can learn the long-term dependency tasks more easily and achieve better generalization than vanilla recurrent neural networks (RNN). We suggest that memory augmented neural networks can reduce the effects of vanishing gradients by creating shortcut (or wormhole) connections. Bas&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1701.08718v1-abstract-full').style.display = 'inline'; document.getElementById('1701.08718v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1701.08718v1-abstract-full" style="display: none;">
        Recent empirical results on long-term dependency tasks have shown that neural networks augmented with an external memory can learn the long-term dependency tasks more easily and achieve better generalization than vanilla recurrent neural networks (RNN). We suggest that memory augmented neural networks can reduce the effects of vanishing gradients by creating shortcut (or wormhole) connections. Based on this observation, we propose a novel memory augmented neural network model called TARDIS (Temporal Automatic Relation Discovery in Sequences). The controller of TARDIS can store a selective set of embeddings of its own previous hidden states into an external memory and revisit them as and when needed. For TARDIS, memory acts as a storage for wormhole connections to the past to propagate the gradients more effectively and it helps to learn the temporal dependencies. The memory structure of TARDIS has similarities to both Neural Turing Machines (NTM) and Dynamic Neural Turing Machines (D-NTM), but both read and write operations of TARDIS are simpler and more efficient. We use discrete addressing for read/write operations which helps to substantially to reduce the vanishing gradient problem with very long sequences. Read and write operations in TARDIS are tied with a heuristic once the memory becomes full, and this makes the learning problem simpler when compared to NTM or D-NTM type of architectures. We provide a detailed analysis on the gradient propagation in general for MANNs. We evaluate our models on different long-term dependency tasks and report competitive results in all of them.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1701.08718v1-abstract-full').style.display = 'none'; document.getElementById('1701.08718v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 30 January, 2017; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2017.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1608.04980">arXiv:1608.04980</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1608.04980">pdf</a>, <a href="https://arxiv.org/format/1608.04980">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Neural and Evolutionary Computing">cs.NE</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Mollifying Networks
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Gulcehre%2C+C">Caglar Gulcehre</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Moczulski%2C+M">Marcin Moczulski</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Visin%2C+F">Francesco Visin</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Bengio%2C+Y">Yoshua Bengio</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1608.04980v1-abstract-short" style="display: inline;">
        The optimization of deep neural networks can be more challenging than traditional convex optimization problems due to the highly non-convex nature of the loss function, e.g. it can involve pathological landscapes such as saddle-surfaces that can be difficult to escape for algorithms based on simple gradient descent. In this paper, we attack the problem of optimization of highly non-convex neural n&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1608.04980v1-abstract-full').style.display = 'inline'; document.getElementById('1608.04980v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1608.04980v1-abstract-full" style="display: none;">
        The optimization of deep neural networks can be more challenging than traditional convex optimization problems due to the highly non-convex nature of the loss function, e.g. it can involve pathological landscapes such as saddle-surfaces that can be difficult to escape for algorithms based on simple gradient descent. In this paper, we attack the problem of optimization of highly non-convex neural networks by starting with a smoothed -- or \textit{mollified} -- objective function that gradually has a more non-convex energy landscape during the training. Our proposition is inspired by the recent studies in continuation methods: similar to curriculum methods, we begin learning an easier (possibly convex) objective function and let it evolve during the training, until it eventually goes back to being the original, difficult to optimize, objective function. The complexity of the mollified networks is controlled by a single hyperparameter which is annealed during the training. We show improvements on various difficult optimization tasks and establish a relationship with recent works on continuation methods for neural networks and mollifiers.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1608.04980v1-abstract-full').style.display = 'none'; document.getElementById('1608.04980v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 17 August, 2016; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2016.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1607.00036">arXiv:1607.00036</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1607.00036">pdf</a>, <a href="https://arxiv.org/format/1607.00036">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Neural and Evolutionary Computing">cs.NE</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Dynamic Neural Turing Machine with Soft and Hard Addressing Schemes
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Gulcehre%2C+C">Caglar Gulcehre</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Chandar%2C+S">Sarath Chandar</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Cho%2C+K">Kyunghyun Cho</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Bengio%2C+Y">Yoshua Bengio</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1607.00036v2-abstract-short" style="display: inline;">
        We extend neural Turing machine (NTM) model into a dynamic neural Turing machine (D-NTM) by introducing a trainable memory addressing scheme. This addressing scheme maintains for each memory cell two separate vectors, content and address vectors. This allows the D-NTM to learn a wide variety of location-based addressing strategies including both linear and nonlinear ones. We implement the D-NTM wi&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1607.00036v2-abstract-full').style.display = 'inline'; document.getElementById('1607.00036v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1607.00036v2-abstract-full" style="display: none;">
        We extend neural Turing machine (NTM) model into a dynamic neural Turing machine (D-NTM) by introducing a trainable memory addressing scheme. This addressing scheme maintains for each memory cell two separate vectors, content and address vectors. This allows the D-NTM to learn a wide variety of location-based addressing strategies including both linear and nonlinear ones. We implement the D-NTM with both continuous, differentiable and discrete, non-differentiable read/write mechanisms. We investigate the mechanisms and effects of learning to read and write into a memory through experiments on Facebook bAbI tasks using both a feedforward and GRUcontroller. The D-NTM is evaluated on a set of Facebook bAbI tasks and shown to outperform NTM and LSTM baselines. We have done extensive analysis of our model and different variations of NTM on bAbI task. We also provide further experimental results on sequential pMNIST, Stanford Natural Language Inference, associative recall and copy tasks.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1607.00036v2-abstract-full').style.display = 'none'; document.getElementById('1607.00036v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 17 March, 2017; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 30 June, 2016;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2016.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">13 pages, 3 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1605.02688">arXiv:1605.02688</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1605.02688">pdf</a>, <a href="https://arxiv.org/format/1605.02688">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Symbolic Computation">cs.SC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Mathematical Software">cs.MS</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Theano: A Python framework for fast computation of mathematical expressions
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=The+Theano+Development+Team"> The Theano Development Team</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Al-Rfou%2C+R">Rami Al-Rfou</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Alain%2C+G">Guillaume Alain</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Almahairi%2C+A">Amjad Almahairi</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Angermueller%2C+C">Christof Angermueller</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Bahdanau%2C+D">Dzmitry Bahdanau</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Ballas%2C+N">Nicolas Ballas</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Bastien%2C+F">Frédéric Bastien</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Bayer%2C+J">Justin Bayer</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Belikov%2C+A">Anatoly Belikov</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Belopolsky%2C+A">Alexander Belopolsky</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Bengio%2C+Y">Yoshua Bengio</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Bergeron%2C+A">Arnaud Bergeron</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Bergstra%2C+J">James Bergstra</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Bisson%2C+V">Valentin Bisson</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Snyder%2C+J+B">Josh Bleecher Snyder</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Bouchard%2C+N">Nicolas Bouchard</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Boulanger-Lewandowski%2C+N">Nicolas Boulanger-Lewandowski</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Bouthillier%2C+X">Xavier Bouthillier</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=de+Br%C3%A9bisson%2C+A">Alexandre de Brébisson</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Breuleux%2C+O">Olivier Breuleux</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Carrier%2C+P">Pierre-Luc Carrier</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Cho%2C+K">Kyunghyun Cho</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Chorowski%2C+J">Jan Chorowski</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Christiano%2C+P">Paul Christiano</a>
      , et al. (88 additional authors not shown)
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1605.02688v1-abstract-short" style="display: inline;">
        Theano is a Python library that allows to define, optimize, and evaluate mathematical expressions involving multi-dimensional arrays efficiently. Since its introduction, it has been one of the most used CPU and GPU mathematical compilers - especially in the machine learning community - and has shown steady performance improvements. Theano is being actively and continuously developed since 2008, mu&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1605.02688v1-abstract-full').style.display = 'inline'; document.getElementById('1605.02688v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1605.02688v1-abstract-full" style="display: none;">
        Theano is a Python library that allows to define, optimize, and evaluate mathematical expressions involving multi-dimensional arrays efficiently. Since its introduction, it has been one of the most used CPU and GPU mathematical compilers - especially in the machine learning community - and has shown steady performance improvements. Theano is being actively and continuously developed since 2008, multiple frameworks have been built on top of it and it has been used to produce many state-of-the-art machine learning models.
  The present article is structured as follows. Section I provides an overview of the Theano software and its community. Section II presents the principal features of Theano and how to use them, and compares them with other similar projects. Section III focuses on recently-introduced functionalities and improvements. Section IV compares the performance of Theano against Torch7 and TensorFlow on several machine learning models. Section V discusses current limitations of Theano and potential ways of improving it.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1605.02688v1-abstract-full').style.display = 'none'; document.getElementById('1605.02688v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 9 May, 2016; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2016.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">19 pages, 5 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1603.09025">arXiv:1603.09025</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1603.09025">pdf</a>, <a href="https://arxiv.org/format/1603.09025">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Recurrent Batch Normalization
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Cooijmans%2C+T">Tim Cooijmans</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Ballas%2C+N">Nicolas Ballas</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Laurent%2C+C">César Laurent</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=G%C3%BCl%C3%A7ehre%2C+%C3%87">Çağlar Gülçehre</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Courville%2C+A">Aaron Courville</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1603.09025v5-abstract-short" style="display: inline;">
        We propose a reparameterization of LSTM that brings the benefits of batch normalization to recurrent neural networks. Whereas previous works only apply batch normalization to the input-to-hidden transformation of RNNs, we demonstrate that it is both possible and beneficial to batch-normalize the hidden-to-hidden transition, thereby reducing internal covariate shift between time steps. We evaluate&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1603.09025v5-abstract-full').style.display = 'inline'; document.getElementById('1603.09025v5-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1603.09025v5-abstract-full" style="display: none;">
        We propose a reparameterization of LSTM that brings the benefits of batch normalization to recurrent neural networks. Whereas previous works only apply batch normalization to the input-to-hidden transformation of RNNs, we demonstrate that it is both possible and beneficial to batch-normalize the hidden-to-hidden transition, thereby reducing internal covariate shift between time steps. We evaluate our proposal on various sequential problems such as sequence classification, language modeling and question answering. Our empirical results show that our batch-normalized LSTM consistently leads to faster convergence and improved generalization.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1603.09025v5-abstract-full').style.display = 'none'; document.getElementById('1603.09025v5-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 27 February, 2017; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 29 March, 2016;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2016.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1603.08148">arXiv:1603.08148</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1603.08148">pdf</a>, <a href="https://arxiv.org/format/1603.08148">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Neural and Evolutionary Computing">cs.NE</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Pointing the Unknown Words
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Gulcehre%2C+C">Caglar Gulcehre</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Ahn%2C+S">Sungjin Ahn</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Nallapati%2C+R">Ramesh Nallapati</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+B">Bowen Zhou</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Bengio%2C+Y">Yoshua Bengio</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1603.08148v3-abstract-short" style="display: inline;">
        The problem of rare and unknown words is an important issue that can potentially influence the performance of many NLP systems, including both the traditional count-based and the deep learning models. We propose a novel way to deal with the rare and unseen words for the neural network models using attention. Our model uses two softmax layers in order to predict the next word in conditional languag&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1603.08148v3-abstract-full').style.display = 'inline'; document.getElementById('1603.08148v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1603.08148v3-abstract-full" style="display: none;">
        The problem of rare and unknown words is an important issue that can potentially influence the performance of many NLP systems, including both the traditional count-based and the deep learning models. We propose a novel way to deal with the rare and unseen words for the neural network models using attention. Our model uses two softmax layers in order to predict the next word in conditional language models: one predicts the location of a word in the source sentence, and the other predicts a word in the shortlist vocabulary. At each time-step, the decision of which softmax layer to use choose adaptively made by an MLP which is conditioned on the context.~We motivate our work from a psychological evidence that humans naturally have a tendency to point towards objects in the context or the environment when the name of an object is not known.~We observe improvements on two tasks, neural machine translation on the Europarl English to French parallel corpora and text summarization on the Gigaword dataset using our proposed model.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1603.08148v3-abstract-full').style.display = 'none'; document.getElementById('1603.08148v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 21 August, 2016; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 26 March, 2016;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2016.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">ACL 2016 Oral Paper</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1603.06807">arXiv:1603.06807</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1603.06807">pdf</a>, <a href="https://arxiv.org/format/1603.06807">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Neural and Evolutionary Computing">cs.NE</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Generating Factoid Questions With Recurrent Neural Networks: The 30M Factoid Question-Answer Corpus
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Serban%2C+I+V">Iulian Vlad Serban</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Garc%C3%ADa-Dur%C3%A1n%2C+A">Alberto García-Durán</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Gulcehre%2C+C">Caglar Gulcehre</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Ahn%2C+S">Sungjin Ahn</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Chandar%2C+S">Sarath Chandar</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Courville%2C+A">Aaron Courville</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Bengio%2C+Y">Yoshua Bengio</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1603.06807v2-abstract-short" style="display: inline;">
        Over the past decade, large-scale supervised learning corpora have enabled machine learning researchers to make substantial advances. However, to this date, there are no large-scale question-answer corpora available. In this paper we present the 30M Factoid Question-Answer Corpus, an enormous question answer pair corpus produced by applying a novel neural network architecture on the knowledge base&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1603.06807v2-abstract-full').style.display = 'inline'; document.getElementById('1603.06807v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1603.06807v2-abstract-full" style="display: none;">
        Over the past decade, large-scale supervised learning corpora have enabled machine learning researchers to make substantial advances. However, to this date, there are no large-scale question-answer corpora available. In this paper we present the 30M Factoid Question-Answer Corpus, an enormous question answer pair corpus produced by applying a novel neural network architecture on the knowledge base Freebase to transduce facts into natural language questions. The produced question answer pairs are evaluated both by human evaluators and using automatic evaluation metrics, including well-established machine translation and sentence similarity metrics. Across all evaluation criteria the question-generation model outperforms the competing template-based baseline. Furthermore, when presented to human evaluators, the generated questions appear comparable in quality to real human-generated questions.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1603.06807v2-abstract-full').style.display = 'none'; document.getElementById('1603.06807v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 29 May, 2016; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 22 March, 2016;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2016.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">13 pages, 1 figure, 7 tables</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          H.3.4; I.5.1; I.2.6; I.2.7
        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1603.00391">arXiv:1603.00391</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1603.00391">pdf</a>, <a href="https://arxiv.org/format/1603.00391">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Neural and Evolutionary Computing">cs.NE</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Noisy Activation Functions
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Gulcehre%2C+C">Caglar Gulcehre</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Moczulski%2C+M">Marcin Moczulski</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Denil%2C+M">Misha Denil</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Bengio%2C+Y">Yoshua Bengio</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1603.00391v3-abstract-short" style="display: inline;">
        Common nonlinear activation functions used in neural networks can cause training difficulties due to the saturation behavior of the activation function, which may hide dependencies that are not visible to vanilla-SGD (using first order gradients only). Gating mechanisms that use softly saturating activation functions to emulate the discrete switching of digital logic circuits are good examples of&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1603.00391v3-abstract-full').style.display = 'inline'; document.getElementById('1603.00391v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1603.00391v3-abstract-full" style="display: none;">
        Common nonlinear activation functions used in neural networks can cause training difficulties due to the saturation behavior of the activation function, which may hide dependencies that are not visible to vanilla-SGD (using first order gradients only). Gating mechanisms that use softly saturating activation functions to emulate the discrete switching of digital logic circuits are good examples of this. We propose to exploit the injection of appropriate noise so that the gradients may flow easily, even if the noiseless application of the activation function would yield zero gradient. Large noise will dominate the noise-free gradient and allow stochastic gradient descent toexplore more. By adding noise only to the problematic parts of the activation function, we allow the optimization procedure to explore the boundary between the degenerate (saturating) and the well-behaved parts of the activation function. We also establish connections to simulated annealing, when the amount of noise is annealed down, making it easier to optimize hard objective functions. We find experimentally that replacing such saturating activation functions by noisy variants helps training in many contexts, yielding state-of-the-art or competitive results on different datasets and task, especially when training seems to be the most difficult, e.g., when curriculum learning is necessary to obtain good results.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1603.00391v3-abstract-full').style.display = 'none'; document.getElementById('1603.00391v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 3 April, 2016; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 1 March, 2016;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2016.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1602.06023">arXiv:1602.06023</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1602.06023">pdf</a>, <a href="https://arxiv.org/format/1602.06023">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Abstractive Text Summarization Using Sequence-to-Sequence RNNs and Beyond
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Nallapati%2C+R">Ramesh Nallapati</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+B">Bowen Zhou</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=santos%2C+C+N+d">Cicero Nogueira dos santos</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Gulcehre%2C+C">Caglar Gulcehre</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Xiang%2C+B">Bing Xiang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1602.06023v5-abstract-short" style="display: inline;">
        In this work, we model abstractive text summarization using Attentional Encoder-Decoder Recurrent Neural Networks, and show that they achieve state-of-the-art performance on two different corpora. We propose several novel models that address critical problems in summarization that are not adequately modeled by the basic architecture, such as modeling key-words, capturing the hierarchy of sentence-&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1602.06023v5-abstract-full').style.display = 'inline'; document.getElementById('1602.06023v5-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1602.06023v5-abstract-full" style="display: none;">
        In this work, we model abstractive text summarization using Attentional Encoder-Decoder Recurrent Neural Networks, and show that they achieve state-of-the-art performance on two different corpora. We propose several novel models that address critical problems in summarization that are not adequately modeled by the basic architecture, such as modeling key-words, capturing the hierarchy of sentence-to-word structure, and emitting words that are rare or unseen at training time. Our work shows that many of our proposed models contribute to further improvement in performance. We also propose a new dataset consisting of multi-sentence summaries, and establish performance benchmarks for further research.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1602.06023v5-abstract-full').style.display = 'none'; document.getElementById('1602.06023v5-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 26 August, 2016; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 18 February, 2016;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2016.
      
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        The SIGNLL Conference on Computational Natural Language Learning (CoNLL), 2016
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1511.06295">arXiv:1511.06295</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1511.06295">pdf</a>, <a href="https://arxiv.org/format/1511.06295">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Policy Distillation
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Rusu%2C+A+A">Andrei A. Rusu</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Colmenarejo%2C+S+G">Sergio Gomez Colmenarejo</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Gulcehre%2C+C">Caglar Gulcehre</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Desjardins%2C+G">Guillaume Desjardins</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Kirkpatrick%2C+J">James Kirkpatrick</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Pascanu%2C+R">Razvan Pascanu</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Mnih%2C+V">Volodymyr Mnih</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Kavukcuoglu%2C+K">Koray Kavukcuoglu</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Hadsell%2C+R">Raia Hadsell</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1511.06295v2-abstract-short" style="display: inline;">
        Policies for complex visual tasks have been successfully learned with deep reinforcement learning, using an approach called deep Q-networks (DQN), but relatively large (task-specific) networks and extensive training are needed to achieve good performance. In this work, we present a novel method called policy distillation that can be used to extract the policy of a reinforcement learning agent and&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1511.06295v2-abstract-full').style.display = 'inline'; document.getElementById('1511.06295v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1511.06295v2-abstract-full" style="display: none;">
        Policies for complex visual tasks have been successfully learned with deep reinforcement learning, using an approach called deep Q-networks (DQN), but relatively large (task-specific) networks and extensive training are needed to achieve good performance. In this work, we present a novel method called policy distillation that can be used to extract the policy of a reinforcement learning agent and train a new network that performs at the expert level while being dramatically smaller and more efficient. Furthermore, the same method can be used to consolidate multiple task-specific policies into a single policy. We demonstrate these claims using the Atari domain and show that the multi-task distilled agent outperforms the single-task teachers as well as a jointly-trained DQN agent.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1511.06295v2-abstract-full').style.display = 'none'; document.getElementById('1511.06295v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 January, 2016; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 19 November, 2015;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2015.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Submitted to ICLR 2016</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1503.03535">arXiv:1503.03535</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1503.03535">pdf</a>, <a href="https://arxiv.org/format/1503.03535">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        On Using Monolingual Corpora in Neural Machine Translation
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Gulcehre%2C+C">Caglar Gulcehre</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Firat%2C+O">Orhan Firat</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Xu%2C+K">Kelvin Xu</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Cho%2C+K">Kyunghyun Cho</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Barrault%2C+L">Loic Barrault</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Lin%2C+H">Huei-Chi Lin</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Bougares%2C+F">Fethi Bougares</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Schwenk%2C+H">Holger Schwenk</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Bengio%2C+Y">Yoshua Bengio</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1503.03535v2-abstract-short" style="display: inline;">
        Recent work on end-to-end neural network-based architectures for machine translation has shown promising results for En-Fr and En-De translation. Arguably, one of the major factors behind this success has been the availability of high quality parallel corpora. In this work, we investigate how to leverage abundant monolingual corpora for neural machine translation. Compared to a phrase-based and hi&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1503.03535v2-abstract-full').style.display = 'inline'; document.getElementById('1503.03535v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1503.03535v2-abstract-full" style="display: none;">
        Recent work on end-to-end neural network-based architectures for machine translation has shown promising results for En-Fr and En-De translation. Arguably, one of the major factors behind this success has been the availability of high quality parallel corpora. In this work, we investigate how to leverage abundant monolingual corpora for neural machine translation. Compared to a phrase-based and hierarchical baseline, we obtain up to $1.96$ BLEU improvement on the low-resource language pair Turkish-English, and $1.59$ BLEU on the focused domain task of Chinese-English chat messages. While our method was initially targeted toward such tasks with less parallel data, we show that it also extends to high resource languages such as Cs-En and De-En where we obtain an improvement of $0.39$ and $0.47$ BLEU scores over the neural machine translation baselines, respectively.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1503.03535v2-abstract-full').style.display = 'none'; document.getElementById('1503.03535v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 12 June, 2015; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 11 March, 2015;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2015.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">9 pages, 2 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1503.01800">arXiv:1503.01800</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1503.01800">pdf</a>, <a href="https://arxiv.org/format/1503.01800">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        EmoNets: Multimodal deep learning approaches for emotion recognition in video
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Kahou%2C+S+E">Samira Ebrahimi Kahou</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Bouthillier%2C+X">Xavier Bouthillier</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Lamblin%2C+P">Pascal Lamblin</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Gulcehre%2C+C">Caglar Gulcehre</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Michalski%2C+V">Vincent Michalski</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Konda%2C+K">Kishore Konda</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Jean%2C+S">Sébastien Jean</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Froumenty%2C+P">Pierre Froumenty</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Dauphin%2C+Y">Yann Dauphin</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Boulanger-Lewandowski%2C+N">Nicolas Boulanger-Lewandowski</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Ferrari%2C+R+C">Raul Chandias Ferrari</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Mirza%2C+M">Mehdi Mirza</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Warde-Farley%2C+D">David Warde-Farley</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Courville%2C+A">Aaron Courville</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Vincent%2C+P">Pascal Vincent</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Memisevic%2C+R">Roland Memisevic</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Pal%2C+C">Christopher Pal</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Bengio%2C+Y">Yoshua Bengio</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1503.01800v2-abstract-short" style="display: inline;">
        The task of the emotion recognition in the wild (EmotiW) Challenge is to assign one of seven emotions to short video clips extracted from Hollywood style movies. The videos depict acted-out emotions under realistic conditions with a large degree of variation in attributes such as pose and illumination, making it worthwhile to explore approaches which consider combinations of features from multiple&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1503.01800v2-abstract-full').style.display = 'inline'; document.getElementById('1503.01800v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1503.01800v2-abstract-full" style="display: none;">
        The task of the emotion recognition in the wild (EmotiW) Challenge is to assign one of seven emotions to short video clips extracted from Hollywood style movies. The videos depict acted-out emotions under realistic conditions with a large degree of variation in attributes such as pose and illumination, making it worthwhile to explore approaches which consider combinations of features from multiple modalities for label assignment. In this paper we present our approach to learning several specialist models using deep learning techniques, each focusing on one modality. Among these are a convolutional neural network, focusing on capturing visual information in detected faces, a deep belief net focusing on the representation of the audio stream, a K-Means based &#34;bag-of-mouths&#34; model, which extracts visual features around the mouth region and a relational autoencoder, which addresses spatio-temporal aspects of videos. We explore multiple methods for the combination of cues from these modalities into one common classifier. This achieves a considerably greater accuracy than predictions from our strongest single-modality classifier. Our method was the winning submission in the 2013 EmotiW challenge and achieved a test set accuracy of 47.67% on the 2014 dataset.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1503.01800v2-abstract-full').style.display = 'none'; document.getElementById('1503.01800v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 29 March, 2015; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 5 March, 2015;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2015.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1502.02367">arXiv:1502.02367</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1502.02367">pdf</a>, <a href="https://arxiv.org/format/1502.02367">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Neural and Evolutionary Computing">cs.NE</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Gated Feedback Recurrent Neural Networks
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Chung%2C+J">Junyoung Chung</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Gulcehre%2C+C">Caglar Gulcehre</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Cho%2C+K">Kyunghyun Cho</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Bengio%2C+Y">Yoshua Bengio</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1502.02367v4-abstract-short" style="display: inline;">
        In this work, we propose a novel recurrent neural network (RNN) architecture. The proposed RNN, gated-feedback RNN (GF-RNN), extends the existing approach of stacking multiple recurrent layers by allowing and controlling signals flowing from upper recurrent layers to lower layers using a global gating unit for each pair of layers. The recurrent signals exchanged between layers are gated adaptively&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1502.02367v4-abstract-full').style.display = 'inline'; document.getElementById('1502.02367v4-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1502.02367v4-abstract-full" style="display: none;">
        In this work, we propose a novel recurrent neural network (RNN) architecture. The proposed RNN, gated-feedback RNN (GF-RNN), extends the existing approach of stacking multiple recurrent layers by allowing and controlling signals flowing from upper recurrent layers to lower layers using a global gating unit for each pair of layers. The recurrent signals exchanged between layers are gated adaptively based on the previous hidden states and the current input. We evaluated the proposed GF-RNN with different types of recurrent units, such as tanh, long short-term memory and gated recurrent units, on the tasks of character-level language modeling and Python program evaluation. Our empirical evaluation of different RNN units, revealed that in both tasks, the GF-RNN outperforms the conventional approaches to build deep stacked RNNs. We suggest that the improvement arises because the GF-RNN can adaptively assign different layers to different timescales and layer-to-layer interactions (including the top-down ones which are not usually present in a stacked RNN) by learning to gate these interactions.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1502.02367v4-abstract-full').style.display = 'none'; document.getElementById('1502.02367v4-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 17 June, 2015; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 9 February, 2015;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2015.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">9 pages, removed appendix</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1412.7419">arXiv:1412.7419</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1412.7419">pdf</a>, <a href="https://arxiv.org/format/1412.7419">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Neural and Evolutionary Computing">cs.NE</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        ADASECANT: Robust Adaptive Secant Method for Stochastic Gradient
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Gulcehre%2C+C">Caglar Gulcehre</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Moczulski%2C+M">Marcin Moczulski</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Bengio%2C+Y">Yoshua Bengio</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1412.7419v5-abstract-short" style="display: inline;">
        Stochastic gradient algorithms have been the main focus of large-scale learning problems and they led to important successes in machine learning. The convergence of SGD depends on the careful choice of learning rate and the amount of the noise in stochastic estimates of the gradients. In this paper, we propose a new adaptive learning rate algorithm, which utilizes curvature information for automat&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1412.7419v5-abstract-full').style.display = 'inline'; document.getElementById('1412.7419v5-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1412.7419v5-abstract-full" style="display: none;">
        Stochastic gradient algorithms have been the main focus of large-scale learning problems and they led to important successes in machine learning. The convergence of SGD depends on the careful choice of learning rate and the amount of the noise in stochastic estimates of the gradients. In this paper, we propose a new adaptive learning rate algorithm, which utilizes curvature information for automatically tuning the learning rates. The information about the element-wise curvature of the loss function is estimated from the local statistics of the stochastic first order gradients. We further propose a new variance reduction technique to speed up the convergence. In our preliminary experiments with deep neural networks, we obtained better performance compared to the popular stochastic gradient algorithms.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1412.7419v5-abstract-full').style.display = 'none'; document.getElementById('1412.7419v5-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 31 October, 2015; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 23 December, 2014;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2014.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">8 pages, 3 figures, ICLR workshop submission</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1412.3555">arXiv:1412.3555</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1412.3555">pdf</a>, <a href="https://arxiv.org/format/1412.3555">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Neural and Evolutionary Computing">cs.NE</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Chung%2C+J">Junyoung Chung</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Gulcehre%2C+C">Caglar Gulcehre</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Cho%2C+K">KyungHyun Cho</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Bengio%2C+Y">Yoshua Bengio</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1412.3555v1-abstract-short" style="display: inline;">
        In this paper we compare different types of recurrent units in recurrent neural networks (RNNs). Especially, we focus on more sophisticated units that implement a gating mechanism, such as a long short-term memory (LSTM) unit and a recently proposed gated recurrent unit (GRU). We evaluate these recurrent units on the tasks of polyphonic music modeling and speech signal modeling. Our experiments re&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1412.3555v1-abstract-full').style.display = 'inline'; document.getElementById('1412.3555v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1412.3555v1-abstract-full" style="display: none;">
        In this paper we compare different types of recurrent units in recurrent neural networks (RNNs). Especially, we focus on more sophisticated units that implement a gating mechanism, such as a long short-term memory (LSTM) unit and a recently proposed gated recurrent unit (GRU). We evaluate these recurrent units on the tasks of polyphonic music modeling and speech signal modeling. Our experiments revealed that these advanced recurrent units are indeed better than more traditional recurrent units such as tanh units. Also, we found GRU to be comparable to LSTM.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1412.3555v1-abstract-full').style.display = 'none'; document.getElementById('1412.3555v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 11 December, 2014; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2014.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Presented in NIPS 2014 Deep Learning and Representation Learning Workshop</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1406.2572">arXiv:1406.2572</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1406.2572">pdf</a>, <a href="https://arxiv.org/format/1406.2572">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Identifying and attacking the saddle point problem in high-dimensional non-convex optimization
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Dauphin%2C+Y">Yann Dauphin</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Pascanu%2C+R">Razvan Pascanu</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Gulcehre%2C+C">Caglar Gulcehre</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Cho%2C+K">Kyunghyun Cho</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Ganguli%2C+S">Surya Ganguli</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Bengio%2C+Y">Yoshua Bengio</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1406.2572v1-abstract-short" style="display: inline;">
        A central challenge to many fields of science and engineering involves minimizing non-convex error functions over continuous, high dimensional spaces. Gradient descent or quasi-Newton methods are almost ubiquitously used to perform such minimizations, and it is often thought that a main source of difficulty for these local methods to find the global minimum is the proliferation of local minima wit&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1406.2572v1-abstract-full').style.display = 'inline'; document.getElementById('1406.2572v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1406.2572v1-abstract-full" style="display: none;">
        A central challenge to many fields of science and engineering involves minimizing non-convex error functions over continuous, high dimensional spaces. Gradient descent or quasi-Newton methods are almost ubiquitously used to perform such minimizations, and it is often thought that a main source of difficulty for these local methods to find the global minimum is the proliferation of local minima with much higher error than the global minimum. Here we argue, based on results from statistical physics, random matrix theory, neural network theory, and empirical evidence, that a deeper and more profound difficulty originates from the proliferation of saddle points, not local minima, especially in high dimensional problems of practical interest. Such saddle points are surrounded by high error plateaus that can dramatically slow down learning, and give the illusory impression of the existence of a local minimum. Motivated by these arguments, we propose a new approach to second-order optimization, the saddle-free Newton method, that can rapidly escape high dimensional saddle points, unlike gradient descent and quasi-Newton methods. We apply this algorithm to deep or recurrent neural network training, and provide numerical evidence for its superior optimization performance.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1406.2572v1-abstract-full').style.display = 'none'; document.getElementById('1406.2572v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 10 June, 2014; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2014.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">The theoretical review and analysis in this article draw heavily from arXiv:1405.4604 [cs.LG]</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1406.1078">arXiv:1406.1078</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1406.1078">pdf</a>, <a href="https://arxiv.org/format/1406.1078">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Neural and Evolutionary Computing">cs.NE</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Cho%2C+K">Kyunghyun Cho</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=van+Merrienboer%2C+B">Bart van Merrienboer</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Gulcehre%2C+C">Caglar Gulcehre</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Bahdanau%2C+D">Dzmitry Bahdanau</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Bougares%2C+F">Fethi Bougares</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Schwenk%2C+H">Holger Schwenk</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Bengio%2C+Y">Yoshua Bengio</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1406.1078v3-abstract-short" style="display: inline;">
        In this paper, we propose a novel neural network model called RNN Encoder-Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixed-length vector representation, and the other decodes the representation into another sequence of symbols. The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1406.1078v3-abstract-full').style.display = 'inline'; document.getElementById('1406.1078v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1406.1078v3-abstract-full" style="display: none;">
        In this paper, we propose a novel neural network model called RNN Encoder-Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixed-length vector representation, and the other decodes the representation into another sequence of symbols. The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence. The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder-Decoder as an additional feature in the existing log-linear model. Qualitatively, we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1406.1078v3-abstract-full').style.display = 'none'; document.getElementById('1406.1078v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 2 September, 2014; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 3 June, 2014;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2014.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">EMNLP 2014</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1312.6026">arXiv:1312.6026</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1312.6026">pdf</a>, <a href="https://arxiv.org/format/1312.6026">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Neural and Evolutionary Computing">cs.NE</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        How to Construct Deep Recurrent Neural Networks
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Pascanu%2C+R">Razvan Pascanu</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Gulcehre%2C+C">Caglar Gulcehre</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Cho%2C+K">Kyunghyun Cho</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Bengio%2C+Y">Yoshua Bengio</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1312.6026v5-abstract-short" style="display: inline;">
        In this paper, we explore different ways to extend a recurrent neural network (RNN) to a \textit{deep} RNN. We start by arguing that the concept of depth in an RNN is not as clear as it is in feedforward neural networks. By carefully analyzing and understanding the architecture of an RNN, however, we find three points of an RNN which may be made deeper; (1) input-to-hidden function, (2) hidden-to-&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1312.6026v5-abstract-full').style.display = 'inline'; document.getElementById('1312.6026v5-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1312.6026v5-abstract-full" style="display: none;">
        In this paper, we explore different ways to extend a recurrent neural network (RNN) to a \textit{deep} RNN. We start by arguing that the concept of depth in an RNN is not as clear as it is in feedforward neural networks. By carefully analyzing and understanding the architecture of an RNN, however, we find three points of an RNN which may be made deeper; (1) input-to-hidden function, (2) hidden-to-hidden transition and (3) hidden-to-output function. Based on this observation, we propose two novel architectures of a deep RNN which are orthogonal to an earlier attempt of stacking multiple recurrent layers to build a deep RNN (Schmidhuber, 1992; El Hihi and Bengio, 1996). We provide an alternative interpretation of these deep RNNs using a novel framework based on neural operators. The proposed deep RNNs are empirically evaluated on the tasks of polyphonic music prediction and language modeling. The experimental result supports our claim that the proposed deep RNNs benefit from the depth and outperform the conventional, shallow RNNs.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1312.6026v5-abstract-full').style.display = 'none'; document.getElementById('1312.6026v5-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 24 April, 2014; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 20 December, 2013;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2013.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted at ICLR 2014 (Conference Track). 10-page text + 3-page references</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1311.1780">arXiv:1311.1780</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1311.1780">pdf</a>, <a href="https://arxiv.org/format/1311.1780">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Neural and Evolutionary Computing">cs.NE</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Learned-Norm Pooling for Deep Feedforward and Recurrent Neural Networks
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Gulcehre%2C+C">Caglar Gulcehre</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Cho%2C+K">Kyunghyun Cho</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Pascanu%2C+R">Razvan Pascanu</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Bengio%2C+Y">Yoshua Bengio</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1311.1780v7-abstract-short" style="display: inline;">
        In this paper we propose and investigate a novel nonlinear unit, called $L_p$ unit, for deep neural networks. The proposed $L_p$ unit receives signals from several projections of a subset of units in the layer below and computes a normalized $L_p$ norm. We notice two interesting interpretations of the $L_p$ unit. First, the proposed unit can be understood as a generalization of a number of convent&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1311.1780v7-abstract-full').style.display = 'inline'; document.getElementById('1311.1780v7-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1311.1780v7-abstract-full" style="display: none;">
        In this paper we propose and investigate a novel nonlinear unit, called $L_p$ unit, for deep neural networks. The proposed $L_p$ unit receives signals from several projections of a subset of units in the layer below and computes a normalized $L_p$ norm. We notice two interesting interpretations of the $L_p$ unit. First, the proposed unit can be understood as a generalization of a number of conventional pooling operators such as average, root-mean-square and max pooling widely used in, for instance, convolutional neural networks (CNN), HMAX models and neocognitrons. Furthermore, the $L_p$ unit is, to a certain degree, similar to the recently proposed maxout unit (Goodfellow et al., 2013) which achieved the state-of-the-art object recognition results on a number of benchmark datasets. Secondly, we provide a geometrical interpretation of the activation function based on which we argue that the $L_p$ unit is more efficient at representing complex, nonlinear separating boundaries. Each $L_p$ unit defines a superelliptic boundary, with its exact shape defined by the order $p$. We claim that this makes it possible to model arbitrarily shaped, curved boundaries more efficiently by combining a few $L_p$ units of different orders. This insight justifies the need for learning different orders for each unit in the model. We empirically evaluate the proposed $L_p$ units on a number of datasets and show that multilayer perceptrons (MLP) consisting of the $L_p$ units achieve the state-of-the-art results on a number of benchmark datasets. Furthermore, we evaluate the proposed $L_p$ unit on the recently proposed deep recurrent neural networks (RNN).
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1311.1780v7-abstract-full').style.display = 'none'; document.getElementById('1311.1780v7-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 1 September, 2014; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 7 November, 2013;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2013.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">ECML/PKDD 2014</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1301.4083">arXiv:1301.4083</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1301.4083">pdf</a>, <a href="https://arxiv.org/format/1301.4083">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Neural and Evolutionary Computing">cs.NE</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Knowledge Matters: Importance of Prior Information for Optimization
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=G%C3%BCl%C3%A7ehre%2C+%C3%87">Çağlar Gülçehre</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Bengio%2C+Y">Yoshua Bengio</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1301.4083v6-abstract-short" style="display: inline;">
        We explore the effect of introducing prior information into the intermediate level of neural networks for a learning task on which all the state-of-the-art machine learning algorithms tested failed to learn. We motivate our work from the hypothesis that humans learn such intermediate concepts from other individuals via a form of supervision or guidance using a curriculum. The experiments we have c&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1301.4083v6-abstract-full').style.display = 'inline'; document.getElementById('1301.4083v6-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1301.4083v6-abstract-full" style="display: none;">
        We explore the effect of introducing prior information into the intermediate level of neural networks for a learning task on which all the state-of-the-art machine learning algorithms tested failed to learn. We motivate our work from the hypothesis that humans learn such intermediate concepts from other individuals via a form of supervision or guidance using a curriculum. The experiments we have conducted provide positive evidence in favor of this hypothesis. In our experiments, a two-tiered MLP architecture is trained on a dataset with 64x64 binary inputs images, each image with three sprites. The final task is to decide whether all the sprites are the same or one of them is different. Sprites are pentomino tetris shapes and they are placed in an image with different locations using scaling and rotation transformations. The first part of the two-tiered MLP is pre-trained with intermediate-level targets being the presence of sprites at each location, while the second part takes the output of the first part as input and predicts the final task&#39;s target binary event. The two-tiered MLP architecture, with a few tens of thousand examples, was able to learn the task perfectly, whereas all other algorithms (include unsupervised pre-training, but also traditional algorithms like SVMs, decision trees and boosting) all perform no better than chance. We hypothesize that the optimization difficulty involved when the intermediate pre-training is not performed is due to the {\em composition} of two highly non-linear tasks. Our findings are also consistent with hypotheses on cultural learning inspired by the observations of optimization problems with deep learning, presumably because of effective local minima.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1301.4083v6-abstract-full').style.display = 'none'; document.getElementById('1301.4083v6-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 13 July, 2013; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 17 January, 2013;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2013.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">37 Pages, 5 figures, 5 tables JMLR Special Topics on Representation Learning Submission</span>
    </p>
    

    

    
  </li>

</ol>


  


      <div class="is-hidden-tablet">
        <!-- feedback for mobile only -->
        <span class="help" style="display: inline-block;"><a href="https://github.com/arXiv/arxiv-search/releases">Search v0.5.6 released 2020-02-24</a>&nbsp;&nbsp;</span>
        <button class="button is-small" id="feedback-button">Feedback?</button>
      </div>
    </div>

  </main>
  <footer>
    
    <div class="columns is-desktop" role="navigation" aria-label="Secondary">
  <!-- MetaColumn 1 -->
  <div class="column">
    <div class="columns">
      <div class="column">
        <ul class="nav-spaced">
          <li><a href="https://arxiv.org/about">About</a></li>
          <li><a href="https://arxiv.org/help">Help</a></li>
        </ul>
      </div>
      <div class="column">
        <ul class="nav-spaced">
          <li>
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
            <a href="https://arxiv.org/help/contact"> Contact</a>
          </li>
          <li>
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
            <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
          </li>
        </ul>
      </div>
    </div>
  </div> <!-- end MetaColumn 1 -->
  <!-- MetaColumn 2 -->
  <div class="column">
    <div class="columns">
      <div class="column">
        <ul class="nav-spaced">
          <li><a href="https://arxiv.org/help/license">Copyright</a></li>
          <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
        </ul>
      </div>
      <div class="column sorry-app-links">
        <ul class="nav-spaced">
          <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
          <li>
            <p class="help">
              <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
              Get status notifications via
              <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
              or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
            </p>
          </li>
        </ul>
      </div>
    </div>
  </div> <!-- end MetaColumn 2 -->
</div>
    
  </footer>
  </body>
</html>