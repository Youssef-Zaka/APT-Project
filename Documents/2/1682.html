<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<!-- new favicon config and versions by realfavicongenerator.net -->
<link rel="apple-touch-icon" sizes="180x180" href="https://static.arxiv.org/static/base/0.17.4.post2/images/icons/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://static.arxiv.org/static/base/0.17.4.post2/images/icons/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="https://static.arxiv.org/static/base/0.17.4.post2/images/icons/favicon-16x16.png">
<link rel="manifest" href="https://static.arxiv.org/static/base/0.17.4.post2/images/icons/site.webmanifest">
<link rel="mask-icon" href="https://static.arxiv.org/static/base/0.17.4.post2/images/icons/safari-pinned-tab.svg" color="#b31b1b">
<link rel="shortcut icon" href="https://static.arxiv.org/static/base/0.17.4.post2/images/icons/favicon.ico">
<meta name="msapplication-TileColor" content="#b31b1b">
<meta name="msapplication-config" content="images/icons/browserconfig.xml">
<meta name="theme-color" content="#b31b1b">
<!-- end favicon config -->
<title>Search | arXiv e-print repository</title>
<script defer src="https://static.arxiv.org/static/base/0.17.4.post2/fontawesome-free-5.11.2-web/js/all.js"></script>
<link rel="stylesheet" href="https://static.arxiv.org/static/base/0.17.4.post2/css/arxivstyle.css" />
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    messageStyle: "none",
    extensions: ["tex2jax.js"],
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
      processEscapes: true,
      ignoreClass: '.*',
      processClass: 'mathjax.*'
    },
    TeX: {
        extensions: ["AMSmath.js", "AMSsymbols.js", "noErrors.js"],
        noErrors: {
          inlineDelimiters: ["$","$"],
          multiLine: false,
          style: {
            "font-size": "normal",
            "border": ""
          }
        }
    },
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>
<script src='//static.arxiv.org/MathJax-2.7.3/MathJax.js'></script>
<script src="https://static.arxiv.org/static/base/0.17.4.post2/js/notification.js"></script>

    
  <link rel="stylesheet" href="https://static.arxiv.org/static/search/0.5.6/css/bulma-tooltip.min.css" />
  <link rel="stylesheet" href="https://static.arxiv.org/static/search/0.5.6/css/search.css" />
  <script
    src="https://code.jquery.com/jquery-3.2.1.slim.min.js"
    integrity="sha256-k2WSCIexGzOj3Euiig+TlR8gA0EmPjuc79OEeY5L45g="
    crossorigin="anonymous"></script>

  <script src="https://static.arxiv.org/static/search/0.5.6/js/fieldset.js"></script>
  <style>
  radio#cf-customfield_11400 {
    display: none;
  }
  </style>
  <script type="text/javascript" src="https://arxiv-org.atlassian.net/s/d41d8cd98f00b204e9800998ecf8427e-T/-tqqyqk/b/20/a44af77267a987a660377e5c46e0fb64/_/download/batch/com.atlassian.jira.collector.plugin.jira-issue-collector-plugin:issuecollector/com.atlassian.jira.collector.plugin.jira-issue-collector-plugin:issuecollector.js?locale=en-US&collectorId=3b3dcb4c"></script>

    <script type="text/javascript">
    window.ATL_JQ_PAGE_PROPS =  {
    	"triggerFunction": function(showCollectorDialog) {
    		//Requires that jQuery is available!
    		$("#feedback-button").click(function(e) {
    			e.preventDefault();
    			showCollectorDialog();
    		});
    	},
      fieldValues: {
        "components": ["16000"],  // Search component.
        "versions": ["14260"],  // Release search-0.5.6
        "customfield_11401": window.location.href
      }
    };
    </script>

  </head>
  <body>
  
  
  <header><a href="#main-container" class="is-sr-only">Skip to main content</a>
    
    <!-- contains Cornell logo and sponsor statement -->
<div class="attribution level is-marginless" role="banner">
  <div class="level-left">
    <a class="level-item" href="https://cornell.edu/"><img src="https://static.arxiv.org/static/base/0.17.4.post2/images/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" aria-label="logo" /></a>
  </div>
  <div class="level-right is-marginless"><p class="sponsors level-item is-marginless"><a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a></p></div>
</div>
<!-- contains arXiv identity and search bar -->
<div class="identity level is-marginless">
  <div class="level-left">
    <div class="level-item">
      <a class="arxiv" href="https://arxiv.org/" aria-label="arxiv-logo">
        <img src="https://static.arxiv.org/static/base/0.17.4.post2/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;"/>
      </a>
    </div>
  </div>
  
  <div class="search-block level-right">
    <form class="level-item mini-search" method="GET" action="https://arxiv.org/search">
      <div class="field has-addons">
        <div class="control">
          <input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" />
          <p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
        </div>
        <div class="control">
          <div class="select is-small">
            <select name="searchtype" aria-label="Field to search">
              <option value="all" selected="selected">All fields</option>
              <option value="title">Title</option>
              <option value="author">Author</option>
              <option value="abstract">Abstract</option>
              <option value="comments">Comments</option>
              <option value="journal_ref">Journal reference</option>
              <option value="acm_class">ACM classification</option>
              <option value="msc_class">MSC classification</option>
              <option value="report_num">Report number</option>
              <option value="paper_id">arXiv identifier</option>
              <option value="doi">DOI</option>
              <option value="orcid">ORCID</option>
              <option value="author_id">arXiv author ID</option>
              <option value="help">Help pages</option>
              <option value="full_text">Full text</option>
            </select>
          </div>
        </div>
        <input type="hidden" name="source" value="header">
        <button class="button is-small is-cul-darker">Search</button>
      </div>
    </form>
  </div>
</div> <!-- closes identity -->

<div class="container">
    <div class="user-tools is-size-7 has-text-right has-text-weight-bold" role="navigation" aria-label="User menu">
      <a href="https://arxiv.org/login">Login</a>
    </div>
</div>
    
  </header>
  <main class="container" id="main-container">
    


    
  <div class="level is-marginless">
    <div class="level-left">
      <h1 class="title is-clearfix">
    
        Showing 1&ndash;50 of 76 results for author: <span class="mathjax">Goel, S</span>
    
</h1>
    </div>
    <div class="level-right is-hidden-mobile">
      <!-- feedback for mobile is moved to footer -->
      <span class="help" style="display: inline-block;"><a href="https://github.com/arXiv/arxiv-search/releases">Search v0.5.6 released 2020-02-24</a>&nbsp;&nbsp;</span>
      <button class="button is-small" id="feedback-button">Feedback?</button>
    </div>
  </div>
    <div class="content">
      
  <form method="GET" action="/search/cs"  aria-role="search">
    
      Searching in archive <strong>cs</strong>. <a href="/search/?searchtype=author&amp;query=Goel%2C+S">Search in all archives.</a>
    

    
    <div class="field has-addons-tablet">
      <div class="control is-expanded">
        <label for="query" class="hidden-label">Search term or terms</label>
        
          <input class="input is-medium" id="query" name="query" placeholder="Search term..." type="text" value="Goel, S">
        
        
      </div>
      <div class="select control is-medium">
        <label class="is-hidden" for="searchtype">Field</label>
        <select class="is-medium" id="searchtype" name="searchtype"><option value="all">All fields</option><option value="title">Title</option><option selected value="author">Author(s)</option><option value="abstract">Abstract</option><option value="comments">Comments</option><option value="journal_ref">Journal reference</option><option value="acm_class">ACM classification</option><option value="msc_class">MSC classification</option><option value="report_num">Report number</option><option value="paper_id">arXiv identifier</option><option value="doi">DOI</option><option value="orcid">ORCID</option><option value="license">License (URI)</option><option value="author_id">arXiv author ID</option><option value="help">Help pages</option><option value="full_text">Full text</option></select>
      </div>
      <div class="control">
          <button class="button is-link is-medium">Search</button>
      </div>
    </div>
    <div class="field">
      <div class="control is-size-7">
        
        <label class="radio">
          <input checked id="abstracts-0" name="abstracts" type="radio" value="show"> Show abstracts
        </label>
        
        <label class="radio">
          <input id="abstracts-1" name="abstracts" type="radio" value="hide"> Hide abstracts
        </label>
        
      </div>
    </div>
    <div class="is-clearfix" style="height: 2.5em"> 
      <div class="is-pulled-right">
        
        <a href="/search/advanced?terms-0-term=Goel%2C+S&amp;terms-0-field=author&amp;size=50&amp;order=-announced_date_first">Advanced Search</a>
        
      </div>
    </div>
    <input type="hidden" name="order" value="-announced_date_first">
    <input type="hidden" name="size" value="50">
  </form>

  

  
      
<div class="level breathe-horizontal">
  <div class="level-left">
    <form method="GET" action="/search/">
      <div style="display: none;">
        
          
            <select id="searchtype" name="searchtype"><option value="all">All fields</option><option value="title">Title</option><option selected value="author">Author(s)</option><option value="abstract">Abstract</option><option value="comments">Comments</option><option value="journal_ref">Journal reference</option><option value="acm_class">ACM classification</option><option value="msc_class">MSC classification</option><option value="report_num">Report number</option><option value="paper_id">arXiv identifier</option><option value="doi">DOI</option><option value="orcid">ORCID</option><option value="license">License (URI)</option><option value="author_id">arXiv author ID</option><option value="help">Help pages</option><option value="full_text">Full text</option></select>
          
        
          
            <input id="query" name="query" type="text" value="Goel, S">
          
        
          
        
          
        
          
            <ul id="abstracts"><li><input checked id="abstracts-0" name="abstracts" type="radio" value="show"> <label for="abstracts-0">Show abstracts</label></li><li><input id="abstracts-1" name="abstracts" type="radio" value="hide"> <label for="abstracts-1">Hide abstracts</label></li></ul>
          
        
      </div>
      <div class="box field is-grouped is-grouped-multiline level-item">
        <div class="control">
          <span class="select is-small">
            <select id="size" name="size"><option value="25">25</option><option selected value="50">50</option><option value="100">100</option><option value="200">200</option></select>
          </span>
          <label for="size">results per page</label>.
        </div>
        <div class="control">
          <label for="order">Sort results by</label>
          <span class="select is-small">
            <select id="order" name="order"><option selected value="-announced_date_first">Announcement date (newest first)</option><option value="announced_date_first">Announcement date (oldest first)</option><option value="-submitted_date">Submission date (newest first)</option><option value="submitted_date">Submission date (oldest first)</option><option value="">Relevance</option></select>
          </span>
        </div>
        <div class="control">
          <button class="button is-small is-link">Go</button>
        </div>
      </div>
    </form>
  </div>
</div>
      


  <nav class="pagination is-small is-centered breathe-horizontal" role="navigation" aria-label="pagination">
    
    <a href=""
      class="pagination-previous is-invisible">Previous
    </a>
    
    
      <a href="/search/?searchtype=author&amp;query=Goel%2C+S&amp;start=50"
        class="pagination-next" >Next
      </a>
    
    <ul class="pagination-list">

      <li>
        <a href="/search/?searchtype=author&amp;query=Goel%2C+S&amp;start=0"
          class="pagination-link is-current"
          aria-label="Goto page 1">1
        </a>
      </li>

      
        
        <li>
          <a href="/search/?searchtype=author&amp;query=Goel%2C+S&amp;start=50"
            class="pagination-link "
            aria-label="Page 2"
            aria-current="page">2
          </a>
        </li>
        
      
    </ul>
  </nav>
  



<ol class="breathe-horizontal" start="1"> 


  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2203.03286">arXiv:2203.03286</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2203.03286">pdf</a>, <a href="https://arxiv.org/ps/2203.03286">ps</a>, <a href="https://arxiv.org/format/2203.03286">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Logic">math.LO</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Logic in Computer Science">cs.LO</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Topological duality for distributive lattices, and applications
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Gehrke%2C+M">Mai Gehrke</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=van+Gool%2C+S">Sam van Gool</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2203.03286v1-abstract-short" style="display: inline;">
        This book is a course in Stone-Priestley duality theory, with applications to logic and theoretical computer science. Our target audience are graduate students and researchers in mathematics and computer science. Our aim is to get in a fairly full palette of duality tools as directly and quickly as possible, then to illustrate and further elaborate these tools within the setting of three emblemati&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2203.03286v1-abstract-full').style.display = 'inline'; document.getElementById('2203.03286v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2203.03286v1-abstract-full" style="display: none;">
        This book is a course in Stone-Priestley duality theory, with applications to logic and theoretical computer science. Our target audience are graduate students and researchers in mathematics and computer science. Our aim is to get in a fairly full palette of duality tools as directly and quickly as possible, then to illustrate and further elaborate these tools within the setting of three emblematic applications: semantics of propositional logics, domain theory in logical form, and the theory of profinite monoids for the study of regular languages and automata. This preprint version contains the first part of the book, a graduate level `crash course&#39; in duality theory as it is practiced now.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2203.03286v1-abstract-full').style.display = 'none'; document.getElementById('2203.03286v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 March, 2022; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2022.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2202.14037">arXiv:2202.14037</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2202.14037">pdf</a>, <a href="https://arxiv.org/format/2202.14037">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Understanding Contrastive Learning Requires Incorporating Inductive Biases
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Saunshi%2C+N">Nikunj Saunshi</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Ash%2C+J">Jordan Ash</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Goel%2C+S">Surbhi Goel</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Misra%2C+D">Dipendra Misra</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+C">Cyril Zhang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Arora%2C+S">Sanjeev Arora</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Kakade%2C+S">Sham Kakade</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Krishnamurthy%2C+A">Akshay Krishnamurthy</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2202.14037v1-abstract-short" style="display: inline;">
        Contrastive learning is a popular form of self-supervised learning that encourages augmentations (views) of the same input to have more similar representations compared to augmentations of different inputs. Recent attempts to theoretically explain the success of contrastive learning on downstream classification tasks prove guarantees depending on properties of {\em augmentations} and the value of&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2202.14037v1-abstract-full').style.display = 'inline'; document.getElementById('2202.14037v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2202.14037v1-abstract-full" style="display: none;">
        Contrastive learning is a popular form of self-supervised learning that encourages augmentations (views) of the same input to have more similar representations compared to augmentations of different inputs. Recent attempts to theoretically explain the success of contrastive learning on downstream classification tasks prove guarantees depending on properties of {\em augmentations} and the value of {\em contrastive loss} of representations. We demonstrate that such analyses, that ignore {\em inductive biases} of the function class and training algorithm, cannot adequately explain the success of contrastive learning, even {\em provably} leading to vacuous guarantees in some settings. Extensive experiments on image and text domains highlight the ubiquity of this problem -- different function classes and algorithms behave very differently on downstream tasks, despite having the same augmentations and contrastive losses. Theoretical analysis is presented for the class of linear representations, where incorporating inductive biases of the function class allows contrastive learning to work with less stringent conditions compared to prior analyses.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2202.14037v1-abstract-full').style.display = 'none'; document.getElementById('2202.14037v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 28 February, 2022; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2022.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2202.01327">arXiv:2202.01327</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2202.01327">pdf</a>, <a href="https://arxiv.org/format/2202.01327">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Methodology">stat.ME</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Adaptive Sampling Strategies to Construct Equitable Training Datasets
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Cai%2C+W">William Cai</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Encarnacion%2C+R">Ro Encarnacion</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Chern%2C+B">Bobbie Chern</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Corbett-Davies%2C+S">Sam Corbett-Davies</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Bogen%2C+M">Miranda Bogen</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Bergman%2C+S">Stevie Bergman</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Goel%2C+S">Sharad Goel</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2202.01327v1-abstract-short" style="display: inline;">
        In domains ranging from computer vision to natural language processing, machine learning models have been shown to exhibit stark disparities, often performing worse for members of traditionally underserved groups. One factor contributing to these performance gaps is a lack of representation in the data the models are trained on. It is often unclear, however, how to operationalize representativenes&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2202.01327v1-abstract-full').style.display = 'inline'; document.getElementById('2202.01327v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2202.01327v1-abstract-full" style="display: none;">
        In domains ranging from computer vision to natural language processing, machine learning models have been shown to exhibit stark disparities, often performing worse for members of traditionally underserved groups. One factor contributing to these performance gaps is a lack of representation in the data the models are trained on. It is often unclear, however, how to operationalize representativeness in specific applications. Here we formalize the problem of creating equitable training datasets, and propose a statistical framework for addressing this problem. We consider a setting where a model builder must decide how to allocate a fixed data collection budget to gather training data from different subgroups. We then frame dataset creation as a constrained optimization problem, in which one maximizes a function of group-specific performance metrics based on (estimated) group-specific learning rates and costs per sample. This flexible approach incorporates preferences of model-builders and other stakeholders, as well as the statistical properties of the learning task. When data collection decisions are made sequentially, we show that under certain conditions this optimization problem can be efficiently solved even without prior knowledge of the learning rates. To illustrate our approach, we conduct a simulation study of polygenic risk scores on synthetic genomic data -- an application domain that often suffers from non-representative data collection. We find that our adaptive sampling strategy outperforms several common data collection heuristics, including equal and proportional sampling, demonstrating the value of strategic dataset design for building equitable models.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2202.01327v1-abstract-full').style.display = 'none'; document.getElementById('2202.01327v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 31 January, 2022; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2022.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">15 pages, 2 figures</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          I.2.0; F.2.0
        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2201.06640">arXiv:2201.06640</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2201.06640">pdf</a>, <a href="https://arxiv.org/format/2201.06640">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Evaluating Inexact Unlearning Requires Revisiting Forgetting
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Goel%2C+S">Shashwat Goel</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Prabhu%2C+A">Ameya Prabhu</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Kumaraguru%2C+P">Ponnurangam Kumaraguru</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2201.06640v2-abstract-short" style="display: inline;">
        Existing methods in inexact unlearning are evaluated by measuring indistinguishability from models retrained after removing the deletion set. We argue that achieving indistinguishability is unnecessary and its practical relaxations are insufficient. We formulate the goal of unlearning as forgetting all information specific to the deletion set while maintaining high utility and resource efficiency.&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2201.06640v2-abstract-full').style.display = 'inline'; document.getElementById('2201.06640v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2201.06640v2-abstract-full" style="display: none;">
        Existing methods in inexact unlearning are evaluated by measuring indistinguishability from models retrained after removing the deletion set. We argue that achieving indistinguishability is unnecessary and its practical relaxations are insufficient. We formulate the goal of unlearning as forgetting all information specific to the deletion set while maintaining high utility and resource efficiency.
  We introduce a novel test for forgetting called Interclass Confusion (IC). Despite being a black-box test, IC can investigate whether information from the deletion set was erased until the early layers of the network. We analyze two aspects of forgetting: (i) memorization and (ii) property generalization. We empirically show that two simple unlearning methods, exact-unlearning and catastrophic-forgetting the final k layers of a network, outperforms prior unlearning methods when scaled to large deletion sets. Overall, we believe our formulation and the IC test will guide the design of better unlearning algorithms.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2201.06640v2-abstract-full').style.display = 'none'; document.getElementById('2201.06640v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 23 February, 2022; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 17 January, 2022;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2022.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2201.03089">arXiv:2201.03089</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2201.03089">pdf</a>, <a href="https://arxiv.org/format/2201.03089">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Logic in Computer Science">cs.LO</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Formal Languages and Automata Theory">cs.FL</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        First-order separation over countable ordinals
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Colcombet%2C+T">Thomas Colcombet</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=van+Gool%2C+S">Sam van Gool</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Morvan%2C+R">Rémi Morvan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2201.03089v1-abstract-short" style="display: inline;">
        We show that the existence of a first-order formula separating two monadic second order formulas over countable ordinal words is decidable. This extends the work of Henckell and Almeida on finite words, and of Place and Zeitoun on $ω$-words. For this, we develop the algebraic concept of monoid (resp. $ω$-semigroup, resp. ordinal monoid) with aperiodic merge, an extension of monoids (resp. $ω$-semi&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2201.03089v1-abstract-full').style.display = 'inline'; document.getElementById('2201.03089v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2201.03089v1-abstract-full" style="display: none;">
        We show that the existence of a first-order formula separating two monadic second order formulas over countable ordinal words is decidable. This extends the work of Henckell and Almeida on finite words, and of Place and Zeitoun on $ω$-words. For this, we develop the algebraic concept of monoid (resp. $ω$-semigroup, resp. ordinal monoid) with aperiodic merge, an extension of monoids (resp. $ω$-semigroup, resp. ordinal monoid) that explicitly includes a new operation capturing the loss of precision induced by first-order indistinguishability. We also show the computability of FO-pointlike sets, and the decidability of the covering problem for first-order logic on countable ordinal words.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2201.03089v1-abstract-full').style.display = 'none'; document.getElementById('2201.03089v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 9 January, 2022; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2022.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2110.13745">arXiv:2110.13745</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2110.13745">pdf</a>, <a href="https://arxiv.org/format/2110.13745">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Human-Computer Interaction">cs.HC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        PARIS: Personalized Activity Recommendation for Improving Sleep Quality
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Singh%2C+M">Meghna Singh</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Goel%2C+S">Saksham Goel</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Mohan%2C+A">Abhiraj Mohan</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Kazaglis%2C+L">Louis Kazaglis</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Srivastava%2C+J">Jaideep Srivastava</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2110.13745v1-abstract-short" style="display: inline;">
        The quality of sleep has a deep impact on people&#39;s physical and mental health. People with insufficient sleep are more likely to report physical and mental distress, activity limitation, anxiety, and pain. Moreover, in the past few years, there has been an explosion of applications and devices for activity monitoring and health tracking. Signals collected from these wearable devices can be used to&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2110.13745v1-abstract-full').style.display = 'inline'; document.getElementById('2110.13745v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2110.13745v1-abstract-full" style="display: none;">
        The quality of sleep has a deep impact on people&#39;s physical and mental health. People with insufficient sleep are more likely to report physical and mental distress, activity limitation, anxiety, and pain. Moreover, in the past few years, there has been an explosion of applications and devices for activity monitoring and health tracking. Signals collected from these wearable devices can be used to study and improve sleep quality. In this paper, we utilize the relationship between physical activity and sleep quality to find ways of assisting people improve their sleep using machine learning techniques. People usually have several behavior modes that their bio-functions can be divided into. Performing time series clustering on activity data, we find cluster centers that would correlate to the most evident behavior modes for a specific subject. Activity recipes are then generated for good sleep quality for each behavior mode within each cluster. These activity recipes are supplied to an activity recommendation engine for suggesting a mix of relaxed to intense activities to subjects during their daily routines. The recommendations are further personalized based on the subjects&#39; lifestyle constraints, i.e. their age, gender, body mass index (BMI), resting heart rate, etc, with the objective of the recommendation being the improvement of that night&#39;s quality of sleep. This would in turn serve a longer-term health objective, like lowering heart rate, improving the overall quality of sleep, etc.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2110.13745v1-abstract-full').style.display = 'none'; document.getElementById('2110.13745v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 26 October, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">18 pages, 7 figures, Submitted to UMUAI: Special Issue on Recommender Systems for Health and Wellbeing, 2020</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2110.11202">arXiv:2110.11202</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2110.11202">pdf</a>, <a href="https://arxiv.org/format/2110.11202">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Anti-Concentrated Confidence Bonuses for Scalable Exploration
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Ash%2C+J+T">Jordan T. Ash</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+C">Cyril Zhang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Goel%2C+S">Surbhi Goel</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Krishnamurthy%2C+A">Akshay Krishnamurthy</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Kakade%2C+S">Sham Kakade</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2110.11202v2-abstract-short" style="display: inline;">
        Intrinsic rewards play a central role in handling the exploration-exploitation trade-off when designing sequential decision-making algorithms, in both foundational theory and state-of-the-art deep reinforcement learning. The LinUCB algorithm, a centerpiece of the stochastic linear bandits literature, prescribes an elliptical bonus which addresses the challenge of leveraging shared information in l&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2110.11202v2-abstract-full').style.display = 'inline'; document.getElementById('2110.11202v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2110.11202v2-abstract-full" style="display: none;">
        Intrinsic rewards play a central role in handling the exploration-exploitation trade-off when designing sequential decision-making algorithms, in both foundational theory and state-of-the-art deep reinforcement learning. The LinUCB algorithm, a centerpiece of the stochastic linear bandits literature, prescribes an elliptical bonus which addresses the challenge of leveraging shared information in large action spaces. This bonus scheme cannot be directly transferred to high-dimensional exploration problems, however, due to the computational cost of maintaining the inverse covariance matrix of action features. We introduce \emph{anti-concentrated confidence bounds} for efficiently approximating the elliptical bonus, using an ensemble of regressors trained to predict random noise from policy network-derived features. Using this approximation, we obtain stochastic linear bandit algorithms which obtain $\tilde O(d \sqrt{T})$ regret bounds for $\mathrm{poly}(d)$ fixed actions. We develop a practical variant for deep reinforcement learning that is competitive with contemporary intrinsic reward heuristics on Atari benchmarks.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2110.11202v2-abstract-full').style.display = 'none'; document.getElementById('2110.11202v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 11 April, 2022; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 21 October, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2021.
      
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        International Conference on Learning Representations 2022
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2110.10090">arXiv:2110.10090</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2110.10090">pdf</a>, <a href="https://arxiv.org/format/2110.10090">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Inductive Biases and Variable Creation in Self-Attention Mechanisms
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Edelman%2C+B+L">Benjamin L. Edelman</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Goel%2C+S">Surbhi Goel</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Kakade%2C+S">Sham Kakade</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+C">Cyril Zhang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2110.10090v1-abstract-short" style="display: inline;">
        Self-attention, an architectural motif designed to model long-range interactions in sequential data, has driven numerous recent breakthroughs in natural language processing and beyond. This work provides a theoretical analysis of the inductive biases of self-attention modules, where our focus is to rigorously establish which functions and long-range dependencies self-attention blocks prefer to rep&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2110.10090v1-abstract-full').style.display = 'inline'; document.getElementById('2110.10090v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2110.10090v1-abstract-full" style="display: none;">
        Self-attention, an architectural motif designed to model long-range interactions in sequential data, has driven numerous recent breakthroughs in natural language processing and beyond. This work provides a theoretical analysis of the inductive biases of self-attention modules, where our focus is to rigorously establish which functions and long-range dependencies self-attention blocks prefer to represent. Our main result shows that bounded-norm Transformer layers create sparse variables: they can represent sparse functions of the input sequence, with sample complexity scaling only logarithmically with the context length. Furthermore, we propose new experimental protocols to support this analysis and to guide the practice of training Transformers, built around the large body of work on provably learning sparse Boolean functions.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2110.10090v1-abstract-full').style.display = 'none'; document.getElementById('2110.10090v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 19 October, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2110.06199">arXiv:2110.06199</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2110.06199">pdf</a>, <a href="https://arxiv.org/format/2110.06199">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Graphics">cs.GR</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        ABO: Dataset and Benchmarks for Real-World 3D Object Understanding
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Collins%2C+J">Jasmine Collins</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Goel%2C+S">Shubham Goel</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Luthra%2C+A">Achleshwar Luthra</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Xu%2C+L">Leon Xu</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Deng%2C+K">Kenan Deng</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+X">Xi Zhang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Vicente%2C+T+F+Y">Tomas F. Yago Vicente</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Arora%2C+H">Himanshu Arora</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Dideriksen%2C+T">Thomas Dideriksen</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Guillaumin%2C+M">Matthieu Guillaumin</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Malik%2C+J">Jitendra Malik</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2110.06199v1-abstract-short" style="display: inline;">
        We introduce Amazon-Berkeley Objects (ABO), a new large-scale dataset of product images and 3D models corresponding to real household objects. We use this realistic, object-centric 3D dataset to measure the domain gap for single-view 3D reconstruction networks trained on synthetic objects. We also use multi-view images from ABO to measure the robustness of state-of-the-art metric learning approach&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2110.06199v1-abstract-full').style.display = 'inline'; document.getElementById('2110.06199v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2110.06199v1-abstract-full" style="display: none;">
        We introduce Amazon-Berkeley Objects (ABO), a new large-scale dataset of product images and 3D models corresponding to real household objects. We use this realistic, object-centric 3D dataset to measure the domain gap for single-view 3D reconstruction networks trained on synthetic objects. We also use multi-view images from ABO to measure the robustness of state-of-the-art metric learning approaches to different camera viewpoints. Finally, leveraging the physically-based rendering materials in ABO, we perform single- and multi-view material estimation for a variety of complex, real-world geometries. The full dataset is available for download at https://amazon-berkeley-objects.s3.amazonaws.com/index.html.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2110.06199v1-abstract-full').style.display = 'none'; document.getElementById('2110.06199v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 12 October, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2110.05472">arXiv:2110.05472</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2110.05472">pdf</a>, <a href="https://arxiv.org/format/2110.05472">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Differentiable Stereopsis: Meshes from multiple views using differentiable rendering
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Goel%2C+S">Shubham Goel</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Gkioxari%2C+G">Georgia Gkioxari</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Malik%2C+J">Jitendra Malik</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2110.05472v1-abstract-short" style="display: inline;">
        We propose Differentiable Stereopsis, a multi-view stereo approach that reconstructs shape and texture from few input views and noisy cameras. We pair traditional stereopsis and modern differentiable rendering to build an end-to-end model which predicts textured 3D meshes of objects with varying topologies and shape. We frame stereopsis as an optimization problem and simultaneously update shape an&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2110.05472v1-abstract-full').style.display = 'inline'; document.getElementById('2110.05472v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2110.05472v1-abstract-full" style="display: none;">
        We propose Differentiable Stereopsis, a multi-view stereo approach that reconstructs shape and texture from few input views and noisy cameras. We pair traditional stereopsis and modern differentiable rendering to build an end-to-end model which predicts textured 3D meshes of objects with varying topologies and shape. We frame stereopsis as an optimization problem and simultaneously update shape and cameras via simple gradient descent. We run an extensive quantitative analysis and compare to traditional multi-view stereo techniques and state-of-the-art learning based methods. We show compelling reconstructions on challenging real-world scenes and for an abundance of object types with complex shape, topology and texture. Project webpage: https://shubham-goel.github.io/ds/
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2110.05472v1-abstract-full').style.display = 'none'; document.getElementById('2110.05472v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 11 October, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">https://shubham-goel.github.io/ds/</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2109.08792">arXiv:2109.08792</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2109.08792">pdf</a>, <a href="https://arxiv.org/format/2109.08792">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Learning to be Fair: A Consequentialist Approach to Equitable Decision-Making
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Chohlas-Wood%2C+A">Alex Chohlas-Wood</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Coots%2C+M">Madison Coots</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+H">Henry Zhu</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Brunskill%2C+E">Emma Brunskill</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Goel%2C+S">Sharad Goel</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2109.08792v2-abstract-short" style="display: inline;">
        In the dominant paradigm for designing equitable machine learning systems, one works to ensure that model predictions satisfy various fairness criteria, such as parity in error rates across race, gender, and other legally protected traits. That approach, however, typically ignores the downstream decisions and outcomes that predictions affect, and, as a result, can induce unexpected harms. Here we&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2109.08792v2-abstract-full').style.display = 'inline'; document.getElementById('2109.08792v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2109.08792v2-abstract-full" style="display: none;">
        In the dominant paradigm for designing equitable machine learning systems, one works to ensure that model predictions satisfy various fairness criteria, such as parity in error rates across race, gender, and other legally protected traits. That approach, however, typically ignores the downstream decisions and outcomes that predictions affect, and, as a result, can induce unexpected harms. Here we present an alternative framework for fairness that directly anticipates the consequences of decisions. Stakeholders first specify preferences over the possible outcomes of an algorithmically informed decision-making process. For example, lenders may prefer extending credit to those most likely to repay a loan, while also preferring similar lending rates across neighborhoods. One then searches the space of decision policies to maximize the specified utility. We develop and describe a method for efficiently learning these optimal policies from data for a large family of expressive utility functions, facilitating a more holistic approach to equitable decision-making.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2109.08792v2-abstract-full').style.display = 'none'; document.getElementById('2109.08792v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 16 February, 2022; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 17 September, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2108.12459">arXiv:2108.12459</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2108.12459">pdf</a>, <a href="https://arxiv.org/format/2108.12459">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        From Pivots to Graphs: Augmented CycleDensity as a Generalization to One Time InverseConsultation
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Goel%2C+S">Shashwat Goel</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Grover%2C+K+S+S">Kunwar Shaanjeet Singh Grover</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2108.12459v1-abstract-short" style="display: inline;">
        This paper describes an approach used to generate new translations using raw bilingual dictionaries as part of the 4th Task Inference Across Dictionaries (TIAD 2021) shared task. We propose Augmented Cycle Density (ACD) as a framework that combines insights from two state of the art methods that require no sense information and parallel corpora: Cycle Density (CD) and One Time Inverse Consultation&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2108.12459v1-abstract-full').style.display = 'inline'; document.getElementById('2108.12459v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2108.12459v1-abstract-full" style="display: none;">
        This paper describes an approach used to generate new translations using raw bilingual dictionaries as part of the 4th Task Inference Across Dictionaries (TIAD 2021) shared task. We propose Augmented Cycle Density (ACD) as a framework that combines insights from two state of the art methods that require no sense information and parallel corpora: Cycle Density (CD) and One Time Inverse Consultation (OTIC). The task results show that across 3 unseen language pairs, ACD&#39;s predictions, has more than double (74%) the coverage of OTIC at almost the same precision (76%). ACD combines CD&#39;s scalability - leveraging rich multilingual graphs for better predictions, and OTIC&#39;s data efficiency - producing good results with the minimum possible resource of one pivot language.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2108.12459v1-abstract-full').style.display = 'none'; document.getElementById('2108.12459v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 27 August, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">8 pages, 3 figures, To be published in: Translation Inference Across Dictionaries 2021 Shared Task, Language Data and Knowledge 2021</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2107.09773">arXiv:2107.09773</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2107.09773">pdf</a>, <a href="https://arxiv.org/format/2107.09773">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Statistics Theory">math.ST</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Statistical Estimation from Dependent Data
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Dagan%2C+Y">Yuval Dagan</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Daskalakis%2C+C">Constantinos Daskalakis</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Dikkala%2C+N">Nishanth Dikkala</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Goel%2C+S">Surbhi Goel</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Kandiros%2C+A+V">Anthimos Vardis Kandiros</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2107.09773v1-abstract-short" style="display: inline;">
        We consider a general statistical estimation problem wherein binary labels across different observations are not independent conditioned on their feature vectors, but dependent, capturing settings where e.g. these observations are collected on a spatial domain, a temporal domain, or a social network, which induce dependencies. We model these dependencies in the language of Markov Random Fields and&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2107.09773v1-abstract-full').style.display = 'inline'; document.getElementById('2107.09773v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2107.09773v1-abstract-full" style="display: none;">
        We consider a general statistical estimation problem wherein binary labels across different observations are not independent conditioned on their feature vectors, but dependent, capturing settings where e.g. these observations are collected on a spatial domain, a temporal domain, or a social network, which induce dependencies. We model these dependencies in the language of Markov Random Fields and, importantly, allow these dependencies to be substantial, i.e do not assume that the Markov Random Field capturing these dependencies is in high temperature. As our main contribution we provide algorithms and statistically efficient estimation rates for this model, giving several instantiations of our bounds in logistic regression, sparse logistic regression, and neural network settings with dependent data. Our estimation guarantees follow from novel results for estimating the parameters (i.e. external fields and interaction strengths) of Ising models from a {\em single} sample. {We evaluate our estimation approach on real networked data, showing that it outperforms standard regression approaches that ignore dependencies, across three text classification datasets: Cora, Citeseer and Pubmed.}
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2107.09773v1-abstract-full').style.display = 'none'; document.getElementById('2107.09773v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 20 July, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">41 pages, ICML 2021</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.09943">arXiv:2106.09943</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.09943">pdf</a>, <a href="https://arxiv.org/format/2106.09943">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Investigating the Role of Negatives in Contrastive Representation Learning
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Ash%2C+J+T">Jordan T. Ash</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Goel%2C+S">Surbhi Goel</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Krishnamurthy%2C+A">Akshay Krishnamurthy</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Misra%2C+D">Dipendra Misra</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.09943v1-abstract-short" style="display: inline;">
        Noise contrastive learning is a popular technique for unsupervised representation learning. In this approach, a representation is obtained via reduction to supervised learning, where given a notion of semantic similarity, the learner tries to distinguish a similar (positive) example from a collection of random (negative) examples. The success of modern contrastive learning pipelines relies on many&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.09943v1-abstract-full').style.display = 'inline'; document.getElementById('2106.09943v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.09943v1-abstract-full" style="display: none;">
        Noise contrastive learning is a popular technique for unsupervised representation learning. In this approach, a representation is obtained via reduction to supervised learning, where given a notion of semantic similarity, the learner tries to distinguish a similar (positive) example from a collection of random (negative) examples. The success of modern contrastive learning pipelines relies on many parameters such as the choice of data augmentation, the number of negative examples, and the batch size; however, there is limited understanding as to how these parameters interact and affect downstream performance. We focus on disambiguating the role of one of these parameters: the number of negative examples. Theoretically, we show the existence of a collision-coverage trade-off suggesting that the optimal number of negative examples should scale with the number of underlying concepts in the data. Empirically, we scrutinize the role of the number of negatives in both NLP and vision tasks. In the NLP task, we find that the results broadly agree with our theory, while our vision experiments are murkier with performance sometimes even being insensitive to the number of negatives. We discuss plausible explanations for this behavior and suggest future directions to better align theory and practice.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.09943v1-abstract-full').style.display = 'none'; document.getElementById('2106.09943v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 18 June, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.09675">arXiv:2106.09675</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.09675">pdf</a>, <a href="https://arxiv.org/format/2106.09675">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Gone Fishing: Neural Active Learning with Fisher Embeddings
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Ash%2C+J+T">Jordan T. Ash</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Goel%2C+S">Surbhi Goel</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Krishnamurthy%2C+A">Akshay Krishnamurthy</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Kakade%2C+S">Sham Kakade</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.09675v2-abstract-short" style="display: inline;">
        There is an increasing need for effective active learning algorithms that are compatible with deep neural networks. This paper motivates and revisits a classic, Fisher-based active selection objective, and proposes BAIT, a practical, tractable, and high-performing algorithm that makes it viable for use with neural models. BAIT draws inspiration from the theoretical analysis of maximum likelihood e&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.09675v2-abstract-full').style.display = 'inline'; document.getElementById('2106.09675v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.09675v2-abstract-full" style="display: none;">
        There is an increasing need for effective active learning algorithms that are compatible with deep neural networks. This paper motivates and revisits a classic, Fisher-based active selection objective, and proposes BAIT, a practical, tractable, and high-performing algorithm that makes it viable for use with neural models. BAIT draws inspiration from the theoretical analysis of maximum likelihood estimators (MLE) for parametric models. It selects batches of samples by optimizing a bound on the MLE error in terms of the Fisher information, which we show can be implemented efficiently at scale by exploiting linear-algebraic structure especially amenable to execution on modern hardware. Our experiments demonstrate that BAIT outperforms the previous state of the art on both classification and regression problems, and is flexible enough to be used with a variety of model architectures.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.09675v2-abstract-full').style.display = 'none'; document.getElementById('2106.09675v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 14 December, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 17 June, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.06515">arXiv:2106.06515</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.06515">pdf</a>, <a href="https://arxiv.org/format/2106.06515">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Methodology">stat.ME</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Probability Paths and the Structure of Predictions over Time
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Lin%2C+Z+J">Zhiyuan Jerry Lin</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Sheng%2C+H">Hao Sheng</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Goel%2C+S">Sharad Goel</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.06515v2-abstract-short" style="display: inline;">
        In settings ranging from weather forecasts to political prognostications to financial projections, probability estimates of future binary outcomes often evolve over time. For example, the estimated likelihood of rain on a specific day changes by the hour as new information becomes available. Given a collection of such probability paths, we introduce a Bayesian framework -- which we call the Gaussi&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.06515v2-abstract-full').style.display = 'inline'; document.getElementById('2106.06515v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.06515v2-abstract-full" style="display: none;">
        In settings ranging from weather forecasts to political prognostications to financial projections, probability estimates of future binary outcomes often evolve over time. For example, the estimated likelihood of rain on a specific day changes by the hour as new information becomes available. Given a collection of such probability paths, we introduce a Bayesian framework -- which we call the Gaussian latent information martingale, or GLIM -- for modeling the structure of dynamic predictions over time. Suppose, for example, that the likelihood of rain in a week is 50 %, and consider two hypothetical scenarios. In the first, one expects the forecast to be equally likely to become either 25 % or 75 % tomorrow; in the second, one expects the forecast to stay constant for the next several days. A time-sensitive decision-maker might select a course of action immediately in the latter scenario, but may postpone their decision in the former, knowing that new information is imminent. We model these trajectories by assuming predictions update according to a latent process of information flow, which is inferred from historical data. In contrast to general methods for time series analysis, this approach preserves important properties of probability paths such as the martingale structure and appropriate amount of volatility and better quantifies future uncertainties around probability paths. We show that GLIM outperforms three popular baseline methods, producing better estimated posterior probability path distributions measured by three different metrics. By elucidating the dynamic structure of predictions over time, we hope to help individuals make more informed choices.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.06515v2-abstract-full').style.display = 'none'; document.getElementById('2106.06515v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 4 November, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 11 June, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        35th Conference on Neural Information Processing Systems (NeurIPS 2021)
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.06205">arXiv:2106.06205</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.06205">pdf</a>, <a href="https://arxiv.org/ps/2106.06205">ps</a>, <a href="https://arxiv.org/format/2106.06205">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Logic">math.LO</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Logic in Computer Science">cs.LO</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Programming Languages">cs.PL</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Time Warps, from Algebra to Algorithms
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=van+Gool%2C+S">Sam van Gool</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Guatto%2C+A">Adrien Guatto</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Metcalfe%2C+G">George Metcalfe</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Santschi%2C+S">Simon Santschi</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.06205v2-abstract-short" style="display: inline;">
        Graded modalities have been proposed in recent work on programming languages as a general framework for refining type systems with intensional properties. In particular, continuous endomaps of the discrete time scale, or time warps, can be used to quantify the growth of information in the course of program execution. Time warps form a complete residuated lattice, with the residuals playing an impo&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.06205v2-abstract-full').style.display = 'inline'; document.getElementById('2106.06205v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.06205v2-abstract-full" style="display: none;">
        Graded modalities have been proposed in recent work on programming languages as a general framework for refining type systems with intensional properties. In particular, continuous endomaps of the discrete time scale, or time warps, can be used to quantify the growth of information in the course of program execution. Time warps form a complete residuated lattice, with the residuals playing an important role in potential programming applications. In this paper, we study the algebraic structure of time warps, and prove that their equational theory is decidable, a necessary condition for their use in real-world compilers. We also describe how our universal-algebraic proof technique lends itself to a constraint-based implementation, establishing a new link between universal algebra and verification technology.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.06205v2-abstract-full').style.display = 'none'; document.getElementById('2106.06205v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 19 August, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 11 June, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">22 pages, version accepted at RAMICS 2021 plus appendices</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2105.01764">arXiv:2105.01764</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2105.01764">pdf</a>, <a href="https://arxiv.org/format/2105.01764">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Surveilling Surveillance: Estimating the Prevalence of Surveillance Cameras with Street View Data
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Sheng%2C+H">Hao Sheng</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Yao%2C+K">Keniel Yao</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Goel%2C+S">Sharad Goel</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2105.01764v3-abstract-short" style="display: inline;">
        The use of video surveillance in public spaces -- both by government agencies and by private citizens -- has attracted considerable attention in recent years, particularly in light of rapid advances in face-recognition technology. But it has been difficult to systematically measure the prevalence and placement of cameras, hampering efforts to assess the implications of surveillance on privacy and&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.01764v3-abstract-full').style.display = 'inline'; document.getElementById('2105.01764v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2105.01764v3-abstract-full" style="display: none;">
        The use of video surveillance in public spaces -- both by government agencies and by private citizens -- has attracted considerable attention in recent years, particularly in light of rapid advances in face-recognition technology. But it has been difficult to systematically measure the prevalence and placement of cameras, hampering efforts to assess the implications of surveillance on privacy and public safety. Here, we combine computer vision, human verification, and statistical analysis to estimate the spatial distribution of surveillance cameras. Specifically, we build a camera detection model and apply it to 1.6 million street view images sampled from 10 large U.S. cities and 6 other major cities around the world, with positive model detections verified by human experts. After adjusting for the estimated recall of our model, and accounting for the spatial coverage of our sampled images, we are able to estimate the density of surveillance cameras visible from the road. Across the 16 cities we consider, the estimated number of surveillance cameras per linear kilometer ranges from 0.2 (in Los Angeles) to 0.9 (in Seoul). In a detailed analysis of the 10 U.S. cities, we find that cameras are concentrated in commercial, industrial, and mixed zones, and in neighborhoods with higher shares of non-white residents -- a pattern that persists even after adjusting for land use. These results help inform ongoing discussions on the use of surveillance technology, including its potential disparate impacts on communities of color.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.01764v3-abstract-full').style.display = 'none'; document.getElementById('2105.01764v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 30 August, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 4 May, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">We now credit Turtiainen et al. (2020) both for creating a state-of-the-art camera detection model and for suggesting that computer vision could, in theory, be applied to street view data to map surveillance cameras. Also, we discovered a coding error in our image sampling strategy that corrupted our analysis of camera density over time. We have now removed the results of that analysis</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.02979">arXiv:2103.02979</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.02979">pdf</a>, <a href="https://arxiv.org/format/2103.02979">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Distributed, Parallel, and Cluster Computing">cs.DC</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Blockchain Based Accounts Payable Platform for Goods Trade
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Narayanam%2C+K">Krishnasuri Narayanam</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Goel%2C+S">Seep Goel</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Singh%2C+A">Abhishek Singh</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Shrinivasan%2C+Y">Yedendra Shrinivasan</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Selvam%2C+P">Parameswaram Selvam</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.02979v1-abstract-short" style="display: inline;">
        Goods trade is a supply chain transaction that involves shippers buying goods from suppliers and carriers providing goods transportation. Shippers are issued invoices from suppliers and carriers. Shippers carry out goods receiving and invoice processing before payment processing of bills for suppliers and carriers, where invoice processing includes tasks like processing claims and adjusting the bi&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.02979v1-abstract-full').style.display = 'inline'; document.getElementById('2103.02979v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.02979v1-abstract-full" style="display: none;">
        Goods trade is a supply chain transaction that involves shippers buying goods from suppliers and carriers providing goods transportation. Shippers are issued invoices from suppliers and carriers. Shippers carry out goods receiving and invoice processing before payment processing of bills for suppliers and carriers, where invoice processing includes tasks like processing claims and adjusting the bill payments. Goods receiving involves verification of received goods by the Shipper&#39;s receiving team. Invoice processing is carried out by the Shipper&#39;s accounts payable team, which in turn is verified by the accounts receivable teams of suppliers and carriers. This paper presents a blockchain-based accounts payable system that generates claims for the deficiency in the goods received and accordingly adjusts the payment in the bills for suppliers and carriers. Primary motivations for these supply chain organizations to adopt blockchain-based accounts payable systems are to eliminate the process redundancies (accounts payable vs. accounts receivable), to reduce the number of disputes among the transacting participants, and to accelerate the accounts payable processes via optimizations in the claims generation and blockchain-based dispute reconciliation.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.02979v1-abstract-full').style.display = 'none'; document.getElementById('2103.02979v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 4 March, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.01338">arXiv:2103.01338</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.01338">pdf</a>, <a href="https://arxiv.org/format/2103.01338">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Acceleration via Fractal Learning Rate Schedules
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Agarwal%2C+N">Naman Agarwal</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Goel%2C+S">Surbhi Goel</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+C">Cyril Zhang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.01338v2-abstract-short" style="display: inline;">
        In practical applications of iterative first-order optimization, the learning rate schedule remains notoriously difficult to understand and expensive to tune. We demonstrate the presence of these subtleties even in the innocuous case when the objective is a convex quadratic. We reinterpret an iterative algorithm from the numerical analysis literature as what we call the Chebyshev learning rate sch&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.01338v2-abstract-full').style.display = 'inline'; document.getElementById('2103.01338v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.01338v2-abstract-full" style="display: none;">
        In practical applications of iterative first-order optimization, the learning rate schedule remains notoriously difficult to understand and expensive to tune. We demonstrate the presence of these subtleties even in the innocuous case when the objective is a convex quadratic. We reinterpret an iterative algorithm from the numerical analysis literature as what we call the Chebyshev learning rate schedule for accelerating vanilla gradient descent, and show that the problem of mitigating instability leads to a fractal ordering of step sizes. We provide some experiments to challenge conventional beliefs about stable learning rates in deep learning: the fractal schedule enables training to converge with locally unstable updates which make negative progress on the objective.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.01338v2-abstract-full').style.display = 'none'; document.getElementById('2103.01338v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 11 June, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 1 March, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">v2: revisions for ICML 2021</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2102.09737">arXiv:2102.09737</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2102.09737">pdf</a>, <a href="https://arxiv.org/format/2102.09737">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Sound">cs.SD</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Audio and Speech Processing">eess.AS</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Image and Video Processing">eess.IV</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        One Shot Audio to Animated Video Generation
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Kumar%2C+N">Neeraj Kumar</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Goel%2C+S">Srishti Goel</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Narang%2C+A">Ankur Narang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Lall%2C+B">Brejesh Lall</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Hasan%2C+M">Mujtaba Hasan</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Agarwal%2C+P">Pranshu Agarwal</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Sarkar%2C+D">Dipankar Sarkar</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2102.09737v1-abstract-short" style="display: inline;">
        We consider the challenging problem of audio to animated video generation. We propose a novel method OneShotAu2AV to generate an animated video of arbitrary length using an audio clip and a single unseen image of a person as an input. The proposed method consists of two stages. In the first stage, OneShotAu2AV generates the talking-head video in the human domain given an audio and a person&#39;s image&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.09737v1-abstract-full').style.display = 'inline'; document.getElementById('2102.09737v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2102.09737v1-abstract-full" style="display: none;">
        We consider the challenging problem of audio to animated video generation. We propose a novel method OneShotAu2AV to generate an animated video of arbitrary length using an audio clip and a single unseen image of a person as an input. The proposed method consists of two stages. In the first stage, OneShotAu2AV generates the talking-head video in the human domain given an audio and a person&#39;s image. In the second stage, the talking-head video from the human domain is converted to the animated domain. The model architecture of the first stage consists of spatially adaptive normalization based multi-level generator and multiple multilevel discriminators along with multiple adversarial and non-adversarial losses. The second stage leverages attention based normalization driven GAN architecture along with temporal predictor based recycle loss and blink loss coupled with lipsync loss, for unsupervised generation of animated video. In our approach, the input audio clip is not restricted to any specific language, which gives the method multilingual applicability. OneShotAu2AV can generate animated videos that have: (a) lip movements that are in sync with the audio, (b) natural facial expressions such as blinks and eyebrow movements, (c) head movements. Experimental evaluation demonstrates superior performance of OneShotAu2AV as compared to U-GAT-IT and RecycleGan on multiple quantitative metrics including KID(Kernel Inception Distance), Word error rate, blinks/sec
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.09737v1-abstract-full').style.display = 'none'; document.getElementById('2102.09737v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 18 February, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">arXiv admin note: substantial text overlap with arXiv:2012.07842, arXiv:2012.07304</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2012.13037">arXiv:2012.13037</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2012.13037">pdf</a>, <a href="https://arxiv.org/format/2012.13037">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        SPOTTER: Extending Symbolic Planning Operators through Targeted Reinforcement Learning
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Sarathy%2C+V">Vasanth Sarathy</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Kasenberg%2C+D">Daniel Kasenberg</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Goel%2C+S">Shivam Goel</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Sinapov%2C+J">Jivko Sinapov</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Scheutz%2C+M">Matthias Scheutz</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2012.13037v1-abstract-short" style="display: inline;">
        Symbolic planning models allow decision-making agents to sequence actions in arbitrary ways to achieve a variety of goals in dynamic domains. However, they are typically handcrafted and tend to require precise formulations that are not robust to human error. Reinforcement learning (RL) approaches do not require such models, and instead learn domain dynamics by exploring the environment and collect&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.13037v1-abstract-full').style.display = 'inline'; document.getElementById('2012.13037v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2012.13037v1-abstract-full" style="display: none;">
        Symbolic planning models allow decision-making agents to sequence actions in arbitrary ways to achieve a variety of goals in dynamic domains. However, they are typically handcrafted and tend to require precise formulations that are not robust to human error. Reinforcement learning (RL) approaches do not require such models, and instead learn domain dynamics by exploring the environment and collecting rewards. However, RL approaches tend to require millions of episodes of experience and often learn policies that are not easily transferable to other tasks. In this paper, we address one aspect of the open problem of integrating these approaches: how can decision-making agents resolve discrepancies in their symbolic planning models while attempting to accomplish goals? We propose an integrated framework named SPOTTER that uses RL to augment and support (&#34;spot&#34;) a planning agent by discovering new operators needed by the agent to accomplish goals that are initially unreachable for the agent. SPOTTER outperforms pure-RL approaches while also discovering transferable symbolic knowledge and does not require supervision, successful plan traces or any a priori knowledge about the missing planning operator.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.13037v1-abstract-full').style.display = 'none'; document.getElementById('2012.13037v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 23 December, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted to AAMAS 2021</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2012.07842">arXiv:2012.07842</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2012.07842">pdf</a>, <a href="https://arxiv.org/format/2012.07842">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Robust One Shot Audio to Video Generation
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Kumar%2C+N">Neeraj Kumar</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Goel%2C+S">Srishti Goel</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Narang%2C+A">Ankur Narang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Hasan%2C+M">Mujtaba Hasan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2012.07842v1-abstract-short" style="display: inline;">
        Audio to Video generation is an interesting problem that has numerous applications across industry verticals including film making, multi-media, marketing, education and others. High-quality video generation with expressive facial movements is a challenging problem that involves complex learning steps for generative adversarial networks. Further, enabling one-shot learning for an unseen single ima&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.07842v1-abstract-full').style.display = 'inline'; document.getElementById('2012.07842v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2012.07842v1-abstract-full" style="display: none;">
        Audio to Video generation is an interesting problem that has numerous applications across industry verticals including film making, multi-media, marketing, education and others. High-quality video generation with expressive facial movements is a challenging problem that involves complex learning steps for generative adversarial networks. Further, enabling one-shot learning for an unseen single image increases the complexity of the problem while simultaneously making it more applicable to practical scenarios. In the paper, we propose a novel approach OneShotA2V to synthesize a talking person video of arbitrary length using as input: an audio signal and a single unseen image of a person. OneShotA2V leverages curriculum learning to learn movements of expressive facial components and hence generates a high-quality talking-head video of the given person. Further, it feeds the features generated from the audio input directly into a generative adversarial network and it adapts to any given unseen selfie by applying fewshot learning with only a few output updation epochs. OneShotA2V leverages spatially adaptive normalization based multi-level generator and multiple multi-level discriminators based architecture. The input audio clip is not restricted to any specific language, which gives the method multilingual applicability. Experimental evaluation demonstrates superior performance of OneShotA2V as compared to Realistic Speech-Driven Facial Animation with GANs(RSDGAN) [43], Speech2Vid [8], and other approaches, on multiple quantitative metrics including: SSIM (structural similarity index), PSNR (peak signal to noise ratio) and CPBD (image sharpness). Further, qualitative evaluation and Online Turing tests demonstrate the efficacy of our approach.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.07842v1-abstract-full').style.display = 'none'; document.getElementById('2012.07842v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 14 December, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted in CVPR Deep Vision 2020. arXiv admin note: text overlap with arXiv:2012.07304</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2012.07304">arXiv:2012.07304</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2012.07304">pdf</a>, <a href="https://arxiv.org/format/2012.07304">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Multi Modal Adaptive Normalization for Audio to Video Generation
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Kumar%2C+N">Neeraj Kumar</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Goel%2C+S">Srishti Goel</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Narang%2C+A">Ankur Narang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Lall%2C+B">Brejesh Lall</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2012.07304v1-abstract-short" style="display: inline;">
        Speech-driven facial video generation has been a complex problem due to its multi-modal aspects namely audio and video domain. The audio comprises lots of underlying features such as expression, pitch, loudness, prosody(speaking style) and facial video has lots of variability in terms of head movement, eye blinks, lip synchronization and movements of various facial action units along with temporal&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.07304v1-abstract-full').style.display = 'inline'; document.getElementById('2012.07304v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2012.07304v1-abstract-full" style="display: none;">
        Speech-driven facial video generation has been a complex problem due to its multi-modal aspects namely audio and video domain. The audio comprises lots of underlying features such as expression, pitch, loudness, prosody(speaking style) and facial video has lots of variability in terms of head movement, eye blinks, lip synchronization and movements of various facial action units along with temporal smoothness. Synthesizing highly expressive facial videos from the audio input and static image is still a challenging task for generative adversarial networks. In this paper, we propose a multi-modal adaptive normalization(MAN) based architecture to synthesize a talking person video of arbitrary length using as input: an audio signal and a single image of a person. The architecture uses the multi-modal adaptive normalization, keypoint heatmap predictor, optical flow predictor and class activation map[58] based layers to learn movements of expressive facial components and hence generates a highly expressive talking-head video of the given person. The multi-modal adaptive normalization uses the various features of audio and video such as Mel spectrogram, pitch, energy from audio signals and predicted keypoint heatmap/optical flow and a single image to learn the respective affine parameters to generate highly expressive video. Experimental evaluation demonstrates superior performance of the proposed method as compared to Realistic Speech-Driven Facial Animation with GANs(RSDGAN) [53], Speech2Vid [10], and other approaches, on multiple quantitative metrics including: SSIM (structural similarity index), PSNR (peak signal to noise ratio), CPBD (image sharpness), WER(word error rate), blinks/sec and LMD(landmark distance). Further, qualitative evaluation and Online Turing tests demonstrate the efficacy of our approach.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.07304v1-abstract-full').style.display = 'none'; document.getElementById('2012.07304v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 14 December, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2012.07252">arXiv:2012.07252</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2012.07252">pdf</a>, <a href="https://arxiv.org/format/2012.07252">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Audio and Speech Processing">eess.AS</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Few Shot Adaptive Normalization Driven Multi-Speaker Speech Synthesis
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Kumar%2C+N">Neeraj Kumar</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Goel%2C+S">Srishti Goel</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Narang%2C+A">Ankur Narang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Lall%2C+B">Brejesh Lall</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2012.07252v1-abstract-short" style="display: inline;">
        The style of the speech varies from person to person and every person exhibits his or her own style of speaking that is determined by the language, geography, culture and other factors. Style is best captured by prosody of a signal. High quality multi-speaker speech synthesis while considering prosody and in a few shot manner is an area of active research with many real-world applications. While m&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.07252v1-abstract-full').style.display = 'inline'; document.getElementById('2012.07252v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2012.07252v1-abstract-full" style="display: none;">
        The style of the speech varies from person to person and every person exhibits his or her own style of speaking that is determined by the language, geography, culture and other factors. Style is best captured by prosody of a signal. High quality multi-speaker speech synthesis while considering prosody and in a few shot manner is an area of active research with many real-world applications. While multiple efforts have been made in this direction, it remains an interesting and challenging problem. In this paper, we present a novel few shot multi-speaker speech synthesis approach (FSM-SS) that leverages adaptive normalization architecture with a non-autoregressive multi-head attention model. Given an input text and a reference speech sample of an unseen person, FSM-SS can generate speech in that person&#39;s style in a few shot manner. Additionally, we demonstrate how the affine parameters of normalization help in capturing the prosodic features such as energy and fundamental frequency in a disentangled fashion and can be used to generate morphed speech output. We demonstrate the efficacy of our proposed architecture on multi-speaker VCTK and LibriTTS datasets, using multiple quantitative metrics that measure generated speech distortion and MoS, along with speaker embedding analysis of the generated speech vs the actual speech samples.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.07252v1-abstract-full').style.display = 'none'; document.getElementById('2012.07252v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 13 December, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Submitted to AAAI 2020</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2012.00659">arXiv:2012.00659</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2012.00659">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Emotion Detection using Image Processing in Python
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Puri%2C+R">Raghav Puri</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Gupta%2C+A">Archit Gupta</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Sikri%2C+M">Manas Sikri</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Tiwari%2C+M">Mohit Tiwari</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Pathak%2C+N">Nitish Pathak</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Goel%2C+S">Shivendra Goel</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2012.00659v1-abstract-short" style="display: inline;">
        In this work, user&#39;s emotion using its facial expressions will be detected. These expressions can be derived from the live feed via system&#39;s camera or any pre-exisiting image available in the memory. Emotions possessed by humans can be recognized and has a vast scope of study in the computer vision industry upon which several researches have already been done. The work has been implemented using P&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.00659v1-abstract-full').style.display = 'inline'; document.getElementById('2012.00659v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2012.00659v1-abstract-full" style="display: none;">
        In this work, user&#39;s emotion using its facial expressions will be detected. These expressions can be derived from the live feed via system&#39;s camera or any pre-exisiting image available in the memory. Emotions possessed by humans can be recognized and has a vast scope of study in the computer vision industry upon which several researches have already been done. The work has been implemented using Python (2.7, Open Source Computer Vision Library (OpenCV) and NumPy. The scanned image(testing dataset) is being compared to the training dataset and thus emotion is predicted. The objective of this paper is to develop a system which can analyze the image and predict the expression of the person. The study proves that this procedure is workable and produces valid results.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.00659v1-abstract-full').style.display = 'none'; document.getElementById('2012.00659v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 1 December, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2011.13550">arXiv:2011.13550</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2011.13550">pdf</a>, <a href="https://arxiv.org/ps/2011.13550">ps</a>, <a href="https://arxiv.org/format/2011.13550">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computational Complexity">cs.CC</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Data Structures and Algorithms">cs.DS</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Tight Hardness Results for Training Depth-2 ReLU Networks
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Goel%2C+S">Surbhi Goel</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Klivans%2C+A">Adam Klivans</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Manurangsi%2C+P">Pasin Manurangsi</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Reichman%2C+D">Daniel Reichman</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2011.13550v1-abstract-short" style="display: inline;">
        We prove several hardness results for training depth-2 neural networks with the ReLU activation function; these networks are simply weighted sums (that may include negative coefficients) of ReLUs. Our goal is to output a depth-2 neural network that minimizes the square loss with respect to a given training set. We prove that this problem is NP-hard already for a network with a single ReLU. We also&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2011.13550v1-abstract-full').style.display = 'inline'; document.getElementById('2011.13550v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2011.13550v1-abstract-full" style="display: none;">
        We prove several hardness results for training depth-2 neural networks with the ReLU activation function; these networks are simply weighted sums (that may include negative coefficients) of ReLUs. Our goal is to output a depth-2 neural network that minimizes the square loss with respect to a given training set. We prove that this problem is NP-hard already for a network with a single ReLU. We also prove NP-hardness for outputting a weighted sum of $k$ ReLUs minimizing the squared error (for $k&gt;1$) even in the realizable setting (i.e., when the labels are consistent with an unknown depth-2 ReLU network). We are also able to obtain lower bounds on the running time in terms of the desired additive error $ε$. To obtain our lower bounds, we use the Gap Exponential Time Hypothesis (Gap-ETH) as well as a new hypothesis regarding the hardness of approximating the well known Densest $κ$-Subgraph problem in subexponential time (these hypotheses are used separately in proving different lower bounds). For example, we prove that under reasonable hardness assumptions, any proper learning algorithm for finding the best fitting ReLU must run in time exponential in $1/ε^2$. Together with a previous work regarding improperly learning a ReLU (Goel et al., COLT&#39;17), this implies the first separation between proper and improper algorithms for learning a ReLU. We also study the problem of properly learning a depth-2 network of ReLUs with bounded weights giving new (worst-case) upper bounds on the running time needed to learn such networks both in the realizable and agnostic settings. Our upper bounds on the running time essentially matches our lower bounds in terms of the dependency on $ε$.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2011.13550v1-abstract-full').style.display = 'none'; document.getElementById('2011.13550v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 26 November, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">To appear in ITCS&#39;21</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2009.13613">arXiv:2009.13613</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2009.13613">pdf</a>, <a href="https://arxiv.org/format/2009.13613">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
          
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1145/3442381.3449857">10.1145/3442381.3449857 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Joint Spatio-Textual Reasoning for Answering Tourism Questions
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Contractor%2C+D">Danish Contractor</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Goel%2C+S">Shashank Goel</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Mausam"> Mausam</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Singla%2C+P">Parag Singla</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2009.13613v2-abstract-short" style="display: inline;">
        Our goal is to answer real-world tourism questions that seek Points-of-Interest (POI) recommendations. Such questions express various kinds of spatial and non-spatial constraints, necessitating a combination of textual and spatial reasoning. In response, we develop the first joint spatio-textual reasoning model, which combines geo-spatial knowledge with information in textual corpora to answer que&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2009.13613v2-abstract-full').style.display = 'inline'; document.getElementById('2009.13613v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2009.13613v2-abstract-full" style="display: none;">
        Our goal is to answer real-world tourism questions that seek Points-of-Interest (POI) recommendations. Such questions express various kinds of spatial and non-spatial constraints, necessitating a combination of textual and spatial reasoning. In response, we develop the first joint spatio-textual reasoning model, which combines geo-spatial knowledge with information in textual corpora to answer questions. We first develop a modular spatial-reasoning network that uses geo-coordinates of location names mentioned in a question, and of candidate answer POIs, to reason over only spatial constraints. We then combine our spatial-reasoner with a textual reasoner in a joint model and present experiments on a real world POI recommendation task. We report substantial improvements over existing models with-out joint spatio-textual reasoning.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2009.13613v2-abstract-full').style.display = 'none'; document.getElementById('2009.13613v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 19 October, 2020; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 28 September, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Updated version</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2007.13325">arXiv:2007.13325</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2007.13325">pdf</a>, <a href="https://arxiv.org/format/2007.13325">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Audio and Speech Processing">eess.AS</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Sound">cs.SD</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Analysis of Emotional Content in Indian Political Speeches
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Goel%2C+S">Sharu Goel</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Pandey%2C+S+K">Sandeep Kumar Pandey</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Shekhawat%2C+H+S">Hanumant Singh Shekhawat</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2007.13325v1-abstract-short" style="display: inline;">
        Emotions play an essential role in public speaking. The emotional content of speech has the power to influence minds. As such, we present an analysis of the emotional content of politicians speech in the Indian political scenario. We investigate the emotional content present in the speeches of politicians using an Attention based CNN+LSTM network. Experimental evaluations on a dataset of eight Ind&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2007.13325v1-abstract-full').style.display = 'inline'; document.getElementById('2007.13325v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2007.13325v1-abstract-full" style="display: none;">
        Emotions play an essential role in public speaking. The emotional content of speech has the power to influence minds. As such, we present an analysis of the emotional content of politicians speech in the Indian political scenario. We investigate the emotional content present in the speeches of politicians using an Attention based CNN+LSTM network. Experimental evaluations on a dataset of eight Indian politicians shows how politicians incorporate emotions in their speeches to strike a chord with the masses. An analysis of the voting share received along with victory margin and their relation to emotional content in speech of the politicians is also presented.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2007.13325v1-abstract-full').style.display = 'none'; document.getElementById('2007.13325v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 27 July, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2007.12815">arXiv:2007.12815</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2007.12815">pdf</a>, <a href="https://arxiv.org/format/2007.12815">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Data Structures and Algorithms">cs.DS</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        From Boltzmann Machines to Neural Networks and Back Again
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Goel%2C+S">Surbhi Goel</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Klivans%2C+A">Adam Klivans</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Koehler%2C+F">Frederic Koehler</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2007.12815v1-abstract-short" style="display: inline;">
        Graphical models are powerful tools for modeling high-dimensional data, but learning graphical models in the presence of latent variables is well-known to be difficult. In this work we give new results for learning Restricted Boltzmann Machines, probably the most well-studied class of latent variable models. Our results are based on new connections to learning two-layer neural networks under&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2007.12815v1-abstract-full').style.display = 'inline'; document.getElementById('2007.12815v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2007.12815v1-abstract-full" style="display: none;">
        Graphical models are powerful tools for modeling high-dimensional data, but learning graphical models in the presence of latent variables is well-known to be difficult. In this work we give new results for learning Restricted Boltzmann Machines, probably the most well-studied class of latent variable models. Our results are based on new connections to learning two-layer neural networks under $\ell_{\infty}$ bounded input; for both problems, we give nearly optimal results under the conjectured hardness of sparse parity with noise. Using the connection between RBMs and feedforward networks, we also initiate the theoretical study of $supervised~RBMs$ [Hinton, 2012], a version of neural-network learning that couples distributional assumptions induced from the underlying graphical model with the architecture of the unknown function class. We then give an algorithm for learning a natural class of supervised RBMs with better runtime than what is possible for its related class of networks without distributional assumptions.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2007.12815v1-abstract-full').style.display = 'none'; document.getElementById('2007.12815v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 24 July, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2007.10982">arXiv:2007.10982</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2007.10982">pdf</a>, <a href="https://arxiv.org/format/2007.10982">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Image and Video Processing">eess.IV</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Shape and Viewpoint without Keypoints
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Goel%2C+S">Shubham Goel</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Kanazawa%2C+A">Angjoo Kanazawa</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Malik%2C+J">Jitendra Malik</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2007.10982v1-abstract-short" style="display: inline;">
        We present a learning framework that learns to recover the 3D shape, pose and texture from a single image, trained on an image collection without any ground truth 3D shape, multi-view, camera viewpoints or keypoint supervision. We approach this highly under-constrained problem in a &#34;analysis by synthesis&#34; framework where the goal is to predict the likely shape, texture and camera viewpoint that co&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2007.10982v1-abstract-full').style.display = 'inline'; document.getElementById('2007.10982v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2007.10982v1-abstract-full" style="display: none;">
        We present a learning framework that learns to recover the 3D shape, pose and texture from a single image, trained on an image collection without any ground truth 3D shape, multi-view, camera viewpoints or keypoint supervision. We approach this highly under-constrained problem in a &#34;analysis by synthesis&#34; framework where the goal is to predict the likely shape, texture and camera viewpoint that could produce the image with various learned category-specific priors. Our particular contribution in this paper is a representation of the distribution over cameras, which we call &#34;camera-multiplex&#34;. Instead of picking a point estimate, we maintain a set of camera hypotheses that are optimized during training to best explain the image given the current shape and texture. We call our approach Unsupervised Category-Specific Mesh Reconstruction (U-CMR), and present qualitative and quantitative results on CUB, Pascal 3D and new web-scraped datasets. We obtain state-of-the-art camera prediction results and show that we can learn to predict diverse shapes and textures across objects using an image collection without any keypoint annotations or 3D ground truth. Project page: https://shubham-goel.github.io/ucmr
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2007.10982v1-abstract-full').style.display = 'none'; document.getElementById('2007.10982v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 21 July, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted at ECCV 2020</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2007.00903">arXiv:2007.00903</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2007.00903">pdf</a>, <a href="https://arxiv.org/ps/2007.00903">ps</a>, <a href="https://arxiv.org/format/2007.00903">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Science and Game Theory">cs.GT</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Optimality of the coordinate-wise median mechanism for strategyproof facility location in two dimensions
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Goel%2C+S">Sumit Goel</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Hann-Caruthers%2C+W">Wade Hann-Caruthers</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2007.00903v4-abstract-short" style="display: inline;">
        We consider the facility location problem in two dimensions. In particular, we consider a setting where agents have Euclidean preferences, defined by their ideal points, for a facility to be located in $\mathbb{R}^2$. For the minisum objective and an odd number of agents, we show that the coordinate-wise median mechanism (CM) has a worst-case approximation ratio (AR) of&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2007.00903v4-abstract-full').style.display = 'inline'; document.getElementById('2007.00903v4-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2007.00903v4-abstract-full" style="display: none;">
        We consider the facility location problem in two dimensions. In particular, we consider a setting where agents have Euclidean preferences, defined by their ideal points, for a facility to be located in $\mathbb{R}^2$. For the minisum objective and an odd number of agents, we show that the coordinate-wise median mechanism (CM) has a worst-case approximation ratio (AR) of $\sqrt{2}\frac{\sqrt{n^2+1}}{n+1}$. Further, we show that CM has the lowest AR for this objective in the class of deterministic, anonymous, and strategyproof mechanisms. For the $p-norm$ social welfare objective, we find that the AR for CM is bounded above by $2^{\frac{3}{2}-\frac{2}{p}}$ for $p\geq 2$. Since any deterministic strategyproof mechanism must have AR at least $2^{1-\frac{1}{p}}$ (\citet{feigenbaum_approximately_2017}), our upper bound suggests that the CM is (at worst) very nearly optimal. We conjecture that the approximation ratio of coordinate-wise median is actually equal to the lower bound $2^{1-\frac{1}{p}}$ (as is the case for $p=2$ and $p=\infty$) for any $p\geq 2$.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2007.00903v4-abstract-full').style.display = 'none'; document.getElementById('2007.00903v4-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 14 February, 2022; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 2 July, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">24 pages</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2006.15812">arXiv:2006.15812</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2006.15812">pdf</a>, <a href="https://arxiv.org/ps/2006.15812">ps</a>, <a href="https://arxiv.org/format/2006.15812">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Data Structures and Algorithms">cs.DS</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Statistical-Query Lower Bounds via Functional Gradients
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Goel%2C+S">Surbhi Goel</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Gollakota%2C+A">Aravind Gollakota</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Klivans%2C+A">Adam Klivans</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2006.15812v2-abstract-short" style="display: inline;">
        We give the first statistical-query lower bounds for agnostically learning any non-polynomial activation with respect to Gaussian marginals (e.g., ReLU, sigmoid, sign). For the specific problem of ReLU regression (equivalently, agnostically learning a ReLU), we show that any statistical-query algorithm with tolerance $n^{-(1/ε)^b}$ must use at least $2^{n^c} ε$ queries for some constant&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2006.15812v2-abstract-full').style.display = 'inline'; document.getElementById('2006.15812v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2006.15812v2-abstract-full" style="display: none;">
        We give the first statistical-query lower bounds for agnostically learning any non-polynomial activation with respect to Gaussian marginals (e.g., ReLU, sigmoid, sign). For the specific problem of ReLU regression (equivalently, agnostically learning a ReLU), we show that any statistical-query algorithm with tolerance $n^{-(1/ε)^b}$ must use at least $2^{n^c} ε$ queries for some constant $b, c &gt; 0$, where $n$ is the dimension and $ε$ is the accuracy parameter. Our results rule out general (as opposed to correlational) SQ learning algorithms, which is unusual for real-valued learning problems. Our techniques involve a gradient boosting procedure for &#34;amplifying&#34; recent lower bounds due to Diakonikolas et al. (COLT 2020) and Goel et al. (ICML 2020) on the SQ dimension of functions computed by two-layer neural networks. The crucial new ingredient is the use of a nonstandard convex functional during the boosting procedure. This also yields a best-possible reduction between two commonly studied models of learning: agnostic learning and probabilistic concepts.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2006.15812v2-abstract-full').style.display = 'none'; document.getElementById('2006.15812v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 22 October, 2020; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 29 June, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">34 pages, NeurIPS 2020</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2006.12011">arXiv:2006.12011</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2006.12011">pdf</a>, <a href="https://arxiv.org/format/2006.12011">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Data Structures and Algorithms">cs.DS</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Superpolynomial Lower Bounds for Learning One-Layer Neural Networks using Gradient Descent
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Goel%2C+S">Surbhi Goel</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Gollakota%2C+A">Aravind Gollakota</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Jin%2C+Z">Zhihan Jin</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Karmalkar%2C+S">Sushrut Karmalkar</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Klivans%2C+A">Adam Klivans</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2006.12011v2-abstract-short" style="display: inline;">
        We prove the first superpolynomial lower bounds for learning one-layer neural networks with respect to the Gaussian distribution using gradient descent. We show that any classifier trained using gradient descent with respect to square-loss will fail to achieve small test error in polynomial time given access to samples labeled by a one-layer neural network. For classification, we give a stronger r&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2006.12011v2-abstract-full').style.display = 'inline'; document.getElementById('2006.12011v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2006.12011v2-abstract-full" style="display: none;">
        We prove the first superpolynomial lower bounds for learning one-layer neural networks with respect to the Gaussian distribution using gradient descent. We show that any classifier trained using gradient descent with respect to square-loss will fail to achieve small test error in polynomial time given access to samples labeled by a one-layer neural network. For classification, we give a stronger result, namely that any statistical query (SQ) algorithm (including gradient descent) will fail to achieve small test error in polynomial time. Prior work held only for gradient descent run with small batch sizes, required sharp activations, and applied to specific classes of queries. Our lower bounds hold for broad classes of activations including ReLU and sigmoid. The core of our result relies on a novel construction of a simple family of neural networks that are exactly orthogonal with respect to all spherically symmetric distributions.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2006.12011v2-abstract-full').style.display = 'none'; document.getElementById('2006.12011v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 22 October, 2020; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 22 June, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">25 pages, ICML 2020</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2005.12844">arXiv:2005.12844</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2005.12844">pdf</a>, <a href="https://arxiv.org/format/2005.12844">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Data Structures and Algorithms">cs.DS</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Approximation Schemes for ReLU Regression
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Diakonikolas%2C+I">Ilias Diakonikolas</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Goel%2C+S">Surbhi Goel</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Karmalkar%2C+S">Sushrut Karmalkar</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Klivans%2C+A+R">Adam R. Klivans</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Soltanolkotabi%2C+M">Mahdi Soltanolkotabi</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2005.12844v2-abstract-short" style="display: inline;">
        We consider the fundamental problem of ReLU regression, where the goal is to output the best fitting ReLU with respect to square loss given access to draws from some unknown distribution. We give the first efficient, constant-factor approximation algorithm for this problem assuming the underlying distribution satisfies some weak concentration and anti-concentration conditions (and includes, for ex&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2005.12844v2-abstract-full').style.display = 'inline'; document.getElementById('2005.12844v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2005.12844v2-abstract-full" style="display: none;">
        We consider the fundamental problem of ReLU regression, where the goal is to output the best fitting ReLU with respect to square loss given access to draws from some unknown distribution. We give the first efficient, constant-factor approximation algorithm for this problem assuming the underlying distribution satisfies some weak concentration and anti-concentration conditions (and includes, for example, all log-concave distributions). This solves the main open problem of Goel et al., who proved hardness results for any exact algorithm for ReLU regression (up to an additive $ε$). Using more sophisticated techniques, we can improve our results and obtain a polynomial-time approximation scheme for any subgaussian distribution. Given the aforementioned hardness results, these guarantees can not be substantially improved.
  Our main insight is a new characterization of surrogate losses for nonconvex activations. While prior work had established the existence of convex surrogates for monotone activations, we show that properties of the underlying distribution actually induce strong convexity for the loss, allowing us to relate the global minimum to the activation&#39;s Chow parameters.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2005.12844v2-abstract-full').style.display = 'none'; document.getElementById('2005.12844v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 28 September, 2020; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 26 May, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2005.07652">arXiv:2005.07652</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2005.07652">pdf</a>, <a href="https://arxiv.org/ps/2005.07652">ps</a>, <a href="https://arxiv.org/format/2005.07652">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Data Structures and Algorithms">cs.DS</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Efficiently Learning Adversarially Robust Halfspaces with Noise
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Montasser%2C+O">Omar Montasser</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Goel%2C+S">Surbhi Goel</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Diakonikolas%2C+I">Ilias Diakonikolas</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Srebro%2C+N">Nathan Srebro</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2005.07652v1-abstract-short" style="display: inline;">
        We study the problem of learning adversarially robust halfspaces in the distribution-independent setting. In the realizable setting, we provide necessary and sufficient conditions on the adversarial perturbation sets under which halfspaces are efficiently robustly learnable. In the presence of random label noise, we give a simple computationally efficient algorithm for this problem with respect to&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2005.07652v1-abstract-full').style.display = 'inline'; document.getElementById('2005.07652v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2005.07652v1-abstract-full" style="display: none;">
        We study the problem of learning adversarially robust halfspaces in the distribution-independent setting. In the realizable setting, we provide necessary and sufficient conditions on the adversarial perturbation sets under which halfspaces are efficiently robustly learnable. In the presence of random label noise, we give a simple computationally efficient algorithm for this problem with respect to any $\ell_p$-perturbation.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2005.07652v1-abstract-full').style.display = 'none'; document.getElementById('2005.07652v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 May, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2003.07996">arXiv:2003.07996</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2003.07996">pdf</a>, <a href="https://arxiv.org/format/2003.07996">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Sound">cs.SD</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Audio and Speech Processing">eess.AS</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Cross Lingual Cross Corpus Speech Emotion Recognition
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Goel%2C+S">Shivali Goel</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Beigi%2C+H">Homayoon Beigi</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2003.07996v1-abstract-short" style="display: inline;">
        The majority of existing speech emotion recognition models are trained and evaluated on a single corpus and a single language setting. These systems do not perform as well when applied in a cross-corpus and cross-language scenario. This paper presents results for speech emotion recognition for 4 languages in both single corpus and cross corpus setting. Additionally, since multi-task learning (MTL)&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2003.07996v1-abstract-full').style.display = 'inline'; document.getElementById('2003.07996v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2003.07996v1-abstract-full" style="display: none;">
        The majority of existing speech emotion recognition models are trained and evaluated on a single corpus and a single language setting. These systems do not perform as well when applied in a cross-corpus and cross-language scenario. This paper presents results for speech emotion recognition for 4 languages in both single corpus and cross corpus setting. Additionally, since multi-task learning (MTL) with gender, naturalness and arousal as auxiliary tasks has shown to enhance the generalisation capabilities of the emotion models, this paper introduces language ID as another auxiliary task in MTL framework to explore the role of spoken language on emotion recognition which has not been studied yet.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2003.07996v1-abstract-full').style.display = 'none'; document.getElementById('2003.07996v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 17 March, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">7 pages, 2 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1912.10285">arXiv:1912.10285</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1912.10285">pdf</a>, <a href="https://arxiv.org/ps/1912.10285">ps</a>, <a href="https://arxiv.org/format/1912.10285">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Logic in Computer Science">cs.LO</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Verifying x86 Instruction Implementations
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Goel%2C+S">Shilpi Goel</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Slobodova%2C+A">Anna Slobodova</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Sumners%2C+R">Rob Sumners</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Swords%2C+S">Sol Swords</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1912.10285v1-abstract-short" style="display: inline;">
        Verification of modern microprocessors is a complex task that requires a substantial allocation of resources. Despite significant progress in formal verification, the goal of complete verification of an industrial design has not been achieved. In this paper, we describe a current contribution of formal methods to the validation of modern x86 microprocessors at Centaur Technology. We focus on provi&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1912.10285v1-abstract-full').style.display = 'inline'; document.getElementById('1912.10285v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1912.10285v1-abstract-full" style="display: none;">
        Verification of modern microprocessors is a complex task that requires a substantial allocation of resources. Despite significant progress in formal verification, the goal of complete verification of an industrial design has not been achieved. In this paper, we describe a current contribution of formal methods to the validation of modern x86 microprocessors at Centaur Technology. We focus on proving correctness of instruction implementations, which includes the decoding of an instruction, its translation into a sequence of micro-operations, any subsequent execution of traps to microcode ROM, and the implementation of these micro-operations in execution units. All these tasks are performed within one verification framework, which includes a theorem prover, a verified symbolic simulator, and SAT solvers. We describe the work of defining the needed formal models for both the architecture and micro-architecture in this framework, as well as tools for decomposing the requisite properties into smaller lemmas which can be automatically checked. We additionally cover the advantages and limitations of our approach. To our knowledge, there are no similar results in the verification of implementations of an x86 microprocessor.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1912.10285v1-abstract-full').style.display = 'none'; document.getElementById('1912.10285v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 21 December, 2019; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2019.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Pre-Print of CPP2020 Paper</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1911.02715">arXiv:1911.02715</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1911.02715">pdf</a>, <a href="https://arxiv.org/format/1911.02715">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computer Science and Game Theory">cs.GT</span>
          
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1145/3375627.3375823">10.1145/3375627.3375823 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Fair Allocation through Selective Information Acquisition
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Cai%2C+W">William Cai</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Gaebler%2C+J">Johann Gaebler</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Garg%2C+N">Nikhil Garg</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Goel%2C+S">Sharad Goel</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1911.02715v3-abstract-short" style="display: inline;">
        Public and private institutions must often allocate scare resources under uncertainty. Banks, for example, extend credit to loan applicants based in part on their estimated likelihood of repaying a loan. But when the quality of information differs across candidates (e.g., if some applicants lack traditional credit histories), common lending strategies can lead to disparities across groups. Here we&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1911.02715v3-abstract-full').style.display = 'inline'; document.getElementById('1911.02715v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1911.02715v3-abstract-full" style="display: none;">
        Public and private institutions must often allocate scare resources under uncertainty. Banks, for example, extend credit to loan applicants based in part on their estimated likelihood of repaying a loan. But when the quality of information differs across candidates (e.g., if some applicants lack traditional credit histories), common lending strategies can lead to disparities across groups. Here we consider a setting in which decision makers -- before allocating resources -- can choose to spend some of their limited budget further screening select individuals. We present a computationally efficient algorithm for deciding whom to screen that maximizes a standard measure of social welfare. Intuitively, decision makers should screen candidates on the margin, for whom the additional information could plausibly alter the allocation. We formalize this idea by showing the problem can be reduced to solving a series of linear programs. Both on synthetic and real-world datasets, this strategy improves utility, illustrating the value of targeted information acquisition in such decisions. Further, when there is social value for distributing resources to groups for whom we have a priori poor information -- like those without credit scores -- our approach can substantially improve the allocation of limited assets.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1911.02715v3-abstract-full').style.display = 'none'; document.getElementById('1911.02715v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 29 September, 2020; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 6 November, 2019;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2019.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">To appear in Proceedings of the 2020 AAAI/ACM Conference on AI, Ethics, and Society (AIES). Update: Fully specified the definition of threshold policies</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1911.01462">arXiv:1911.01462</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1911.01462">pdf</a>, <a href="https://arxiv.org/ps/1911.01462">ps</a>, <a href="https://arxiv.org/format/1911.01462">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Data Structures and Algorithms">cs.DS</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Time/Accuracy Tradeoffs for Learning a ReLU with respect to Gaussian Marginals
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Goel%2C+S">Surbhi Goel</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Karmalkar%2C+S">Sushrut Karmalkar</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Klivans%2C+A">Adam Klivans</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1911.01462v1-abstract-short" style="display: inline;">
        We consider the problem of computing the best-fitting ReLU with respect to square-loss on a training set when the examples have been drawn according to a spherical Gaussian distribution (the labels can be arbitrary). Let $\mathsf{opt} &lt; 1$ be the population loss of the best-fitting ReLU. We prove:
  1. Finding a ReLU with square-loss $\mathsf{opt} + ε$ is as hard as the problem of learning sparse&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1911.01462v1-abstract-full').style.display = 'inline'; document.getElementById('1911.01462v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1911.01462v1-abstract-full" style="display: none;">
        We consider the problem of computing the best-fitting ReLU with respect to square-loss on a training set when the examples have been drawn according to a spherical Gaussian distribution (the labels can be arbitrary). Let $\mathsf{opt} &lt; 1$ be the population loss of the best-fitting ReLU. We prove:
  1. Finding a ReLU with square-loss $\mathsf{opt} + ε$ is as hard as the problem of learning sparse parities with noise, widely thought to be computationally intractable. This is the first hardness result for learning a ReLU with respect to Gaussian marginals, and our results imply -{\emph unconditionally}- that gradient descent cannot converge to the global minimum in polynomial time.
  2. There exists an efficient approximation algorithm for finding the best-fitting ReLU that achieves error $O(\mathsf{opt}^{2/3})$. The algorithm uses a novel reduction to noisy halfspace learning with respect to $0/1$ loss.
  Prior work due to Soltanolkotabi [Sol17] showed that gradient descent can find the best-fitting ReLU with respect to Gaussian marginals, if the training set is exactly labeled by a ReLU.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1911.01462v1-abstract-full').style.display = 'none'; document.getElementById('1911.01462v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 4 November, 2019; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2019.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">To appear in NeurIPS 2019 (Spotlight)</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1909.03543">arXiv:1909.03543</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1909.03543">pdf</a>, <a href="https://arxiv.org/format/1909.03543">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Social and Information Networks">cs.SI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Physics and Society">physics.soc-ph</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        An Experimental Study of Structural Diversity in Social Networks
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Su%2C+J">Jessica Su</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Kamath%2C+K">Krishna Kamath</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Sharma%2C+A">Aneesh Sharma</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Ugander%2C+J">Johan Ugander</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Goel%2C+S">Sharad Goel</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1909.03543v2-abstract-short" style="display: inline;">
        Several recent studies of online social networking platforms have found that adoption rates and engagement levels are positively correlated with structural diversity, the degree of heterogeneity among an individual&#39;s contacts as measured by network ties. One common theory for this observation is that structural diversity increases utility, in part because there is value to interacting with people&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1909.03543v2-abstract-full').style.display = 'inline'; document.getElementById('1909.03543v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1909.03543v2-abstract-full" style="display: none;">
        Several recent studies of online social networking platforms have found that adoption rates and engagement levels are positively correlated with structural diversity, the degree of heterogeneity among an individual&#39;s contacts as measured by network ties. One common theory for this observation is that structural diversity increases utility, in part because there is value to interacting with people from different network components on the same platform. While compelling, evidence for this causal theory comes from observational studies, making it difficult to rule out non-causal explanations. We investigate the role of structural diversity on retention by conducting a large-scale randomized controlled study on the Twitter platform. We first show that structural diversity correlates with user retention on Twitter, corroborating results from past observational studies. We then exogenously vary structural diversity by altering the set of network recommendations new users see when joining the platform; we confirm that this design induces the desired changes to network topology. We find, however, that low, medium, and high structural diversity treatment groups in our experiment have comparable retention rates. Thus, at least in this case, the observed correlation between structural diversity and retention does not appear to result from a causal relationship, challenging theories based on past observational studies.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1909.03543v2-abstract-full').style.display = 'none'; document.getElementById('1909.03543v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 9 September, 2019; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 8 September, 2019;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2019.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">To appear in the Proceedings of International AAAI Conference on Web and Social Media (ICWSM 2020)</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1906.06595">arXiv:1906.06595</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1906.06595">pdf</a>, <a href="https://arxiv.org/ps/1906.06595">ps</a>, <a href="https://arxiv.org/format/1906.06595">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Data Structures and Algorithms">cs.DS</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Learning Restricted Boltzmann Machines with Arbitrary External Fields
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Goel%2C+S">Surbhi Goel</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1906.06595v1-abstract-short" style="display: inline;">
        We study the problem of learning graphical models with latent variables. We give the first algorithm for learning locally consistent (ferromagnetic or antiferromagnetic) Restricted Boltzmann Machines (or RBMs) with {\em arbitrary} external fields. Our algorithm has optimal dependence on dimension in the sample complexity and run time however it suffers from a sub-optimal dependency on the underlyi&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1906.06595v1-abstract-full').style.display = 'inline'; document.getElementById('1906.06595v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1906.06595v1-abstract-full" style="display: none;">
        We study the problem of learning graphical models with latent variables. We give the first algorithm for learning locally consistent (ferromagnetic or antiferromagnetic) Restricted Boltzmann Machines (or RBMs) with {\em arbitrary} external fields. Our algorithm has optimal dependence on dimension in the sample complexity and run time however it suffers from a sub-optimal dependency on the underlying parameters of the RBM.
  Prior results have been established only for {\em ferromagnetic} RBMs with {\em consistent} external fields (signs must be same)\cite{bresler2018learning}. The proposed algorithm strongly relies on the concavity of magnetization which does not hold in our setting. We show the following key structural property: even in the presence of arbitrary external field, for any two observed nodes that share a common latent neighbor, the covariance is high. This enables us to design a simple greedy algorithm that maximizes covariance to iteratively build the neighborhood of each vertex.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1906.06595v1-abstract-full').style.display = 'none'; document.getElementById('1906.06595v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 June, 2019; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2019.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1906.06057">arXiv:1906.06057</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1906.06057">pdf</a>, <a href="https://arxiv.org/ps/1906.06057">ps</a>, <a href="https://arxiv.org/format/1906.06057">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Social and Information Networks">cs.SI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Learning Mixtures of Graphs from Epidemic Cascades
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Hoffmann%2C+J">Jessica Hoffmann</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Basu%2C+S">Soumya Basu</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Goel%2C+S">Surbhi Goel</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Caramanis%2C+C">Constantine Caramanis</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1906.06057v2-abstract-short" style="display: inline;">
        We consider the problem of learning the weighted edges of a balanced mixture of two undirected graphs from epidemic cascades. While mixture models are popular modeling tools, algorithmic development with rigorous guarantees has lagged. Graph mixtures are apparently no exception: until now, very little is known about whether this problem is solvable.
  To the best of our knowledge, we establish the&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1906.06057v2-abstract-full').style.display = 'inline'; document.getElementById('1906.06057v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1906.06057v2-abstract-full" style="display: none;">
        We consider the problem of learning the weighted edges of a balanced mixture of two undirected graphs from epidemic cascades. While mixture models are popular modeling tools, algorithmic development with rigorous guarantees has lagged. Graph mixtures are apparently no exception: until now, very little is known about whether this problem is solvable.
  To the best of our knowledge, we establish the first necessary and sufficient conditions for this problem to be solvable in polynomial time on edge-separated graphs. When the conditions are met, i.e., when the graphs are connected with at least three edges, we give an efficient algorithm for learning the weights of both graphs with optimal sample complexity (up to log factors).
  We give complimentary results and provide sample-optimal (up to log factors) algorithms for mixtures of directed graphs of out-degree at least three, for mixture of undirected graphs of unbalanced and/or unknown priors.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1906.06057v2-abstract-full').style.display = 'none'; document.getElementById('1906.06057v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 29 January, 2020; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 14 June, 2019;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2019.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">29 pages</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1904.11388">arXiv:1904.11388</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1904.11388">pdf</a>, <a href="https://arxiv.org/format/1904.11388">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Information Retrieval">cs.IR</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Identifying short-term interests from mobile app adoption pattern
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Gaind%2C+B">Bharat Gaind</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Varshney%2C+N">Nitish Varshney</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Goel%2C+S">Shubham Goel</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Mondal%2C+A">Akash Mondal</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1904.11388v1-abstract-short" style="display: inline;">
        With the increase in an average user&#39;s dependence on their mobile devices, the reliance on collecting his browsing history from mobile browsers has also increased. This browsing history is highly utilized in the advertising industry for providing targeted ads in the purview of inferring his short-term interests and pushing relevant ads. However, the major limitation of such an extraction from mobi&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1904.11388v1-abstract-full').style.display = 'inline'; document.getElementById('1904.11388v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1904.11388v1-abstract-full" style="display: none;">
        With the increase in an average user&#39;s dependence on their mobile devices, the reliance on collecting his browsing history from mobile browsers has also increased. This browsing history is highly utilized in the advertising industry for providing targeted ads in the purview of inferring his short-term interests and pushing relevant ads. However, the major limitation of such an extraction from mobile browsers is that they reset when the browser is closed or when the device is shut down/restarted; thus rendering existing methods to identify the user&#39;s short-term interests on mobile devices users, ineffective. In this paper, we propose an alternative method to identify such short-term interests by analysing their mobile app adoption (installation/uninstallation) patterns over a period of time. Such a method can be highly effective in pinpointing the user&#39;s ephemeral inclinations like buying/renting an apartment, buying/selling a car or a sudden increased interest in shopping (possibly due to a recent salary bonus, he received). Subsequently, these derived interests are also used for targeted experiments. Our experiments result in up to 93.68% higher click-through rate in comparison to the ads shown without any user-interest knowledge. Also, up to 51% higher revenue in the long term is expected as a result of the application of our proposed algorithm.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1904.11388v1-abstract-full').style.display = 'none'; document.getElementById('1904.11388v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 25 April, 2019; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2019.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted and presented in the 20th International Conference on Computational Linguistics and Intelligent Text Processing, France, 2019 and soon to be published in the Computación y Sistemas (Scopus-indexed) journal</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1903.09231">arXiv:1903.09231</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1903.09231">pdf</a>, <a href="https://arxiv.org/ps/1903.09231">ps</a>, <a href="https://arxiv.org/format/1903.09231">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Recovering the Lowest Layer of Deep Networks with High Threshold Activations
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Goel%2C+S">Surbhi Goel</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Panigrahy%2C+R">Rina Panigrahy</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1903.09231v2-abstract-short" style="display: inline;">
        Giving provable guarantees for learning neural networks is a core challenge of machine learning theory. Most prior work gives parameter recovery guarantees for one hidden layer networks, however, the networks used in practice have multiple non-linear layers. In this work, we show how we can strengthen such results to deeper networks -- we address the problem of uncovering the lowest layer in a dee&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1903.09231v2-abstract-full').style.display = 'inline'; document.getElementById('1903.09231v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1903.09231v2-abstract-full" style="display: none;">
        Giving provable guarantees for learning neural networks is a core challenge of machine learning theory. Most prior work gives parameter recovery guarantees for one hidden layer networks, however, the networks used in practice have multiple non-linear layers. In this work, we show how we can strengthen such results to deeper networks -- we address the problem of uncovering the lowest layer in a deep neural network under the assumption that the lowest layer uses a high threshold before applying the activation, the upper network can be modeled as a well-behaved polynomial and the input distribution is Gaussian.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1903.09231v2-abstract-full').style.display = 'none'; document.getElementById('1903.09231v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 19 February, 2020; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 21 March, 2019;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2019.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1903.03308">arXiv:1903.03308</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1903.03308">pdf</a>, <a href="https://arxiv.org/format/1903.03308">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Thanks for Stopping By: A Study of &#34;Thanks&#34; Usage on Wikimedia
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Goel%2C+S">Swati Goel</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Anderson%2C+A">Ashton Anderson</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Zia%2C+L">Leila Zia</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1903.03308v1-abstract-short" style="display: inline;">
        The Thanks feature on Wikipedia, also known as &#34;Thanks&#34;, is a tool with which editors can quickly and easily send one other positive feedback. The aim of this project is to better understand this feature: its scope, the characteristics of a typical &#34;Thanks&#34; interaction, and the effects of receiving a thank on individual editors. We study the motivational impacts of &#34;Thanks&#34; because maintaining edi&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1903.03308v1-abstract-full').style.display = 'inline'; document.getElementById('1903.03308v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1903.03308v1-abstract-full" style="display: none;">
        The Thanks feature on Wikipedia, also known as &#34;Thanks&#34;, is a tool with which editors can quickly and easily send one other positive feedback. The aim of this project is to better understand this feature: its scope, the characteristics of a typical &#34;Thanks&#34; interaction, and the effects of receiving a thank on individual editors. We study the motivational impacts of &#34;Thanks&#34; because maintaining editor engagement is a central problem for crowdsourced repositories of knowledge such as Wikimedia. Our main findings are that most editors have not been exposed to the Thanks feature (meaning they have never given nor received a thank), thanks are typically sent upwards (from less experienced to more experienced editors), and receiving a thank is correlated with having high levels of editor engagement. Though the prevalence of &#34;Thanks&#34; usage varies by editor experience, the impact of receiving a thank seems mostly consistent for all users. We empirically demonstrate that receiving a thank has a strong positive effect on short-term editor activity across the board and provide preliminary evidence that thanks could compound to have long-term effects as well.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1903.03308v1-abstract-full').style.display = 'none'; document.getElementById('1903.03308v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 March, 2019; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2019.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1902.08265">arXiv:1902.08265</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1902.08265">pdf</a>, <a href="https://arxiv.org/format/1902.08265">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Quantifying Perceptual Distortion of Adversarial Examples
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Jordan%2C+M">Matt Jordan</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Manoj%2C+N">Naren Manoj</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Goel%2C+S">Surbhi Goel</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Dimakis%2C+A+G">Alexandros G. Dimakis</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1902.08265v1-abstract-short" style="display: inline;">
        Recent work has shown that additive threat models, which only permit the addition of bounded noise to the pixels of an image, are insufficient for fully capturing the space of imperceivable adversarial examples. For example, small rotations and spatial transformations can fool classifiers, remain imperceivable to humans, but have large additive distance from the original images. In this work, we l&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1902.08265v1-abstract-full').style.display = 'inline'; document.getElementById('1902.08265v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1902.08265v1-abstract-full" style="display: none;">
        Recent work has shown that additive threat models, which only permit the addition of bounded noise to the pixels of an image, are insufficient for fully capturing the space of imperceivable adversarial examples. For example, small rotations and spatial transformations can fool classifiers, remain imperceivable to humans, but have large additive distance from the original images. In this work, we leverage quantitative perceptual metrics like LPIPS and SSIM to define a novel threat model for adversarial attacks.
  To demonstrate the value of quantifying the perceptual distortion of adversarial examples, we present and employ a unifying framework fusing different attack styles. We first prove that our framework results in images that are unattainable by attack styles in isolation. We then perform adversarial training using attacks generated by our framework to demonstrate that networks are only robust to classes of adversarial perturbations they have been trained against, and combination attacks are stronger than any of their individual components. Finally, we experimentally demonstrate that our combined attacks retain the same perceptual distortion but induce far higher misclassification rates when compared against individual attacks.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1902.08265v1-abstract-full').style.display = 'none'; document.getElementById('1902.08265v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 21 February, 2019; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2019.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">18 pages, codebase/framework available at https://github.com/revbucket/mister_ed</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1902.04728">arXiv:1902.04728</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1902.04728">pdf</a>, <a href="https://arxiv.org/ps/1902.04728">ps</a>, <a href="https://arxiv.org/format/1902.04728">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Data Structures and Algorithms">cs.DS</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Learning Ising Models with Independent Failures
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Goel%2C+S">Surbhi Goel</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Kane%2C+D+M">Daniel M. Kane</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Klivans%2C+A+R">Adam R. Klivans</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1902.04728v1-abstract-short" style="display: inline;">
        We give the first efficient algorithm for learning the structure of an Ising model that tolerates independent failures; that is, each entry of the observed sample is missing with some unknown probability p. Our algorithm matches the essentially optimal runtime and sample complexity bounds of recent work for learning Ising models due to Klivans and Meka (2017).
  We devise a novel unbiased estimato&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1902.04728v1-abstract-full').style.display = 'inline'; document.getElementById('1902.04728v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1902.04728v1-abstract-full" style="display: none;">
        We give the first efficient algorithm for learning the structure of an Ising model that tolerates independent failures; that is, each entry of the observed sample is missing with some unknown probability p. Our algorithm matches the essentially optimal runtime and sample complexity bounds of recent work for learning Ising models due to Klivans and Meka (2017).
  We devise a novel unbiased estimator for the gradient of the Interaction Screening Objective (ISO) due to Vuffray et al. (2016) and apply a stochastic multiplicative gradient descent algorithm to minimize this objective. Solutions to this minimization recover the neighborhood information of the underlying Ising model on a node by node basis.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1902.04728v1-abstract-full').style.display = 'none'; document.getElementById('1902.04728v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 12 February, 2019; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2019.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1810.04313">arXiv:1810.04313</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1810.04313">pdf</a>, <a href="https://arxiv.org/ps/1810.04313">ps</a>, <a href="https://arxiv.org/format/1810.04313">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Logic in Computer Science">cs.LO</span>
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.4204/EPTCS.280.6">10.4204/EPTCS.280.6 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Adding 32-bit Mode to the ACL2 Model of the x86 ISA
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Coglio%2C+A">Alessandro Coglio</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Goel%2C+S">Shilpi Goel</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1810.04313v1-abstract-short" style="display: inline;">
        The ACL2 model of the x86 Instruction Set Architecture was built for the 64-bit mode of operation of the processor. This paper reports on our work to extend the model with support for 32-bit mode, recounting the salient aspects of this activity and identifying the ones that required the most work.
        
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1810.04313v1-abstract-full" style="display: none;">
        The ACL2 model of the x86 Instruction Set Architecture was built for the 64-bit mode of operation of the processor. This paper reports on our work to extend the model with support for 32-bit mode, recounting the salient aspects of this activity and identifying the ones that required the most work.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1810.04313v1-abstract-full').style.display = 'none'; document.getElementById('1810.04313v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 9 October, 2018; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2018.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">In Proceedings ACL2 2018, arXiv:1810.03762</span>
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        EPTCS 280, 2018, pp. 77-94
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1810.03762">arXiv:1810.03762</a>
        <span>&nbsp;&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Symbolic Computation">cs.SC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Logic in Computer Science">cs.LO</span>
          
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.4204/EPTCS.280">10.4204/EPTCS.280 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Proceedings of the 15th International Workshop on the ACL2 Theorem Prover and Its Applications
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Goel%2C+S">Shilpi Goel</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Kaufmann%2C+M">Matt Kaufmann</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1810.03762v2-abstract-short" style="display: inline;">
        This volume contains the proceedings of the Fifteenth International Workshop on the ACL2 Theorem Prover and Its Applications (ACL2-2018), a two-day workshop held in Austin, Texas, USA, on November 5-6, 2018, immediately after FMCAD&#39;18.  The proceedings of ACL2-2018 include eleven long papers and two extended abstracts.
        
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1810.03762v2-abstract-full" style="display: none;">
        This volume contains the proceedings of the Fifteenth International Workshop on the ACL2 Theorem Prover and Its Applications (ACL2-2018), a two-day workshop held in Austin, Texas, USA, on November 5-6, 2018, immediately after FMCAD&#39;18.  The proceedings of ACL2-2018 include eleven long papers and two extended abstracts.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1810.03762v2-abstract-full').style.display = 'none'; document.getElementById('1810.03762v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 29 October, 2018; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 8 October, 2018;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2018.
      
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        EPTCS 280, 2018
      </p>
    
  </li>

</ol>


  <nav class="pagination is-small is-centered breathe-horizontal" role="navigation" aria-label="pagination">
    
    <a href=""
      class="pagination-previous is-invisible">Previous
    </a>
    
    
      <a href="/search/?searchtype=author&amp;query=Goel%2C+S&amp;start=50"
        class="pagination-next" >Next
      </a>
    
    <ul class="pagination-list">

      <li>
        <a href="/search/?searchtype=author&amp;query=Goel%2C+S&amp;start=0"
          class="pagination-link is-current"
          aria-label="Goto page 1">1
        </a>
      </li>

      
        
        <li>
          <a href="/search/?searchtype=author&amp;query=Goel%2C+S&amp;start=50"
            class="pagination-link "
            aria-label="Page 2"
            aria-current="page">2
          </a>
        </li>
        
      
    </ul>
  </nav>
  

  


      <div class="is-hidden-tablet">
        <!-- feedback for mobile only -->
        <span class="help" style="display: inline-block;"><a href="https://github.com/arXiv/arxiv-search/releases">Search v0.5.6 released 2020-02-24</a>&nbsp;&nbsp;</span>
        <button class="button is-small" id="feedback-button">Feedback?</button>
      </div>
    </div>

  </main>
  <footer>
    
    <div class="columns is-desktop" role="navigation" aria-label="Secondary">
  <!-- MetaColumn 1 -->
  <div class="column">
    <div class="columns">
      <div class="column">
        <ul class="nav-spaced">
          <li><a href="https://arxiv.org/about">About</a></li>
          <li><a href="https://arxiv.org/help">Help</a></li>
        </ul>
      </div>
      <div class="column">
        <ul class="nav-spaced">
          <li>
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
            <a href="https://arxiv.org/help/contact"> Contact</a>
          </li>
          <li>
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
            <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
          </li>
        </ul>
      </div>
    </div>
  </div> <!-- end MetaColumn 1 -->
  <!-- MetaColumn 2 -->
  <div class="column">
    <div class="columns">
      <div class="column">
        <ul class="nav-spaced">
          <li><a href="https://arxiv.org/help/license">Copyright</a></li>
          <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
        </ul>
      </div>
      <div class="column sorry-app-links">
        <ul class="nav-spaced">
          <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
          <li>
            <p class="help">
              <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
              Get status notifications via
              <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
              or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
            </p>
          </li>
        </ul>
      </div>
    </div>
  </div> <!-- end MetaColumn 2 -->
</div>
    
  </footer>
  </body>
</html>