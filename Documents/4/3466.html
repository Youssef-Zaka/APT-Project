<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<!-- new favicon config and versions by realfavicongenerator.net -->
<link rel="apple-touch-icon" sizes="180x180" href="https://static.arxiv.org/static/base/0.17.4.post2/images/icons/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://static.arxiv.org/static/base/0.17.4.post2/images/icons/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="https://static.arxiv.org/static/base/0.17.4.post2/images/icons/favicon-16x16.png">
<link rel="manifest" href="https://static.arxiv.org/static/base/0.17.4.post2/images/icons/site.webmanifest">
<link rel="mask-icon" href="https://static.arxiv.org/static/base/0.17.4.post2/images/icons/safari-pinned-tab.svg" color="#b31b1b">
<link rel="shortcut icon" href="https://static.arxiv.org/static/base/0.17.4.post2/images/icons/favicon.ico">
<meta name="msapplication-TileColor" content="#b31b1b">
<meta name="msapplication-config" content="images/icons/browserconfig.xml">
<meta name="theme-color" content="#b31b1b">
<!-- end favicon config -->
<title>Search | arXiv e-print repository</title>
<script defer src="https://static.arxiv.org/static/base/0.17.4.post2/fontawesome-free-5.11.2-web/js/all.js"></script>
<link rel="stylesheet" href="https://static.arxiv.org/static/base/0.17.4.post2/css/arxivstyle.css" />
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    messageStyle: "none",
    extensions: ["tex2jax.js"],
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
      processEscapes: true,
      ignoreClass: '.*',
      processClass: 'mathjax.*'
    },
    TeX: {
        extensions: ["AMSmath.js", "AMSsymbols.js", "noErrors.js"],
        noErrors: {
          inlineDelimiters: ["$","$"],
          multiLine: false,
          style: {
            "font-size": "normal",
            "border": ""
          }
        }
    },
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>
<script src='//static.arxiv.org/MathJax-2.7.3/MathJax.js'></script>
<script src="https://static.arxiv.org/static/base/0.17.4.post2/js/notification.js"></script>

    
  <link rel="stylesheet" href="https://static.arxiv.org/static/search/0.5.6/css/bulma-tooltip.min.css" />
  <link rel="stylesheet" href="https://static.arxiv.org/static/search/0.5.6/css/search.css" />
  <script
    src="https://code.jquery.com/jquery-3.2.1.slim.min.js"
    integrity="sha256-k2WSCIexGzOj3Euiig+TlR8gA0EmPjuc79OEeY5L45g="
    crossorigin="anonymous"></script>

  <script src="https://static.arxiv.org/static/search/0.5.6/js/fieldset.js"></script>
  <style>
  radio#cf-customfield_11400 {
    display: none;
  }
  </style>
  <script type="text/javascript" src="https://arxiv-org.atlassian.net/s/d41d8cd98f00b204e9800998ecf8427e-T/-tqqyqk/b/20/a44af77267a987a660377e5c46e0fb64/_/download/batch/com.atlassian.jira.collector.plugin.jira-issue-collector-plugin:issuecollector/com.atlassian.jira.collector.plugin.jira-issue-collector-plugin:issuecollector.js?locale=en-US&collectorId=3b3dcb4c"></script>

    <script type="text/javascript">
    window.ATL_JQ_PAGE_PROPS =  {
    	"triggerFunction": function(showCollectorDialog) {
    		//Requires that jQuery is available!
    		$("#feedback-button").click(function(e) {
    			e.preventDefault();
    			showCollectorDialog();
    		});
    	},
      fieldValues: {
        "components": ["16000"],  // Search component.
        "versions": ["14260"],  // Release search-0.5.6
        "customfield_11401": window.location.href
      }
    };
    </script>

  </head>
  <body>
  
  
  <header><a href="#main-container" class="is-sr-only">Skip to main content</a>
    
    <!-- contains Cornell logo and sponsor statement -->
<div class="attribution level is-marginless" role="banner">
  <div class="level-left">
    <a class="level-item" href="https://cornell.edu/"><img src="https://static.arxiv.org/static/base/0.17.4.post2/images/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" aria-label="logo" /></a>
  </div>
  <div class="level-right is-marginless"><p class="sponsors level-item is-marginless"><a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a></p></div>
</div>
<!-- contains arXiv identity and search bar -->
<div class="identity level is-marginless">
  <div class="level-left">
    <div class="level-item">
      <a class="arxiv" href="https://arxiv.org/" aria-label="arxiv-logo">
        <img src="https://static.arxiv.org/static/base/0.17.4.post2/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;"/>
      </a>
    </div>
  </div>
  
  <div class="search-block level-right">
    <form class="level-item mini-search" method="GET" action="https://arxiv.org/search">
      <div class="field has-addons">
        <div class="control">
          <input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" />
          <p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
        </div>
        <div class="control">
          <div class="select is-small">
            <select name="searchtype" aria-label="Field to search">
              <option value="all" selected="selected">All fields</option>
              <option value="title">Title</option>
              <option value="author">Author</option>
              <option value="abstract">Abstract</option>
              <option value="comments">Comments</option>
              <option value="journal_ref">Journal reference</option>
              <option value="acm_class">ACM classification</option>
              <option value="msc_class">MSC classification</option>
              <option value="report_num">Report number</option>
              <option value="paper_id">arXiv identifier</option>
              <option value="doi">DOI</option>
              <option value="orcid">ORCID</option>
              <option value="author_id">arXiv author ID</option>
              <option value="help">Help pages</option>
              <option value="full_text">Full text</option>
            </select>
          </div>
        </div>
        <input type="hidden" name="source" value="header">
        <button class="button is-small is-cul-darker">Search</button>
      </div>
    </form>
  </div>
</div> <!-- closes identity -->

<div class="container">
    <div class="user-tools is-size-7 has-text-right has-text-weight-bold" role="navigation" aria-label="User menu">
      <a href="https://arxiv.org/login">Login</a>
    </div>
</div>
    
  </header>
  <main class="container" id="main-container">
    


    
  <div class="level is-marginless">
    <div class="level-left">
      <h1 class="title is-clearfix">
    
        Showing 1&ndash;49 of 49 results for author: <span class="mathjax">Rudra, A</span>
    
</h1>
    </div>
    <div class="level-right is-hidden-mobile">
      <!-- feedback for mobile is moved to footer -->
      <span class="help" style="display: inline-block;"><a href="https://github.com/arXiv/arxiv-search/releases">Search v0.5.6 released 2020-02-24</a>&nbsp;&nbsp;</span>
      <button class="button is-small" id="feedback-button">Feedback?</button>
    </div>
  </div>
    <div class="content">
      
  <form method="GET" action="/search/cs"  aria-role="search">
    
      Searching in archive <strong>cs</strong>. <a href="/search/?searchtype=author&amp;query=Rudra%2C+A">Search in all archives.</a>
    

    
    <div class="field has-addons-tablet">
      <div class="control is-expanded">
        <label for="query" class="hidden-label">Search term or terms</label>
        
          <input class="input is-medium" id="query" name="query" placeholder="Search term..." type="text" value="Rudra, A">
        
        
      </div>
      <div class="select control is-medium">
        <label class="is-hidden" for="searchtype">Field</label>
        <select class="is-medium" id="searchtype" name="searchtype"><option value="all">All fields</option><option value="title">Title</option><option selected value="author">Author(s)</option><option value="abstract">Abstract</option><option value="comments">Comments</option><option value="journal_ref">Journal reference</option><option value="acm_class">ACM classification</option><option value="msc_class">MSC classification</option><option value="report_num">Report number</option><option value="paper_id">arXiv identifier</option><option value="doi">DOI</option><option value="orcid">ORCID</option><option value="license">License (URI)</option><option value="author_id">arXiv author ID</option><option value="help">Help pages</option><option value="full_text">Full text</option></select>
      </div>
      <div class="control">
          <button class="button is-link is-medium">Search</button>
      </div>
    </div>
    <div class="field">
      <div class="control is-size-7">
        
        <label class="radio">
          <input checked id="abstracts-0" name="abstracts" type="radio" value="show"> Show abstracts
        </label>
        
        <label class="radio">
          <input id="abstracts-1" name="abstracts" type="radio" value="hide"> Hide abstracts
        </label>
        
      </div>
    </div>
    <div class="is-clearfix" style="height: 2.5em"> 
      <div class="is-pulled-right">
        
        <a href="/search/advanced?terms-0-term=Rudra%2C+A&amp;terms-0-field=author&amp;size=50&amp;order=-announced_date_first">Advanced Search</a>
        
      </div>
    </div>
    <input type="hidden" name="order" value="-announced_date_first">
    <input type="hidden" name="size" value="50">
  </form>

  

  
      
<div class="level breathe-horizontal">
  <div class="level-left">
    <form method="GET" action="/search/">
      <div style="display: none;">
        
          
            <select id="searchtype" name="searchtype"><option value="all">All fields</option><option value="title">Title</option><option selected value="author">Author(s)</option><option value="abstract">Abstract</option><option value="comments">Comments</option><option value="journal_ref">Journal reference</option><option value="acm_class">ACM classification</option><option value="msc_class">MSC classification</option><option value="report_num">Report number</option><option value="paper_id">arXiv identifier</option><option value="doi">DOI</option><option value="orcid">ORCID</option><option value="license">License (URI)</option><option value="author_id">arXiv author ID</option><option value="help">Help pages</option><option value="full_text">Full text</option></select>
          
        
          
            <input id="query" name="query" type="text" value="Rudra, A">
          
        
          
        
          
        
          
            <ul id="abstracts"><li><input checked id="abstracts-0" name="abstracts" type="radio" value="show"> <label for="abstracts-0">Show abstracts</label></li><li><input id="abstracts-1" name="abstracts" type="radio" value="hide"> <label for="abstracts-1">Hide abstracts</label></li></ul>
          
        
      </div>
      <div class="box field is-grouped is-grouped-multiline level-item">
        <div class="control">
          <span class="select is-small">
            <select id="size" name="size"><option value="25">25</option><option selected value="50">50</option><option value="100">100</option><option value="200">200</option></select>
          </span>
          <label for="size">results per page</label>.
        </div>
        <div class="control">
          <label for="order">Sort results by</label>
          <span class="select is-small">
            <select id="order" name="order"><option selected value="-announced_date_first">Announcement date (newest first)</option><option value="announced_date_first">Announcement date (oldest first)</option><option value="-submitted_date">Submission date (newest first)</option><option value="submitted_date">Submission date (oldest first)</option><option value="">Relevance</option></select>
          </span>
        </div>
        <div class="control">
          <button class="button is-small is-link">Go</button>
        </div>
      </div>
    </form>
  </div>
</div>
      




<ol class="breathe-horizontal" start="1"> 


  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2204.02758">arXiv:2204.02758</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2204.02758">pdf</a>, <a href="https://arxiv.org/ps/2204.02758">ps</a>, <a href="https://arxiv.org/format/2204.02758">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Databases">cs.DB</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computational Complexity">cs.CC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Computing expected multiplicities for bag-TIDBs with bounded multiplicities
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Feng%2C+S">Su Feng</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Glavic%2C+B">Boris Glavic</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Huber%2C+A">Aaron Huber</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Kennedy%2C+O">Oliver Kennedy</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Rudra%2C+A">Atri Rudra</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2204.02758v1-abstract-short" style="display: inline;">
        In this work, we study the problem of computing a tuple&#39;s expected multiplicity over probabilistic databases with bag semantics (where each tuple is associated with a multiplicity) exactly and approximately. We consider bag-TIDBs where we have a bound $c$ on the maximum multiplicity of each tuple and tuples are independent probabilistic events (we refer to such databases as c-TIDBs. We are specifi&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2204.02758v1-abstract-full').style.display = 'inline'; document.getElementById('2204.02758v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2204.02758v1-abstract-full" style="display: none;">
        In this work, we study the problem of computing a tuple&#39;s expected multiplicity over probabilistic databases with bag semantics (where each tuple is associated with a multiplicity) exactly and approximately. We consider bag-TIDBs where we have a bound $c$ on the maximum multiplicity of each tuple and tuples are independent probabilistic events (we refer to such databases as c-TIDBs. We are specifically interested in the fine-grained complexity of computing expected multiplicities and how it compares to the complexity of deterministic query evaluation algorithms -- if these complexities are comparable, it opens the door to practical deployment of probabilistic databases. Unfortunately, our results imply that computing expected multiplicities for c-TIDBs based on the results produced by such query evaluation algorithms introduces super-linear overhead (under parameterized complexity hardness assumptions/conjectures). We proceed to study approximation of expected result tuple multiplicities for positive relational algebra queries ($RA^+$) over c-TIDBs and for a non-trivial subclass of block-independent databases (BIDBs). We develop a sampling algorithm that computes a 1$\pmε$ approximation of the expected multiplicity of an output tuple in time linear in the runtime of the corresponding deterministic query for any $RA^+$ query.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2204.02758v1-abstract-full').style.display = 'none'; document.getElementById('2204.02758v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 6 April, 2022; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2022.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2204.00595">arXiv:2204.00595</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2204.00595">pdf</a>, <a href="https://arxiv.org/format/2204.00595">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Monarch: Expressive Structured Matrices for Efficient and Accurate Training
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Dao%2C+T">Tri Dao</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Chen%2C+B">Beidi Chen</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Sohoni%2C+N">Nimit Sohoni</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Desai%2C+A">Arjun Desai</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Poli%2C+M">Michael Poli</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Grogan%2C+J">Jessica Grogan</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Liu%2C+A">Alexander Liu</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Rao%2C+A">Aniruddh Rao</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Rudra%2C+A">Atri Rudra</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=R%C3%A9%2C+C">Christopher Ré</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2204.00595v1-abstract-short" style="display: inline;">
        Large neural networks excel in many domains, but they are expensive to train and fine-tune. A popular approach to reduce their compute or memory requirements is to replace dense weight matrices with structured ones (e.g., sparse, low-rank, Fourier transform). These methods have not seen widespread adoption (1) in end-to-end training due to unfavorable efficiency--quality tradeoffs, and (2) in dens&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2204.00595v1-abstract-full').style.display = 'inline'; document.getElementById('2204.00595v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2204.00595v1-abstract-full" style="display: none;">
        Large neural networks excel in many domains, but they are expensive to train and fine-tune. A popular approach to reduce their compute or memory requirements is to replace dense weight matrices with structured ones (e.g., sparse, low-rank, Fourier transform). These methods have not seen widespread adoption (1) in end-to-end training due to unfavorable efficiency--quality tradeoffs, and (2) in dense-to-sparse fine-tuning due to lack of tractable algorithms to approximate a given dense weight matrix. To address these issues, we propose a class of matrices (Monarch) that is hardware-efficient (they are parameterized as products of two block-diagonal matrices for better hardware utilization) and expressive (they can represent many commonly used transforms). Surprisingly, the problem of approximating a dense weight matrix with a Monarch matrix, though nonconvex, has an analytical optimal solution. These properties of Monarch matrices unlock new ways to train and fine-tune sparse and dense models. We empirically validate that Monarch can achieve favorable accuracy-efficiency tradeoffs in several end-to-end sparse training applications: speeding up ViT and GPT-2 training on ImageNet classification and Wikitext-103 language modeling by 2x with comparable model quality, and reducing the error on PDE solving and MRI reconstruction tasks by 40%. In sparse-to-dense training, with a simple technique called &#34;reverse sparsification,&#34; Monarch matrices serve as a useful intermediate representation to speed up GPT-2 pretraining on OpenWebText by 2x without quality drop. The same technique brings 23% faster BERT pretraining than even the very optimized implementation from Nvidia that set the MLPerf 1.1 record. In dense-to-sparse fine-tuning, as a proof-of-concept, our Monarch approximation algorithm speeds up BERT fine-tuning on GLUE by 1.7x with comparable accuracy.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2204.00595v1-abstract-full').style.display = 'none'; document.getElementById('2204.00595v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 1 April, 2022; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2022.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2112.01003">arXiv:2112.01003</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2112.01003">pdf</a>, <a href="https://arxiv.org/format/2112.01003">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Databases">cs.DB</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Worst-case Optimal Binary Join Algorithms under General $\ell_p$ Constraints
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Jayaraman%2C+S+V+M">Sai Vikneshwar Mani Jayaraman</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Ropell%2C+C">Corey Ropell</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Rudra%2C+A">Atri Rudra</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2112.01003v1-abstract-short" style="display: inline;">
        Worst-case optimal join algorithms have so far been studied in two broad contexts -- $(1)$ when we are given input relation sizes [Atserias et al., FOCS 2008, Ngo et al., PODS 2012, Velduizhen et. al, ICDT 2014] $(2)$ when in addition to size, we are given a degree bound on the relation [Abo Khamis et al., PODS 2017]. To the best of our knowledge, this problem has not been studied beyond these two&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2112.01003v1-abstract-full').style.display = 'inline'; document.getElementById('2112.01003v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2112.01003v1-abstract-full" style="display: none;">
        Worst-case optimal join algorithms have so far been studied in two broad contexts -- $(1)$ when we are given input relation sizes [Atserias et al., FOCS 2008, Ngo et al., PODS 2012, Velduizhen et. al, ICDT 2014] $(2)$ when in addition to size, we are given a degree bound on the relation [Abo Khamis et al., PODS 2017]. To the best of our knowledge, this problem has not been studied beyond these two statistics even for the case when input relations have arity (at most) two.
  In this paper, we present a worst-case optimal join algorithm when are given $\ell_{p}$-norm size bounds on input relations of arity at most two for $p \in (1, 2]$. ($p=1$ corresponds to relation size bounds and $p=\infty$ corresponds to the degree bounds.) The worst-case optimality holds any fixed $p \in (2, \infty)$ as well (as long as the join query graph has large enough girth). Our algorithm is {\em simple}, does not depend on $p$ (or) the $\ell_{p}$-norm bounds and avoids the (large) poly-log factor associated with the best known algorithm PANDA [Abo Khamis et al., PODS 2017] for the size and degree bounds setting of the problem. In this process, we (partially) resolve two open question from [Ngo, 2018 Gems of PODS]. We believe our algorithm has the {\em potential} to pave the way for practical worst-case optimal join algorithms beyond the case of size bounds.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2112.01003v1-abstract-full').style.display = 'none'; document.getElementById('2112.01003v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 2 December, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2112.00029">arXiv:2112.00029</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2112.00029">pdf</a>, <a href="https://arxiv.org/format/2112.00029">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Pixelated Butterfly: Simple and Efficient Sparse training for Neural Network Models
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Chen%2C+B">Beidi Chen</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Dao%2C+T">Tri Dao</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Liang%2C+K">Kaizhao Liang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Yang%2C+J">Jiaming Yang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Song%2C+Z">Zhao Song</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Rudra%2C+A">Atri Rudra</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Re%2C+C">Christopher Re</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2112.00029v1-abstract-short" style="display: inline;">
        Overparameterized neural networks generalize well but are expensive to train. Ideally, one would like to reduce their computational cost while retaining their generalization benefits. Sparse model training is a simple and promising approach to achieve this, but there remain challenges as existing methods struggle with accuracy loss, slow training runtime, or difficulty in sparsifying all model com&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2112.00029v1-abstract-full').style.display = 'inline'; document.getElementById('2112.00029v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2112.00029v1-abstract-full" style="display: none;">
        Overparameterized neural networks generalize well but are expensive to train. Ideally, one would like to reduce their computational cost while retaining their generalization benefits. Sparse model training is a simple and promising approach to achieve this, but there remain challenges as existing methods struggle with accuracy loss, slow training runtime, or difficulty in sparsifying all model components. The core problem is that searching for a sparsity mask over a discrete set of sparse matrices is difficult and expensive. To address this, our main insight is to optimize over a continuous superset of sparse matrices with a fixed structure known as products of butterfly matrices. As butterfly matrices are not hardware efficient, we propose simple variants of butterfly (block and flat) to take advantage of modern hardware. Our method (Pixelated Butterfly) uses a simple fixed sparsity pattern based on flat block butterfly and low-rank matrices to sparsify most network layers (e.g., attention, MLP). We empirically validate that Pixelated Butterfly is 3x faster than butterfly and speeds up training to achieve favorable accuracy--efficiency tradeoffs. On the ImageNet classification and WikiText-103 language modeling tasks, our sparse models train up to 2.5x faster than the dense MLP-Mixer, Vision Transformer, and GPT-2 medium with no drop in accuracy.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2112.00029v1-abstract-full').style.display = 'none'; document.getElementById('2112.00029v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 30 November, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2110.15343">arXiv:2110.15343</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2110.15343">pdf</a>, <a href="https://arxiv.org/format/2110.15343">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Scatterbrain: Unifying Sparse and Low-rank Attention Approximation
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Chen%2C+B">Beidi Chen</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Dao%2C+T">Tri Dao</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Winsor%2C+E">Eric Winsor</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Song%2C+Z">Zhao Song</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Rudra%2C+A">Atri Rudra</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=R%C3%A9%2C+C">Christopher Ré</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2110.15343v1-abstract-short" style="display: inline;">
        Recent advances in efficient Transformers have exploited either the sparsity or low-rank properties of attention matrices to reduce the computational and memory bottlenecks of modeling long sequences. However, it is still challenging to balance the trade-off between model quality and efficiency to perform a one-size-fits-all approximation for different tasks. To better understand this trade-off, w&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2110.15343v1-abstract-full').style.display = 'inline'; document.getElementById('2110.15343v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2110.15343v1-abstract-full" style="display: none;">
        Recent advances in efficient Transformers have exploited either the sparsity or low-rank properties of attention matrices to reduce the computational and memory bottlenecks of modeling long sequences. However, it is still challenging to balance the trade-off between model quality and efficiency to perform a one-size-fits-all approximation for different tasks. To better understand this trade-off, we observe that sparse and low-rank approximations excel in different regimes, determined by the softmax temperature in attention, and sparse + low-rank can outperform each individually. Inspired by the classical robust-PCA algorithm for sparse and low-rank decomposition, we propose Scatterbrain, a novel way to unify sparse (via locality sensitive hashing) and low-rank (via kernel feature map) attention for accurate and efficient approximation. The estimation is unbiased with provably low error. We empirically show that Scatterbrain can achieve 2.1x lower error than baselines when serving as a drop-in replacement in BigGAN image generation and pre-trained T2T-ViT. On a pre-trained T2T Vision transformer, even without fine-tuning, Scatterbrain can reduce 98% of attention memory at the cost of only 1% drop in accuracy. We demonstrate Scatterbrain for end-to-end training with up to 4 points better perplexity and 5 points better average accuracy than sparse or low-rank efficient transformers on language modeling and long-range-arena tasks.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2110.15343v1-abstract-full').style.display = 'none'; document.getElementById('2110.15343v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 28 October, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">NeurIPS 2021</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2110.13985">arXiv:2110.13985</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2110.13985">pdf</a>, <a href="https://arxiv.org/format/2110.13985">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Combining Recurrent, Convolutional, and Continuous-time Models with Linear State-Space Layers
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Gu%2C+A">Albert Gu</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Johnson%2C+I">Isys Johnson</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Goel%2C+K">Karan Goel</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Saab%2C+K">Khaled Saab</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Dao%2C+T">Tri Dao</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Rudra%2C+A">Atri Rudra</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=R%C3%A9%2C+C">Christopher Ré</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2110.13985v1-abstract-short" style="display: inline;">
        Recurrent neural networks (RNNs), temporal convolutions, and neural differential equations (NDEs) are popular families of deep learning models for time-series data, each with unique strengths and tradeoffs in modeling power and computational efficiency. We introduce a simple sequence model inspired by control systems that generalizes these approaches while addressing their shortcomings. The Linear&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2110.13985v1-abstract-full').style.display = 'inline'; document.getElementById('2110.13985v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2110.13985v1-abstract-full" style="display: none;">
        Recurrent neural networks (RNNs), temporal convolutions, and neural differential equations (NDEs) are popular families of deep learning models for time-series data, each with unique strengths and tradeoffs in modeling power and computational efficiency. We introduce a simple sequence model inspired by control systems that generalizes these approaches while addressing their shortcomings. The Linear State-Space Layer (LSSL) maps a sequence $u \mapsto y$ by simply simulating a linear continuous-time state-space representation $\dot{x} = Ax + Bu, y = Cx + Du$. Theoretically, we show that LSSL models are closely related to the three aforementioned families of models and inherit their strengths. For example, they generalize convolutions to continuous-time, explain common RNN heuristics, and share features of NDEs such as time-scale adaptation. We then incorporate and generalize recent theory on continuous-time memorization to introduce a trainable subset of structured matrices $A$ that endow LSSLs with long-range memory. Empirically, stacking LSSL layers into a simple deep neural network obtains state-of-the-art results across time series benchmarks for long dependencies in sequential image classification, real-world healthcare regression tasks, and speech. On a difficult speech classification task with length-16000 sequences, LSSL outperforms prior approaches by 24 accuracy points, and even outperforms baselines that use hand-crafted features on 100x shorter sequences.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2110.13985v1-abstract-full').style.display = 'none'; document.getElementById('2110.13985v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 26 October, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">NeurIPS 2021</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2105.03239">arXiv:2105.03239</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2105.03239">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Databases">cs.DB</span>
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1007/978-981-33-6652-7_4">10.1007/978-981-33-6652-7_4 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Semantic data discovery from Social Big Data
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Abu-Salih%2C+B">Bilal Abu-Salih</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Wongthongtham%2C+P">Pornpit Wongthongtham</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+D">Dengya Zhu</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Chan%2C+K+Y">Kit Yan Chan</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Rudra%2C+A">Amit Rudra</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2105.03239v1-abstract-short" style="display: inline;">
        Due to the large volume of data and information generated by a multitude of social data sources, it is a huge challenge to manage and extract useful knowledge, especially given the different forms of data, streaming data and uncertainty and ambiguity of data. Hence, there are still challenges in this area of BD analytics research to capture, store, process, visualise, query, and manipulate dataset&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.03239v1-abstract-full').style.display = 'inline'; document.getElementById('2105.03239v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2105.03239v1-abstract-full" style="display: none;">
        Due to the large volume of data and information generated by a multitude of social data sources, it is a huge challenge to manage and extract useful knowledge, especially given the different forms of data, streaming data and uncertainty and ambiguity of data. Hence, there are still challenges in this area of BD analytics research to capture, store, process, visualise, query, and manipulate datasets to derive meaningful information that is specific to an application&#39;s domain. This chapter attempts to address this problem by studying Semantic Analytics and domain knowledge modelling, and to what extent these technologies can be utilised toward better understanding to the social textual contents. In particular, the chapter gives an overview of semantic analysis and domain ontology followed by shedding light on domain knowledge modelling, inference, semantic storage, and publicly available semantic tools and APIs. Also, the theoretical notion of Knowledge Graphs is reported and their interlinking with SBD is discussed. The utility of the semantic analytics is demonstrated and evaluated through a case study on social data in the context of politics domain.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.03239v1-abstract-full').style.display = 'none'; document.getElementById('2105.03239v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 21 April, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">arXiv admin note: substantial text overlap with arXiv:1801.01624</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2104.12591">arXiv:2104.12591</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2104.12591">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1007/978-981-33-6652-7_5">10.1007/978-981-33-6652-7_5 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Predictive analytics using Social Big Data and machine learning
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Abu-Salih%2C+B">Bilal Abu-Salih</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Wongthongtham%2C+P">Pornpit Wongthongtham</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+D">Dengya Zhu</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Chan%2C+K+Y">Kit Yan Chan</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Rudra%2C+A">Amit Rudra</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2104.12591v1-abstract-short" style="display: inline;">
        The ever-increase in the quality and quantity of data generated from day-to-day businesses operations in conjunction with the continuously imported related social data have made the traditional statistical approaches inadequate to tackle such data floods. This has dictated researchers to design and develop advance and sophisticated analytics that can be incorporated to gain valuable insights that&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.12591v1-abstract-full').style.display = 'inline'; document.getElementById('2104.12591v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2104.12591v1-abstract-full" style="display: none;">
        The ever-increase in the quality and quantity of data generated from day-to-day businesses operations in conjunction with the continuously imported related social data have made the traditional statistical approaches inadequate to tackle such data floods. This has dictated researchers to design and develop advance and sophisticated analytics that can be incorporated to gain valuable insights that benefit the business domain. This chapter sheds the light on core aspects that lay the foundations for social big data analytics. In particular, the significance of predictive analytics in the context of SBD is discussed fortified with presenting a framework for SBD predictive analytics. Then, various predictive analytical algorithms are introduced with their usage in several important application and top-tier tools and APIs. A case study on using predictive analytics to social data is provided supported with experiments to substantiate the significance and utility of predictive analytics.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.12591v1-abstract-full').style.display = 'none'; document.getElementById('2104.12591v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 21 April, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2104.09190">arXiv:2104.09190</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2104.09190">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Social and Information Networks">cs.SI</span>
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1007/978-981-33-6652-7_3">10.1007/978-981-33-6652-7_3 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Credibility Analysis in Social Big Data
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Abu-Salih%2C+B">Bilal Abu-Salih</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Wongthongtham%2C+P">Pornpit Wongthongtham</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+D">Dengya Zhu</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Chan%2C+K+Y">Kit Yan Chan</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Rudra%2C+A">Amit Rudra</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2104.09190v1-abstract-short" style="display: inline;">
        The concept of social trust has attracted an attention of information processors/data scientists and information consumers / business firms. One of the main reasons for acquiring the value of SBD is to provide frameworks and methodologies using which the credibility of online social services users can be evaluated. These approaches should be scalable to accommodate large-scale social data. Hence,&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.09190v1-abstract-full').style.display = 'inline'; document.getElementById('2104.09190v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2104.09190v1-abstract-full" style="display: none;">
        The concept of social trust has attracted an attention of information processors/data scientists and information consumers / business firms. One of the main reasons for acquiring the value of SBD is to provide frameworks and methodologies using which the credibility of online social services users can be evaluated. These approaches should be scalable to accommodate large-scale social data. Hence, there is a need for well comprehending of social trust to improve and expand the analysis process and inferring credibility of social big data. Given the exposed environment&#39;s settings and fewer limitations related to online social services, the medium allows legitimate and genuine users as well as spammers and other low trustworthy users to publish and spread their content. This chapter presents an overview of the notion of credibility in the context of SBD. It also list an array of approaches to measure and evaluate the trustworthiness of users and their contents. Finally, a case study is presented that incorporates semantic analysis and machine learning modules to measure and predict users&#39; trustworthiness in numerous domains in different time periods. The evaluation of the conducted experiment validates the applicability of the incorporated machine learning techniques to predict highly trustworthy domain-based users.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.09190v1-abstract-full').style.display = 'none'; document.getElementById('2104.09190v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 19 April, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2104.08062">arXiv:2104.08062</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2104.08062">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Other Computer Science">cs.OH</span>
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1007/978-981-33-6652-7_2">10.1007/978-981-33-6652-7_2 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Introduction to Big data Technology
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Abu-Salih%2C+B">Bilal Abu-Salih</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Wongthongtham%2C+P">Pornpit Wongthongtham</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+D">Dengya Zhu</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Chan%2C+K+Y">Kit Yan Chan</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Rudra%2C+A">Amit Rudra</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2104.08062v1-abstract-short" style="display: inline;">
        Big data is no more &#34;all just hype&#34; but widely applied in nearly all aspects of our business, governments, and organizations with the technology stack of AI. Its influences are far beyond a simple technique innovation but involves all rears in the world. This chapter will first have historical review of big data; followed by discussion of characteristics of big data, i.e. from the 3V&#39;s to up 10V&#39;s&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.08062v1-abstract-full').style.display = 'inline'; document.getElementById('2104.08062v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2104.08062v1-abstract-full" style="display: none;">
        Big data is no more &#34;all just hype&#34; but widely applied in nearly all aspects of our business, governments, and organizations with the technology stack of AI. Its influences are far beyond a simple technique innovation but involves all rears in the world. This chapter will first have historical review of big data; followed by discussion of characteristics of big data, i.e. from the 3V&#39;s to up 10V&#39;s of big data. The chapter then introduces technology stacks for an or-ganization to build a big data application, from infrastruc-ture/platform/ecosystem to constructional units and components. Finally, we provide some big data online resources for reference.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.08062v1-abstract-full').style.display = 'none'; document.getElementById('2104.08062v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 April, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2104.03904">arXiv:2104.03904</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2104.03904">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Social and Information Networks">cs.SI</span>
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1007/978-981-33-6652-7_1">10.1007/978-981-33-6652-7_1 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Social Big Data: An Overview and Applications
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Abu-Salih%2C+B">Bilal Abu-Salih</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Wongthongtham%2C+P">Pornpit Wongthongtham</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+D">Dengya Zhu</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Chan%2C+K+Y">Kit Yan Chan</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Rudra%2C+A">Amit Rudra</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2104.03904v1-abstract-short" style="display: inline;">
        The emergence of online social media services has made a qualitative leap and brought profound changes to various aspects of human, cultural, intellectual, and social life. These significant Big data tributaries have further transformed the businesses processes by establishing convergent and transparent dialogues between businesses and their customers. Therefore, analysing the flow of social data&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.03904v1-abstract-full').style.display = 'inline'; document.getElementById('2104.03904v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2104.03904v1-abstract-full" style="display: none;">
        The emergence of online social media services has made a qualitative leap and brought profound changes to various aspects of human, cultural, intellectual, and social life. These significant Big data tributaries have further transformed the businesses processes by establishing convergent and transparent dialogues between businesses and their customers. Therefore, analysing the flow of social data content is necessary in order to enhance business practices, to augment brand awareness, to develop insights on target markets, to detect and identify positive and negative customer sentiments, etc., thereby achieving the hoped-for added value. This chapter presents an overview of Social Big Data term and definition. This chapter also lays the foundation for several applications and analytics that are broadly discussed in this book.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.03904v1-abstract-full').style.display = 'none'; document.getElementById('2104.03904v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 1 April, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2012.14966">arXiv:2012.14966</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2012.14966">pdf</a>, <a href="https://arxiv.org/format/2012.14966">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Kaleidoscope: An Efficient, Learnable Representation For All Structured Linear Maps
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Dao%2C+T">Tri Dao</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Sohoni%2C+N+S">Nimit S. Sohoni</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Gu%2C+A">Albert Gu</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Eichhorn%2C+M">Matthew Eichhorn</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Blonder%2C+A">Amit Blonder</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Leszczynski%2C+M">Megan Leszczynski</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Rudra%2C+A">Atri Rudra</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=R%C3%A9%2C+C">Christopher Ré</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2012.14966v2-abstract-short" style="display: inline;">
        Modern neural network architectures use structured linear transformations, such as low-rank matrices, sparse matrices, permutations, and the Fourier transform, to improve inference speed and reduce memory usage compared to general linear maps. However, choosing which of the myriad structured transformations to use (and its associated parameterization) is a laborious task that requires trading off&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.14966v2-abstract-full').style.display = 'inline'; document.getElementById('2012.14966v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2012.14966v2-abstract-full" style="display: none;">
        Modern neural network architectures use structured linear transformations, such as low-rank matrices, sparse matrices, permutations, and the Fourier transform, to improve inference speed and reduce memory usage compared to general linear maps. However, choosing which of the myriad structured transformations to use (and its associated parameterization) is a laborious task that requires trading off speed, space, and accuracy. We consider a different approach: we introduce a family of matrices called kaleidoscope matrices (K-matrices) that provably capture any structured matrix with near-optimal space (parameter) and time (arithmetic operation) complexity. We empirically validate that K-matrices can be automatically learned within end-to-end pipelines to replace hand-crafted procedures, in order to improve model quality. For example, replacing channel shuffles in ShuffleNet improves classification accuracy on ImageNet by up to 5%. K-matrices can also simplify hand-engineered pipelines -- we replace filter bank feature computation in speech data preprocessing with a learnable kaleidoscope layer, resulting in only 0.4% loss in accuracy on the TIMIT speech recognition task. In addition, K-matrices can capture latent structure in models: for a challenging permuted image classification task, a K-matrix based representation of permutations is able to learn the right latent structure and improves accuracy of a downstream convolutional model by over 9%. We provide a practically efficient implementation of our approach, and use K-matrices in a Transformer network to attain 36% faster end-to-end inference speed on a language translation task.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.14966v2-abstract-full').style.display = 'none'; document.getElementById('2012.14966v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 5 January, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 29 December, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">International Conference on Learning Representations (ICLR) 2020 spotlight</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2012.05397">arXiv:2012.05397</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2012.05397">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Information Retrieval">cs.IR</span>
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.3127/ajis.v24i0.2331">10.3127/ajis.v24i0.2331 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        An Integrated Search Framework for Leveraging the Knowledge-Based Web Ecosystem
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+D">Dengya Zhu</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Nimmagadda%2C+S+L">Shastri Lakshman Nimmagadda</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Reiners%2C+T">Torsten Reiners</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Rudra%2C+A">Amit Rudra</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2012.05397v1-abstract-short" style="display: inline;">
        The explosion of information constrains the judgement of search terms associated with Knowledge-Based Web Ecosystem (KBWE), making the retrieval of relevant information and its knowledge management challenging. The existing information retrieval (IR) tools and their fusion in a framework need attention, in which search results can effectively be managed. In this article, we demonstrate the effecti&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.05397v1-abstract-full').style.display = 'inline'; document.getElementById('2012.05397v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2012.05397v1-abstract-full" style="display: none;">
        The explosion of information constrains the judgement of search terms associated with Knowledge-Based Web Ecosystem (KBWE), making the retrieval of relevant information and its knowledge management challenging. The existing information retrieval (IR) tools and their fusion in a framework need attention, in which search results can effectively be managed. In this article, we demonstrate the effective use of information retrieval services by a variety of users and agents in various KBWE scenarios. An innovative Integrated Search Framework (ISF) is proposed, which utilises crawling strategies, web search technologies and traditional database search methods. Besides, ISF offers comprehensive, dynamic, personalized, and organization-oriented information retrieval services, ranging from the Internet, extranet, intranet, to personal desktop. In this empirical research, experiments are carried out demonstrating the improvements in the search process, as discerned in the conceptual ISF. The experimental results show improved precision compared with other popular search engines.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.05397v1-abstract-full').style.display = 'none'; document.getElementById('2012.05397v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 9 December, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2020.
      
    </p>
    

    
      <p class="comments is-size-7">
        

        
          <span class="has-text-black-bis has-text-weight-semibold">MSC Class:</span>
          68P20 Information storage and retrieval of data
        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          H.3.3
        
      </p>
    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        Australasian Journal of Information Systems, 2020, Vol 24, Research Article, pp. 1-24
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2008.07669">arXiv:2008.07669</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2008.07669">pdf</a>, <a href="https://arxiv.org/format/2008.07669">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        HiPPO: Recurrent Memory with Optimal Polynomial Projections
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Gu%2C+A">Albert Gu</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Dao%2C+T">Tri Dao</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Ermon%2C+S">Stefano Ermon</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Rudra%2C+A">Atri Rudra</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Re%2C+C">Christopher Re</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2008.07669v2-abstract-short" style="display: inline;">
        A central problem in learning from sequential data is representing cumulative history in an incremental fashion as more data is processed. We introduce a general framework (HiPPO) for the online compression of continuous signals and discrete time series by projection onto polynomial bases. Given a measure that specifies the importance of each time step in the past, HiPPO produces an optimal soluti&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2008.07669v2-abstract-full').style.display = 'inline'; document.getElementById('2008.07669v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2008.07669v2-abstract-full" style="display: none;">
        A central problem in learning from sequential data is representing cumulative history in an incremental fashion as more data is processed. We introduce a general framework (HiPPO) for the online compression of continuous signals and discrete time series by projection onto polynomial bases. Given a measure that specifies the importance of each time step in the past, HiPPO produces an optimal solution to a natural online function approximation problem. As special cases, our framework yields a short derivation of the recent Legendre Memory Unit (LMU) from first principles, and generalizes the ubiquitous gating mechanism of recurrent neural networks such as GRUs. This formal framework yields a new memory update mechanism (HiPPO-LegS) that scales through time to remember all history, avoiding priors on the timescale. HiPPO-LegS enjoys the theoretical benefits of timescale robustness, fast updates, and bounded gradients. By incorporating the memory dynamics into recurrent neural networks, HiPPO RNNs can empirically capture complex temporal dependencies. On the benchmark permuted MNIST dataset, HiPPO-LegS sets a new state-of-the-art accuracy of 98.3%. Finally, on a novel trajectory classification task testing robustness to out-of-distribution timescales and missing data, HiPPO-LegS outperforms RNN and neural ODE baselines by 25-40% accuracy.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2008.07669v2-abstract-full').style.display = 'none'; document.getElementById('2008.07669v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 22 October, 2020; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 17 August, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2003.09537">arXiv:2003.09537</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2003.09537">pdf</a>, <a href="https://arxiv.org/format/2003.09537">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Databases">cs.DB</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Covering the Relational Join
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Li%2C+S">Shi Li</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Jayaraman%2C+S+V+M">Sai Vikneshwar Mani Jayaraman</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Rudra%2C+A">Atri Rudra</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2003.09537v1-abstract-short" style="display: inline;">
        In this paper, we initiate a theoretical study of what we call the join covering problem. We are given a natural join query instance $Q$ on $n$ attributes and $m$ relations $(R_i)_{i \in [m]}$. Let $J_{Q} = \ \Join_{i=1}^m R_i$ denote the join output of $Q$. In addition to $Q$, we are given a parameter $Δ: 1\le Δ\le n$ and our goal is to compute the smallest subset&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2003.09537v1-abstract-full').style.display = 'inline'; document.getElementById('2003.09537v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2003.09537v1-abstract-full" style="display: none;">
        In this paper, we initiate a theoretical study of what we call the join covering problem. We are given a natural join query instance $Q$ on $n$ attributes and $m$ relations $(R_i)_{i \in [m]}$. Let $J_{Q} = \ \Join_{i=1}^m R_i$ denote the join output of $Q$. In addition to $Q$, we are given a parameter $Δ: 1\le Δ\le n$ and our goal is to compute the smallest subset $\mathcal{T}_{Q, Δ} \subseteq J_{Q}$ such that every tuple in $J_{Q}$ is within Hamming distance $Δ- 1$ from some tuple in $\mathcal{T}_{Q, Δ}$. The join covering problem captures both computing the natural join from database theory and constructing a covering code with covering radius $Δ- 1$ from coding theory, as special cases.
  We consider the combinatorial version of the join covering problem, where our goal is to determine the worst-case $|\mathcal{T}_{Q, Δ}|$ in terms of the structure of $Q$ and value of $Δ$. One obvious approach to upper bound $|\mathcal{T}_{Q, Δ}|$ is to exploit a distance property (of Hamming distance) from coding theory and combine it with the worst-case bounds on output size of natural joins (AGM bound hereon) due to Atserias, Grohe and Marx [SIAM J. of Computing&#39;13]. Somewhat surprisingly, this approach is not tight even for the case when the input relations have arity at most two. Instead, we show that using the polymatroid degree-based bound of Abo Khamis, Ngo and Suciu [PODS&#39;17] in place of the AGM bound gives us a tight bound (up to constant factors) on the $|\mathcal{T}_{Q, Δ}|$ for the arity two case. We prove lower bounds for $|\mathcal{T}_{Q, Δ}|$ using well-known classes of error-correcting codes e.g, Reed-Solomon codes. We can extend our results for the arity two case to general arity with a polynomial gap between our upper and lower bounds.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2003.09537v1-abstract-full').style.display = 'none'; document.getElementById('2003.09537v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 20 March, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2003.05575">arXiv:2003.05575</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2003.05575">pdf</a>, <a href="https://arxiv.org/format/2003.05575">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Distributed, Parallel, and Cluster Computing">cs.DC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computational Complexity">cs.CC</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Databases">cs.DB</span>
          
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1145/3294052.3319686">10.1145/3294052.3319686 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Topology Dependent Bounds For FAQs
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Langberg%2C+M">Michael Langberg</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Li%2C+S">Shi Li</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Jayaraman%2C+S+V+M">Sai Vikneshwar Mani Jayaraman</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Rudra%2C+A">Atri Rudra</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2003.05575v1-abstract-short" style="display: inline;">
        In this paper, we prove topology dependent bounds on the number of rounds needed to compute Functional Aggregate Queries (FAQs) studied by Abo Khamis et al. [PODS 2016] in a synchronous distributed network under the model considered by Chattopadhyay et al. [FOCS 2014, SODA 2017]. Unlike the recent work on computing database queries in the Massively Parallel Computation model, in the model of Chatt&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2003.05575v1-abstract-full').style.display = 'inline'; document.getElementById('2003.05575v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2003.05575v1-abstract-full" style="display: none;">
        In this paper, we prove topology dependent bounds on the number of rounds needed to compute Functional Aggregate Queries (FAQs) studied by Abo Khamis et al. [PODS 2016] in a synchronous distributed network under the model considered by Chattopadhyay et al. [FOCS 2014, SODA 2017]. Unlike the recent work on computing database queries in the Massively Parallel Computation model, in the model of Chattopadhyay et al., nodes can communicate only via private point-to-point channels and we are interested in bounds that work over an {\em arbitrary} communication topology. This is the first work to consider more practically motivated problems in this distributed model. For the sake of exposition, we focus on two special problems in this paper: Boolean Conjunctive Query (BCQ) and computing variable/factor marginals in Probabilistic Graphical Models (PGMs). We obtain tight bounds on the number of rounds needed to compute such queries as long as the underlying hypergraph of the query is $O(1)$-degenerate and has $O(1)$-arity. In particular, the $O(1)$-degeneracy condition covers most well-studied queries that are efficiently computable in the centralized computation model like queries with constant treewidth. These tight bounds depend on a new notion of `width&#39; (namely internal-node-width) for Generalized Hypertree Decompositions (GHDs) of acyclic hypergraphs, which minimizes the number of internal nodes in a sub-class of GHDs. To the best of our knowledge, this width has not been studied explicitly in the theoretical database literature. Finally, we consider the problem of computing the product of a vector with a chain of matrices and prove tight bounds on its round complexity (over the finite field of two elements) using a novel min-entropy based argument.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2003.05575v1-abstract-full').style.display = 'none'; document.getElementById('2003.05575v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 11 March, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">A conference version was presented at PODS 2019</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1907.08362">arXiv:1907.08362</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1907.08362">pdf</a>, <a href="https://arxiv.org/ps/1907.08362">ps</a>, <a href="https://arxiv.org/format/1907.08362">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Data Structures and Algorithms">cs.DS</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Sparse Recovery for Orthogonal Polynomial Transforms
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Gilbert%2C+A">Anna Gilbert</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Gu%2C+A">Albert Gu</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Re%2C+C">Christopher Re</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Rudra%2C+A">Atri Rudra</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Wootters%2C+M">Mary Wootters</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1907.08362v1-abstract-short" style="display: inline;">
        In this paper we consider the following sparse recovery problem. We have query access to a vector $\vx \in \R^N$ such that $\vhx = \vF \vx$ is $k$-sparse (or nearly $k$-sparse) for some orthogonal transform $\vF$. The goal is to output an approximation (in an $\ell_2$ sense) to $\vhx$ in sublinear time. This problem has been well-studied in the special case that $\vF$ is the Discrete Fourier Trans&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1907.08362v1-abstract-full').style.display = 'inline'; document.getElementById('1907.08362v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1907.08362v1-abstract-full" style="display: none;">
        In this paper we consider the following sparse recovery problem. We have query access to a vector $\vx \in \R^N$ such that $\vhx = \vF \vx$ is $k$-sparse (or nearly $k$-sparse) for some orthogonal transform $\vF$. The goal is to output an approximation (in an $\ell_2$ sense) to $\vhx$ in sublinear time. This problem has been well-studied in the special case that $\vF$ is the Discrete Fourier Transform (DFT), and a long line of work has resulted in sparse Fast Fourier Transforms that run in time $O(k \cdot \mathrm{polylog} N)$. However, for transforms $\vF$ other than the DFT (or closely related transforms like the Discrete Cosine Transform), the question is much less settled.
  In this paper we give sublinear-time algorithms---running in time $\poly(k \log(N))$---for solving the sparse recovery problem for orthogonal transforms $\vF$ that arise from orthogonal polynomials. More precisely, our algorithm works for any $\vF$ that is an orthogonal polynomial transform derived from Jacobi polynomials. The Jacobi polynomials are a large class of classical orthogonal polynomials (and include Chebyshev and Legendre polynomials as special cases), and show up extensively in applications like numerical analysis and signal processing. One caveat of our work is that we require an assumption on the sparsity structure of the sparse vector, although we note that vectors with random support have this property with high probability.
  Our approach is to give a very general reduction from the $k$-sparse sparse recovery problem to the $1$-sparse sparse recovery problem that holds for any flat orthogonal polynomial transform; then we solve this one-sparse recovery problem for transforms derived from Jacobi polynomials.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1907.08362v1-abstract-full').style.display = 'none'; document.getElementById('1907.08362v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 18 July, 2019; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2019.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">64 pages</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1903.05895">arXiv:1903.05895</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1903.05895">pdf</a>, <a href="https://arxiv.org/format/1903.05895">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Learning Fast Algorithms for Linear Transforms Using Butterfly Factorizations
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Dao%2C+T">Tri Dao</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Gu%2C+A">Albert Gu</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Eichhorn%2C+M">Matthew Eichhorn</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Rudra%2C+A">Atri Rudra</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=R%C3%A9%2C+C">Christopher Ré</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1903.05895v2-abstract-short" style="display: inline;">
        Fast linear transforms are ubiquitous in machine learning, including the discrete Fourier transform, discrete cosine transform, and other structured transformations such as convolutions. All of these transforms can be represented by dense matrix-vector multiplication, yet each has a specialized and highly efficient (subquadratic) algorithm. We ask to what extent hand-crafting these algorithms and&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1903.05895v2-abstract-full').style.display = 'inline'; document.getElementById('1903.05895v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1903.05895v2-abstract-full" style="display: none;">
        Fast linear transforms are ubiquitous in machine learning, including the discrete Fourier transform, discrete cosine transform, and other structured transformations such as convolutions. All of these transforms can be represented by dense matrix-vector multiplication, yet each has a specialized and highly efficient (subquadratic) algorithm. We ask to what extent hand-crafting these algorithms and implementations is necessary, what structural priors they encode, and how much knowledge is required to automatically learn a fast algorithm for a provided structured transform. Motivated by a characterization of fast matrix-vector multiplication as products of sparse matrices, we introduce a parameterization of divide-and-conquer methods that is capable of representing a large class of transforms. This generic formulation can automatically learn an efficient algorithm for many important transforms; for example, it recovers the $O(N \log N)$ Cooley-Tukey FFT algorithm to machine precision, for dimensions $N$ up to $1024$. Furthermore, our method can be incorporated as a lightweight replacement of generic matrices in machine learning pipelines to learn efficient and compressible transformations. On a standard task of compressing a single hidden-layer network, our method exceeds the classification accuracy of unconstrained matrices on CIFAR-10 by 3.9 points -- the first time a structured approach has done so -- with 4X faster inference speed and 40X fewer parameters.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1903.05895v2-abstract-full').style.display = 'none'; document.getElementById('1903.05895v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 28 December, 2020; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 14 March, 2019;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2019.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">International Conference on Machine Learning (ICML) 2019</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1810.02309">arXiv:1810.02309</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1810.02309">pdf</a>, <a href="https://arxiv.org/format/1810.02309">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Learning Compressed Transforms with Low Displacement Rank
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Thomas%2C+A+T">Anna T. Thomas</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Gu%2C+A">Albert Gu</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Dao%2C+T">Tri Dao</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Rudra%2C+A">Atri Rudra</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=R%C3%A9%2C+C">Christopher Ré</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1810.02309v3-abstract-short" style="display: inline;">
        The low displacement rank (LDR) framework for structured matrices represents a matrix through two displacement operators and a low-rank residual. Existing use of LDR matrices in deep learning has applied fixed displacement operators encoding forms of shift invariance akin to convolutions. We introduce a class of LDR matrices with more general displacement operators, and explicitly learn over both&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1810.02309v3-abstract-full').style.display = 'inline'; document.getElementById('1810.02309v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1810.02309v3-abstract-full" style="display: none;">
        The low displacement rank (LDR) framework for structured matrices represents a matrix through two displacement operators and a low-rank residual. Existing use of LDR matrices in deep learning has applied fixed displacement operators encoding forms of shift invariance akin to convolutions. We introduce a class of LDR matrices with more general displacement operators, and explicitly learn over both the operators and the low-rank component. This class generalizes several previous constructions while preserving compression and efficient computation. We prove bounds on the VC dimension of multi-layer neural networks with structured weight matrices and show empirically that our compact parameterization can reduce the sample complexity of learning. When replacing weight layers in fully-connected, convolutional, and recurrent neural networks for image classification and language modeling tasks, our new classes exceed the accuracy of existing compression approaches, and on some tasks also outperform general unstructured layers while using more than 20x fewer parameters.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1810.02309v3-abstract-full').style.display = 'none'; document.getElementById('1810.02309v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 1 January, 2019; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 4 October, 2018;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2018.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">NeurIPS 2018. Code available at https://github.com/HazyResearch/structured-nets</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1807.00886">arXiv:1807.00886</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1807.00886">pdf</a>, <a href="https://arxiv.org/format/1807.00886">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Hypertree Decompositions Revisited for PGMs
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Arun%2C+A+S">Aarthy Shivram Arun</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Jayaraman%2C+S+V+M">Sai Vikneshwar Mani Jayaraman</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=R%C3%A9%2C+C">Christopher Ré</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Rudra%2C+A">Atri Rudra</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1807.00886v1-abstract-short" style="display: inline;">
        We revisit the classical problem of exact inference on probabilistic graphical models (PGMs). Our algorithm is based on recent \emph{worst-case optimal database join} algorithms, which can be asymptotically faster than traditional data processing methods. We present the first empirical evaluation of these algorithms via JoinInfer -- a new exact inference engine. We empirically explore the properti&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1807.00886v1-abstract-full').style.display = 'inline'; document.getElementById('1807.00886v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1807.00886v1-abstract-full" style="display: none;">
        We revisit the classical problem of exact inference on probabilistic graphical models (PGMs). Our algorithm is based on recent \emph{worst-case optimal database join} algorithms, which can be asymptotically faster than traditional data processing methods. We present the first empirical evaluation of these algorithms via JoinInfer -- a new exact inference engine. We empirically explore the properties of the data for which our engine can be expected to outperform traditional inference engines, refining current theoretical notions. Further, JoinInfer outperforms existing state-of-the-art inference engines (ACE, IJGP and libDAI) on some standard benchmark datasets by up to a factor of 630x. Finally, we propose a promising data-driven heuristic that extends JoinInfer to automatically tailor its parameters and/or switch to the traditional inference algorithms.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1807.00886v1-abstract-full').style.display = 'none'; document.getElementById('1807.00886v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 2 July, 2018; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2018.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted for StarAI Proceedings. Camera Ready Version of arXiv:1804.01640</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1804.01640">arXiv:1804.01640</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1804.01640">pdf</a>, <a href="https://arxiv.org/format/1804.01640">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Databases">cs.DB</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Hypertree Decompositions Revisited for PGMs
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Arun%2C+A+S">Aarthy Shivram Arun</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Jayaraman%2C+S+V+M">Sai Vikneshwar Mani Jayaraman</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=R%C3%A9%2C+C">Christopher Ré</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Rudra%2C+A">Atri Rudra</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1804.01640v1-abstract-short" style="display: inline;">
        We revisit the classical problem of exact inference on probabilistic graphical models (PGMs). Our algorithm is based on recent worst-case optimal database join algorithms, which can be asymptotically faster than traditional data processing methods. We present the first empirical evaluation of these new algorithms via JoinInfer, a new exact inference engine. We empirically explore the properties of&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1804.01640v1-abstract-full').style.display = 'inline'; document.getElementById('1804.01640v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1804.01640v1-abstract-full" style="display: none;">
        We revisit the classical problem of exact inference on probabilistic graphical models (PGMs). Our algorithm is based on recent worst-case optimal database join algorithms, which can be asymptotically faster than traditional data processing methods. We present the first empirical evaluation of these new algorithms via JoinInfer, a new exact inference engine. We empirically explore the properties of the data for which our engine can be expected to outperform traditional inference engines refining current theoretical notions. Further, JoinInfer outperforms existing state-of-the-art inference engines (ACE, IJGP and libDAI) on some standard benchmark datasets by up to a factor of 630x. Finally, we propose a promising data-driven heuristic that extends JoinInfer to automatically tailor its parameters and/or switch to the traditional inference algorithms.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1804.01640v1-abstract-full').style.display = 'none'; document.getElementById('1804.01640v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 4 April, 2018; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2018.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1802.02718">arXiv:1802.02718</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1802.02718">pdf</a>, <a href="https://arxiv.org/format/1802.02718">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Information Theory">cs.IT</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        General Strong Polarization
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=B%C5%82asiok%2C+J">Jarosław Błasiok</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Guruswami%2C+V">Venkatesan Guruswami</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Nakkiran%2C+P">Preetum Nakkiran</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Rudra%2C+A">Atri Rudra</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Sudan%2C+M">Madhu Sudan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1802.02718v2-abstract-short" style="display: inline;">
        Arikan&#39;s exciting discovery of polar codes has provided an altogether new way to efficiently achieve Shannon capacity. Given a (constant-sized) invertible matrix $M$, a family of polar codes can be associated with this matrix and its ability to approach capacity follows from the {\em polarization} of an associated $[0,1]$-bounded martingale, namely its convergence in the limit to either $0$ or&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1802.02718v2-abstract-full').style.display = 'inline'; document.getElementById('1802.02718v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1802.02718v2-abstract-full" style="display: none;">
        Arikan&#39;s exciting discovery of polar codes has provided an altogether new way to efficiently achieve Shannon capacity. Given a (constant-sized) invertible matrix $M$, a family of polar codes can be associated with this matrix and its ability to approach capacity follows from the {\em polarization} of an associated $[0,1]$-bounded martingale, namely its convergence in the limit to either $0$ or $1$. Arikan showed polarization of the martingale associated with the matrix $G_2 = \left(\begin{matrix} 1&amp; 0 \\ 1&amp; 1\end{matrix}\right)$ to get capacity achieving codes. His analysis was later extended to all matrices $M$ that satisfy an obvious necessary condition for polarization.
  While Arikan&#39;s theorem does not guarantee that the codes achieve capacity at small blocklengths, it turns out that a &#34;strong&#34; analysis of the polarization of the underlying martingale would lead to such constructions. Indeed for the martingale associated with $G_2$ such a strong polarization was shown in two independent works ([Guruswami and Xia, IEEE IT &#39;15] and [Hassani et al., IEEE IT &#39;14]), resolving a major theoretical challenge of the efficient attainment of Shannon capacity.
  In this work we extend the result above to cover martingales associated with all matrices that satisfy the necessary condition for (weak) polarization. In addition to being vastly more general, our proofs of strong polarization are also simpler and modular. Specifically, our result shows strong polarization over all prime fields and leads to efficient capacity-achieving codes for arbitrary symmetric memoryless channels. We show how to use our analyses to achieve exponentially small error probabilities at lengths inverse polynomial in the gap to capacity. Indeed we show that we can essentially match any error probability with lengths that are only inverse polynomial in the gap to capacity.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1802.02718v2-abstract-full').style.display = 'none'; document.getElementById('1802.02718v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 30 June, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 8 February, 2018;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2018.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">72 pages, 2 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1704.02420">arXiv:1704.02420</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1704.02420">pdf</a>, <a href="https://arxiv.org/format/1704.02420">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Information Theory">cs.IT</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Average-radius list-recovery of random linear codes: it really ties the room together
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Rudra%2C+A">Atri Rudra</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Wootters%2C+M">Mary Wootters</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1704.02420v1-abstract-short" style="display: inline;">
        We analyze the list-decodability, and related notions, of random linear codes. This has been studied extensively before: there are many different parameter regimes and many different variants. Previous works have used complementary styles of arguments---which each work in their own parameter regimes but not in others---and moreover have left some gaps in our understanding of the list-decodability&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1704.02420v1-abstract-full').style.display = 'inline'; document.getElementById('1704.02420v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1704.02420v1-abstract-full" style="display: none;">
        We analyze the list-decodability, and related notions, of random linear codes. This has been studied extensively before: there are many different parameter regimes and many different variants. Previous works have used complementary styles of arguments---which each work in their own parameter regimes but not in others---and moreover have left some gaps in our understanding of the list-decodability of random linear codes. In particular, none of these arguments work well for list-recovery, a generalization of list-decoding that has been useful in a variety of settings.
  In this work, we present a new approach, which works across parameter regimes and further generalizes to list-recovery. Our main theorem can establish better list-decoding and list-recovery results for low-rate random linear codes over large fields; list-recovery of high-rate random linear codes; and it can recover the rate bounds of Guruswami, Hastad, and Kopparty for constant-rate random linear codes (although with large list sizes).
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1704.02420v1-abstract-full').style.display = 'none'; document.getElementById('1704.02420v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 April, 2017; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2017.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1703.03147">arXiv:1703.03147</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1703.03147">pdf</a>, <a href="https://arxiv.org/ps/1703.03147">ps</a>, <a href="https://arxiv.org/format/1703.03147">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Databases">cs.DB</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Data Structures and Algorithms">cs.DS</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Logic in Computer Science">cs.LO</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Juggling Functions Inside a Database
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Khamis%2C+M+A">Mahmoud Abo Khamis</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Ngo%2C+H+Q">Hung Q. Ngo</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Rudra%2C+A">Atri Rudra</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1703.03147v1-abstract-short" style="display: inline;">
        We define and study the Functional Aggregate Query (FAQ) problem, which captures common computational tasks across a very wide range of domains including relational databases, logic, matrix and tensor computation, probabilistic graphical models, constraint satisfaction, and signal processing. Simply put, an FAQ is a declarative way of defining a new function from a database of input functions.
  W&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1703.03147v1-abstract-full').style.display = 'inline'; document.getElementById('1703.03147v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1703.03147v1-abstract-full" style="display: none;">
        We define and study the Functional Aggregate Query (FAQ) problem, which captures common computational tasks across a very wide range of domains including relational databases, logic, matrix and tensor computation, probabilistic graphical models, constraint satisfaction, and signal processing. Simply put, an FAQ is a declarative way of defining a new function from a database of input functions.
  We present &#34;InsideOut&#34;, a dynamic programming algorithm, to evaluate an FAQ. The algorithm rewrites the input query into a set of easier-to-compute FAQ sub-queries. Each sub-query is then evaluated using a worst-case optimal relational join algorithm. The topic of designing algorithms to optimally evaluate the classic multiway join problem has seen exciting developments in the past few years. Our framework tightly connects these new ideas in database theory with a vast number of application areas in a coherent manner, showing potentially that a good database engine can be a general-purpose constraint solver, relational data store, graphical model inference engine, and matrix/tensor computation processor all at once.
  The InsideOut algorithm is very simple, as shall be described in this paper. Yet, in spite of solving an extremely general problem, its runtime either is as good as or improves upon the best known algorithm for the applications that FAQ specializes to. These corollaries include computational tasks in graphical model inference, matrix/tensor operations, relational joins, and logic. Better yet, InsideOut can be used within any database engine, because it is basically a principled way of rewriting queries. Indeed, it is already part of the LogicBlox database engine, helping efficiently answer traditional database queries, graphical model inference queries, and train a large class of machine learning models inside the database itself.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1703.03147v1-abstract-full').style.display = 'none'; document.getElementById('1703.03147v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 9 March, 2017; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2017.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">arXiv admin note: text overlap with arXiv:1504.04044</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1701.07473">arXiv:1701.07473</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1701.07473">pdf</a>, <a href="https://arxiv.org/ps/1701.07473">ps</a>, <a href="https://arxiv.org/format/1701.07473">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Data Structures and Algorithms">cs.DS</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Databases">cs.DB</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Implementation of Tetris as a Model Counter
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Dobler%2C+J">Jimmy Dobler</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Rudra%2C+A">Atri Rudra</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1701.07473v1-abstract-short" style="display: inline;">
        Solving SharpSAT problems is an important area of work. In this paper, we discuss implementing Tetris, an algorithm originally designed for handling natural joins, as an exact model counter for the SharpSAT problem. Tetris uses a simple geometric framework, yet manages to achieve the fractional hypertree-width bound. Its design allows it to handle complex problems involving extremely large numbers&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1701.07473v1-abstract-full').style.display = 'inline'; document.getElementById('1701.07473v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1701.07473v1-abstract-full" style="display: none;">
        Solving SharpSAT problems is an important area of work. In this paper, we discuss implementing Tetris, an algorithm originally designed for handling natural joins, as an exact model counter for the SharpSAT problem. Tetris uses a simple geometric framework, yet manages to achieve the fractional hypertree-width bound. Its design allows it to handle complex problems involving extremely large numbers of clauses on which other state-of-the-art model counters do not perform well, yet still performs strongly on standard SAT benchmarks.
  We have achieved the following objectives. First, we have found a natural set of model counting benchmarks on which Tetris outperforms other model counters. Second, we have constructed a data structure capable of efficiently handling and caching all of the data Tetris needs to work on over the course of the algorithm. Third, we have modified Tetris in order to move from a theoretical, asymptotic-time-focused environment to one that performs well in practice. In particular, we have managed to produce results keeping us within a single order of magnitude as compared to other solvers on most benchmarks, and outperform those solvers by multiple orders of magnitude on others.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1701.07473v1-abstract-full').style.display = 'none'; document.getElementById('1701.07473v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 25 January, 2017; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2017.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1611.01569">arXiv:1611.01569</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1611.01569">pdf</a>, <a href="https://arxiv.org/ps/1611.01569">ps</a>, <a href="https://arxiv.org/format/1611.01569">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Data Structures and Algorithms">cs.DS</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        A Two Pronged Progress in Structured Dense Matrix Multiplication
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=De+Sa%2C+C">Christopher De Sa</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Gu%2C+A">Albert Gu</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Puttagunta%2C+R">Rohan Puttagunta</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=R%C3%A9%2C+C">Christopher Ré</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Rudra%2C+A">Atri Rudra</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1611.01569v3-abstract-short" style="display: inline;">
        Matrix-vector multiplication is one of the most fundamental computing primitives. Given a matrix $A\in\mathbb{F}^{N\times N}$ and a vector $b$, it is known that in the worst case $Θ(N^2)$ operations over $\mathbb{F}$ are needed to compute $Ab$. A broad question is to identify classes of structured dense matrices that can be represented with $O(N)$ parameters, and for which matrix-vector multiplica&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1611.01569v3-abstract-full').style.display = 'inline'; document.getElementById('1611.01569v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1611.01569v3-abstract-full" style="display: none;">
        Matrix-vector multiplication is one of the most fundamental computing primitives. Given a matrix $A\in\mathbb{F}^{N\times N}$ and a vector $b$, it is known that in the worst case $Θ(N^2)$ operations over $\mathbb{F}$ are needed to compute $Ab$. A broad question is to identify classes of structured dense matrices that can be represented with $O(N)$ parameters, and for which matrix-vector multiplication can be performed sub-quadratically. One such class of structured matrices is the orthogonal polynomial transforms, whose rows correspond to a family of orthogonal polynomials. Other well known classes include the Toeplitz, Hankel, Vandermonde, Cauchy matrices and their extensions that are all special cases of a ldisplacement rank property. In this paper, we make progress on two fronts:
  1. We introduce the notion of recurrence width of matrices. For matrices with constant recurrence width, we design algorithms to compute $Ab$ and $A^Tb$ with a near-linear number of operations. This notion of width is finer than all the above classes of structured matrices and thus we can compute multiplication for all of them using the same core algorithm.
  2. We additionally adapt this algorithm to an algorithm for a much more general class of matrices with displacement structure: those with low displacement rank with respect to quasiseparable matrices. This class includes Toeplitz-plus-Hankel-like matrices, Discrete Cosine/Sine Transforms, and more, and captures all previously known matrices with displacement structure that we are aware of under a unified parametrization and algorithm.
  Our work unifies, generalizes, and simplifies existing state-of-the-art results in structured matrix-vector multiplication. Finally, we show how applications in areas such as multipoint evaluations of multivariate polynomials can be reduced to problems involving low recurrence width matrices.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1611.01569v3-abstract-full').style.display = 'none'; document.getElementById('1611.01569v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 17 November, 2017; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 4 November, 2016;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2016.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1608.03313">arXiv:1608.03313</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1608.03313">pdf</a>, <a href="https://arxiv.org/ps/1608.03313">ps</a>, <a href="https://arxiv.org/format/1608.03313">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computational Complexity">cs.CC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Distributed, Parallel, and Cluster Computing">cs.DC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Tight Network Topology Dependent Bounds on Rounds of Communication
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Chattopadhyay%2C+A">Arkadev Chattopadhyay</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Langberg%2C+M">Michael Langberg</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Li%2C+S">Shi Li</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Rudra%2C+A">Atri Rudra</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1608.03313v2-abstract-short" style="display: inline;">
        We prove tight network topology dependent bounds on the round complexity of computing well studied $k$-party functions such as set disjointness and element distinctness. Unlike the usual case in the CONGEST model in distributed computing, we fix the function and then vary the underlying network topology. This complements the recent such results on total communication that have received some attent&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1608.03313v2-abstract-full').style.display = 'inline'; document.getElementById('1608.03313v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1608.03313v2-abstract-full" style="display: none;">
        We prove tight network topology dependent bounds on the round complexity of computing well studied $k$-party functions such as set disjointness and element distinctness. Unlike the usual case in the CONGEST model in distributed computing, we fix the function and then vary the underlying network topology. This complements the recent such results on total communication that have received some attention. We also present some applications to distributed graph computation problems.
  Our main contribution is a proof technique that allows us to reduce the problem on a general graph topology to a relevant two-party communication complexity problem. However, unlike many previous works that also used the same high level strategy, we do not reason about a two-party communication problem that is induced by a cut in the graph. To `stitch&#39; back the various lower bounds from the two party communication problems, we use the notion of timed graph that has seen prior use in network coding. Our reductions use some tools from Steiner tree packing and multi-commodity flow problems that have a delay constraint.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1608.03313v2-abstract-full').style.display = 'none'; document.getElementById('1608.03313v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 1 November, 2016; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 10 August, 2016;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2016.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">31 pages, 2 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1504.06602">arXiv:1504.06602</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1504.06602">pdf</a>, <a href="https://arxiv.org/ps/1504.06602">ps</a>, <a href="https://arxiv.org/format/1504.06602">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computational Complexity">cs.CC</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        The Range of Topological Effects on Communication
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Chattopadhyay%2C+A">Arkadev Chattopadhyay</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Rudra%2C+A">Atri Rudra</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1504.06602v1-abstract-short" style="display: inline;">
        We continue the study of communication cost of computing functions when inputs are distributed among $k$ processors, each of which is located at one vertex of a network/graph called a terminal. Every other node of the network also has a processor, with no input. The communication is point-to-point and the cost is the total number of bits exchanged by the protocol, in the worst case, on all edges.&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1504.06602v1-abstract-full').style.display = 'inline'; document.getElementById('1504.06602v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1504.06602v1-abstract-full" style="display: none;">
        We continue the study of communication cost of computing functions when inputs are distributed among $k$ processors, each of which is located at one vertex of a network/graph called a terminal. Every other node of the network also has a processor, with no input. The communication is point-to-point and the cost is the total number of bits exchanged by the protocol, in the worst case, on all edges.
  Chattopadhyay, Radhakrishnan and Rudra (FOCS&#39;14) recently initiated a study of the effect of topology of the network on the total communication cost using tools from $L_1$ embeddings. Their techniques provided tight bounds for simple functions like Element-Distinctness (ED), which depend on the 1-median of the graph. This work addresses two other kinds of natural functions. We show that for a large class of natural functions like Set-Disjointness the communication cost is essentially $n$ times the cost of the optimal Steiner tree connecting the terminals. Further, we show for natural composed functions like $\text{ED} \circ \text{XOR}$ and $\text{XOR} \circ \text{ED}$, the naive protocols suggested by their definition is optimal for general networks. Interestingly, the bounds for these functions depend on more involved topological parameters that are a combination of Steiner tree and 1-median costs.
  To obtain our results, we use some new tools in addition to ones used in Chattopadhyay et. al. These include (i) viewing the communication constraints via a linear program; (ii) using tools from the theory of tree embeddings to prove topology sensitive direct sum results that handle the case of composed functions and (iii) representing the communication constraints of certain problems as a family of collection of multiway cuts, where each multiway cut simulates the hardness of computing the function on the star topology.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1504.06602v1-abstract-full').style.display = 'none'; document.getElementById('1504.06602v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 24 April, 2015; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2015.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1504.04044">arXiv:1504.04044</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1504.04044">pdf</a>, <a href="https://arxiv.org/ps/1504.04044">ps</a>, <a href="https://arxiv.org/format/1504.04044">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Databases">cs.DB</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Data Structures and Algorithms">cs.DS</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Logic in Computer Science">cs.LO</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        FAQ: Questions Asked Frequently
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Khamis%2C+M+A">Mahmoud Abo Khamis</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Ngo%2C+H+Q">Hung Q. Ngo</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Rudra%2C+A">Atri Rudra</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1504.04044v6-abstract-short" style="display: inline;">
        We define and study the Functional Aggregate Query (FAQ) problem, which encompasses many frequently asked questions in constraint satisfaction, databases, matrix operations, probabilistic graphical models and logic. This is our main conceptual contribution.
  We then present a simple algorithm called &#34;InsideOut&#34; to solve this general problem. InsideOut is a variation of the traditional dynamic pro&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1504.04044v6-abstract-full').style.display = 'inline'; document.getElementById('1504.04044v6-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1504.04044v6-abstract-full" style="display: none;">
        We define and study the Functional Aggregate Query (FAQ) problem, which encompasses many frequently asked questions in constraint satisfaction, databases, matrix operations, probabilistic graphical models and logic. This is our main conceptual contribution.
  We then present a simple algorithm called &#34;InsideOut&#34; to solve this general problem. InsideOut is a variation of the traditional dynamic programming approach for constraint programming based on variable elimination. Our variation adds a couple of simple twists to basic variable elimination in order to deal with the generality of FAQ, to take full advantage of Grohe and Marx&#39;s fractional edge cover framework, and of the analysis of recent worst-case optimal relational join algorithms.
  As is the case with constraint programming and graphical model inference, to make InsideOut run efficiently we need to solve an optimization problem to compute an appropriate &#39;variable ordering&#39;. The main technical contribution of this work is a precise characterization of when a variable ordering is &#39;semantically equivalent&#39; to the variable ordering given by the input FAQ expression. Then, we design an approximation algorithm to find an equivalent variable ordering that has the best &#39;fractional FAQ-width&#39;. Our results imply a host of known and a few new results in graphical model inference, matrix operations, relational joins, and logic.
  We also briefly explain how recent algorithms on beyond worst-case analysis for joins and those for solving SAT and #SAT can be viewed as variable elimination to solve FAQ over compactly represented input functions.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1504.04044v6-abstract-full').style.display = 'none'; document.getElementById('1504.04044v6-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 5 February, 2017; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 15 April, 2015;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2015.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1503.04169">arXiv:1503.04169</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1503.04169">pdf</a>, <a href="https://arxiv.org/format/1503.04169">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Databases">cs.DB</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Data Structures and Algorithms">cs.DS</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Join Processing for Graph Patterns: An Old Dog with New Tricks
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Nguyen%2C+D">Dung Nguyen</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Aref%2C+M">Molham Aref</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Bravenboer%2C+M">Martin Bravenboer</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Kollias%2C+G">George Kollias</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Ngo%2C+H+Q">Hung Q. Ngo</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=R%C3%A9%2C+C">Christopher Ré</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Rudra%2C+A">Atri Rudra</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1503.04169v2-abstract-short" style="display: inline;">
        Join optimization has been dominated by Selinger-style, pairwise optimizers for decades. But, Selinger-style algorithms are asymptotically suboptimal for applications in graphic analytics. This suboptimality is one of the reasons that many have advocated supplementing relational engines with specialized graph processing engines. Recently, new join algorithms have been discovered that achieve optim&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1503.04169v2-abstract-full').style.display = 'inline'; document.getElementById('1503.04169v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1503.04169v2-abstract-full" style="display: none;">
        Join optimization has been dominated by Selinger-style, pairwise optimizers for decades. But, Selinger-style algorithms are asymptotically suboptimal for applications in graphic analytics. This suboptimality is one of the reasons that many have advocated supplementing relational engines with specialized graph processing engines. Recently, new join algorithms have been discovered that achieve optimal worst-case run times for any join or even so-called beyond worst-case (or instance optimal) run time guarantees for specialized classes of joins. These new algorithms match or improve on those used in specialized graph-processing systems. This paper asks can these new join algorithms allow relational engines to close the performance gap with graph engines?
  We examine this question for graph-pattern queries or join queries. We find that classical relational databases like Postgres and MonetDB or newer graph databases/stores like Virtuoso and Neo4j may be orders of magnitude slower than these new approaches compared to a fully featured RDBMS, LogicBlox, using these new ideas. Our results demonstrate that an RDBMS with such new algorithms can perform as well as specialized engines like GraphLab -- while retaining a high-level interface. We hope this adds to the ongoing debate of the role of graph accelerators, new graph systems, and relational systems in modern workloads.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1503.04169v2-abstract-full').style.display = 'none'; document.getElementById('1503.04169v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 17 March, 2015; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 13 March, 2015;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2015.
      
    </p>
    

    
      <p class="comments is-size-7">
        

        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          H.2; E.1; H.3.4
        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1408.2237">arXiv:1408.2237</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1408.2237">pdf</a>, <a href="https://arxiv.org/ps/1408.2237">ps</a>, <a href="https://arxiv.org/format/1408.2237">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Information Theory">cs.IT</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        It&#39;ll probably work out: improved list-decoding through random operations
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Rudra%2C+A">Atri Rudra</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Wootters%2C+M">Mary Wootters</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1408.2237v1-abstract-short" style="display: inline;">
        In this work, we introduce a framework to study the effect of random operations on the combinatorial list-decodability of a code. The operations we consider correspond to row and column operations on the matrix obtained from the code by stacking the codewords together as columns. This captures many natural transformations on codes, such as puncturing, folding, and taking subcodes; we show that man&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1408.2237v1-abstract-full').style.display = 'inline'; document.getElementById('1408.2237v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1408.2237v1-abstract-full" style="display: none;">
        In this work, we introduce a framework to study the effect of random operations on the combinatorial list-decodability of a code. The operations we consider correspond to row and column operations on the matrix obtained from the code by stacking the codewords together as columns. This captures many natural transformations on codes, such as puncturing, folding, and taking subcodes; we show that many such operations can improve the list-decoding properties of a code. There are two main points to this. First, our goal is to advance our (combinatorial) understanding of list-decodability, by understanding what structure (or lack thereof) is necessary to obtain it. Second, we use our more general results to obtain a few interesting corollaries for list decoding:
  (1) We show the existence of binary codes that are combinatorially list-decodable from $1/2-ε$ fraction of errors with optimal rate $Ω(ε^2)$ that can be encoded in linear time.
  (2) We show that any code with $Ω(1)$ relative distance, when randomly folded, is combinatorially list-decodable $1-ε$ fraction of errors with high probability. This formalizes the intuition for why the folding operation has been successful in obtaining codes with optimal list decoding parameters; previously, all arguments used algebraic methods and worked only with specific codes.
  (3) We show that any code which is list-decodable with suboptimal list sizes has many subcodes which have near-optimal list sizes, while retaining the error correcting capabilities of the original code. This generalizes recent results where subspace evasive sets have been used to reduce list sizes of codes that achieve list decoding capacity.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1408.2237v1-abstract-full').style.display = 'none'; document.getElementById('1408.2237v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 10 August, 2014; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2014.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1404.5190">arXiv:1404.5190</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1404.5190">pdf</a>, <a href="https://arxiv.org/format/1404.5190">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Information Theory">cs.IT</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Sparse Approximation, List Decoding, and Uncertainty Principles
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Khamis%2C+M+A">Mahmoud Abo Khamis</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Gilbert%2C+A+C">Anna C. Gilbert</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Ngo%2C+H+Q">Hung Q. Ngo</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Rudra%2C+A">Atri Rudra</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1404.5190v2-abstract-short" style="display: inline;">
        We consider list versions of sparse approximation problems, where unlike the existing results in sparse approximation that consider situations with unique solutions, we are interested in multiple solutions. We introduce these problems and present the first combinatorial results on the output list size. These generalize and enhance some of the existing results on threshold phenomenon and uncertaint&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1404.5190v2-abstract-full').style.display = 'inline'; document.getElementById('1404.5190v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1404.5190v2-abstract-full" style="display: none;">
        We consider list versions of sparse approximation problems, where unlike the existing results in sparse approximation that consider situations with unique solutions, we are interested in multiple solutions. We introduce these problems and present the first combinatorial results on the output list size. These generalize and enhance some of the existing results on threshold phenomenon and uncertainty principles in sparse approximations. Our definitions and results are inspired by similar results in list decoding. We also present lower bound examples that bolster our results and show they are of the appropriate size.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1404.5190v2-abstract-full').style.display = 'none'; document.getElementById('1404.5190v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 August, 2014; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 18 April, 2014;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2014.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1404.0703">arXiv:1404.0703</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1404.0703">pdf</a>, <a href="https://arxiv.org/format/1404.0703">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Databases">cs.DB</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Data Structures and Algorithms">cs.DS</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Joins via Geometric Resolutions: Worst-case and Beyond
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Khamis%2C+M+A">Mahmoud Abo Khamis</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Ngo%2C+H+Q">Hung Q. Ngo</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=R%C3%A9%2C+C">Christopher Ré</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Rudra%2C+A">Atri Rudra</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1404.0703v7-abstract-short" style="display: inline;">
        We present a simple geometric framework for the relational join. Using this framework, we design an algorithm that achieves the fractional hypertree-width bound, which generalizes classical and recent worst-case algorithmic results on computing joins. In addition, we use our framework and the same algorithm to show a series of what are colloquially known as beyond worst-case results. The framework&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1404.0703v7-abstract-full').style.display = 'inline'; document.getElementById('1404.0703v7-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1404.0703v7-abstract-full" style="display: none;">
        We present a simple geometric framework for the relational join. Using this framework, we design an algorithm that achieves the fractional hypertree-width bound, which generalizes classical and recent worst-case algorithmic results on computing joins. In addition, we use our framework and the same algorithm to show a series of what are colloquially known as beyond worst-case results. The framework allows us to prove results for data stored in Btrees, multidimensional data structures, and even multiple indices per table. A key idea in our framework is formalizing the inference one does with an index as a type of geometric resolution; transforming the algorithmic problem of computing joins to a geometric problem. Our notion of geometric resolution can be viewed as a geometric analog of logical resolution. In addition to the geometry and logic connections, our algorithm can also be thought of as backtracking search with memoization.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1404.0703v7-abstract-full').style.display = 'none'; document.getElementById('1404.0703v7-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 23 December, 2016; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 2 April, 2014;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2014.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1310.3314">arXiv:1310.3314</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1310.3314">pdf</a>, <a href="https://arxiv.org/format/1310.3314">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Databases">cs.DB</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Data Structures and Algorithms">cs.DS</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Skew Strikes Back: New Developments in the Theory of Join Algorithms
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Ngo%2C+H+Q">Hung Q. Ngo</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Re%2C+C">Christopher Re</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Rudra%2C+A">Atri Rudra</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1310.3314v2-abstract-short" style="display: inline;">
        Evaluating the relational join is one of the central algorithmic and most well-studied problems in database systems. A staggering number of variants have been considered including Block-Nested loop join, Hash-Join, Grace, Sort-merge for discussions of more modern issues). Commercial database engines use finely tuned join heuristics that take into account a wide variety of factors including the sel&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1310.3314v2-abstract-full').style.display = 'inline'; document.getElementById('1310.3314v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1310.3314v2-abstract-full" style="display: none;">
        Evaluating the relational join is one of the central algorithmic and most well-studied problems in database systems. A staggering number of variants have been considered including Block-Nested loop join, Hash-Join, Grace, Sort-merge for discussions of more modern issues). Commercial database engines use finely tuned join heuristics that take into account a wide variety of factors including the selectivity of various predicates, memory, IO, etc. In spite of this study of join queries, the textbook description of join processing is suboptimal. This survey describes recent results on join algorithms that have provable worst-case optimality runtime guarantees. We survey recent work and provide a simpler and unified description of these algorithms that we hope is useful for theory-minded readers, algorithm designers, and systems implementors.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1310.3314v2-abstract-full').style.display = 'none'; document.getElementById('1310.3314v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 16 October, 2013; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 11 October, 2013;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2013.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1310.1891">arXiv:1310.1891</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1310.1891">pdf</a>, <a href="https://arxiv.org/ps/1310.1891">ps</a>, <a href="https://arxiv.org/format/1310.1891">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Information Theory">cs.IT</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Every list-decodable code for high noise has abundant near-optimal rate puncturings
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Rudra%2C+A">Atri Rudra</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Wootters%2C+M">Mary Wootters</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1310.1891v1-abstract-short" style="display: inline;">
        We show that any q-ary code with sufficiently good distance can be randomly punctured to obtain, with high probability, a code that is list decodable up to radius $1 - 1/q - ε$ with near-optimal rate and list sizes. Our results imply that &#34;most&#34; Reed-Solomon codes are list decodable beyond the Johnson bound, settling the long-standing open question of whether any Reed Solomon codes meet this crite&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1310.1891v1-abstract-full').style.display = 'inline'; document.getElementById('1310.1891v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1310.1891v1-abstract-full" style="display: none;">
        We show that any q-ary code with sufficiently good distance can be randomly punctured to obtain, with high probability, a code that is list decodable up to radius $1 - 1/q - ε$ with near-optimal rate and list sizes. Our results imply that &#34;most&#34; Reed-Solomon codes are list decodable beyond the Johnson bound, settling the long-standing open question of whether any Reed Solomon codes meet this criterion.
  More precisely, we show that a Reed-Solomon code with random evaluation points is, with high probability, list decodable up to radius $1 - ε$ with list sizes $O(1/ε)$ and rate $Ω(ε)$. As a second corollary of our argument, we obtain improved bounds on the list decodability of random linear codes over large fields.
  Our approach exploits techniques from high dimensional probability. Previous work used similar tools to obtain bounds on the list decodability of random linear codes, but the bounds did not scale with the size of the alphabet. In this paper, we use a chaining argument to deal with large alphabet sizes.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1310.1891v1-abstract-full').style.display = 'none'; document.getElementById('1310.1891v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 October, 2013; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2013.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1307.7810">arXiv:1307.7810</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1307.7810">pdf</a>, <a href="https://arxiv.org/ps/1307.7810">ps</a>, <a href="https://arxiv.org/format/1307.7810">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Quantitative Methods">q-bio.QM</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computational Engineering, Finance, and Science">cs.CE</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Information Theory">cs.IT</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Genomics">q-bio.GN</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Accurate Decoding of Pooled Sequenced Data Using Compressed Sensing
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Duma%2C+D">Denisa Duma</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Wootters%2C+M">Mary Wootters</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Gilbert%2C+A+C">Anna C. Gilbert</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Ngo%2C+H+Q">Hung Q. Ngo</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Rudra%2C+A">Atri Rudra</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Alpert%2C+M">Matthew Alpert</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Close%2C+T+J">Timothy J. Close</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Ciardo%2C+G">Gianfranco Ciardo</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Lonardi%2C+S">Stefano Lonardi</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1307.7810v1-abstract-short" style="display: inline;">
        In order to overcome the limitations imposed by DNA barcoding when multiplexing a large number of samples in the current generation of high-throughput sequencing instruments, we have recently proposed a new protocol that leverages advances in combinatorial pooling design (group testing) doi:10.1371/journal.pcbi.1003010. We have also demonstrated how this new protocol would enable de novo selective&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1307.7810v1-abstract-full').style.display = 'inline'; document.getElementById('1307.7810v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1307.7810v1-abstract-full" style="display: none;">
        In order to overcome the limitations imposed by DNA barcoding when multiplexing a large number of samples in the current generation of high-throughput sequencing instruments, we have recently proposed a new protocol that leverages advances in combinatorial pooling design (group testing) doi:10.1371/journal.pcbi.1003010. We have also demonstrated how this new protocol would enable de novo selective sequencing and assembly of large, highly-repetitive genomes. Here we address the problem of decoding pooled sequenced data obtained from such a protocol. Our algorithm employs a synergistic combination of ideas from compressed sensing and the decoding of error-correcting codes. Experimental results on synthetic data for the rice genome and real data for the barley genome show that our novel decoding algorithm enables significantly higher quality assemblies than the previous approach.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1307.7810v1-abstract-full').style.display = 'none'; document.getElementById('1307.7810v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 30 July, 2013; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2013.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Peer-reviewed and presented as part of the 13th Workshop on Algorithms in Bioinformatics (WABI2013)</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1304.6232">arXiv:1304.6232</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1304.6232">pdf</a>, <a href="https://arxiv.org/format/1304.6232">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Data Structures and Algorithms">cs.DS</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        L2/L2-foreach sparse recovery with low risk
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Gilbert%2C+A+C">Anna C. Gilbert</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Ngo%2C+H+Q">Hung Q. Ngo</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Porat%2C+E">Ely Porat</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Rudra%2C+A">Atri Rudra</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Strauss%2C+M+J">Martin J. Strauss</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1304.6232v1-abstract-short" style="display: inline;">
        In this paper, we consider the &#34;foreach&#34; sparse recovery problem with failure probability $p$. The goal of which is to design a distribution over $m \times N$ matrices $Φ$ and a decoding algorithm $\algo$ such that for every $\vx\in\R^N$, we have the following error guarantee with probability at least $1-p$ \[\|\vx-\algo(Φ\vx)\|_2\le C\|\vx-\vx_k\|_2,\] where $C$ is a constant (ideally arbitrarily&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1304.6232v1-abstract-full').style.display = 'inline'; document.getElementById('1304.6232v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1304.6232v1-abstract-full" style="display: none;">
        In this paper, we consider the &#34;foreach&#34; sparse recovery problem with failure probability $p$. The goal of which is to design a distribution over $m \times N$ matrices $Φ$ and a decoding algorithm $\algo$ such that for every $\vx\in\R^N$, we have the following error guarantee with probability at least $1-p$ \[\|\vx-\algo(Φ\vx)\|_2\le C\|\vx-\vx_k\|_2,\] where $C$ is a constant (ideally arbitrarily close to 1) and $\vx_k$ is the best $k$-sparse approximation of $\vx$.
  Much of the sparse recovery or compressive sensing literature has focused on the case of either $p = 0$ or $p = Ω(1)$. We initiate the study of this problem for the entire range of failure probability. Our two main results are as follows: \begin{enumerate} \item We prove a lower bound on $m$, the number measurements, of $Ω(k\log(n/k)+\log(1/p))$ for $2^{-Θ(N)}\le p &lt;1$. Cohen, Dahmen, and DeVore \cite{CDD2007:NearOptimall2l2} prove that this bound is tight. \item We prove nearly matching upper bounds for \textit{sub-linear} time decoding. Previous such results addressed only $p = Ω(1)$. \end{enumerate}
  Our results and techniques lead to the following corollaries: (i) the first ever sub-linear time decoding $\lolo$ &#34;forall&#34; sparse recovery system that requires a $\log^γ{N}$ extra factor (for some $γ&lt;1$) over the optimal $O(k\log(N/k))$ number of measurements, and (ii) extensions of Gilbert et al. \cite{GHRSW12:SimpleSignals} results for information-theoretically bounded adversaries.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1304.6232v1-abstract-full').style.display = 'none'; document.getElementById('1304.6232v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 23 April, 2013; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2013.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">1 figure, extended abstract to appear in ICALP 2013</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1302.0914">arXiv:1302.0914</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1302.0914">pdf</a>, <a href="https://arxiv.org/format/1302.0914">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Databases">cs.DB</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Beyond Worst-Case Analysis for Joins with Minesweeper
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Ngo%2C+H+Q">Hung Q. Ngo</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Nguyen%2C+D+T">Dung T. Nguyen</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=R%C3%A9%2C+C">Christopher Ré</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Rudra%2C+A">Atri Rudra</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1302.0914v5-abstract-short" style="display: inline;">
        We describe a new algorithm, Minesweeper, that is able to satisfy stronger runtime guarantees than previous join algorithms (colloquially, `beyond worst-case guarantees&#39;) for data in indexed search trees. Our first contribution is developing a framework to measure this stronger notion of complexity, which we call {\it certificate complexity}, that extends notions of Barbay et al. and Demaine et al&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1302.0914v5-abstract-full').style.display = 'inline'; document.getElementById('1302.0914v5-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1302.0914v5-abstract-full" style="display: none;">
        We describe a new algorithm, Minesweeper, that is able to satisfy stronger runtime guarantees than previous join algorithms (colloquially, `beyond worst-case guarantees&#39;) for data in indexed search trees. Our first contribution is developing a framework to measure this stronger notion of complexity, which we call {\it certificate complexity}, that extends notions of Barbay et al. and Demaine et al.; a certificate is a set of propositional formulae that certifies that the output is correct. This notion captures a natural class of join algorithms. In addition, the certificate allows us to define a strictly stronger notion of runtime complexity than traditional worst-case guarantees. Our second contribution is to develop a dichotomy theorem for the certificate-based notion of complexity. Roughly, we show that Minesweeper evaluates $β$-acyclic queries in time linear in the certificate plus the output size, while for any $β$-cyclic query there is some instance that takes superlinear time in the certificate (and for which the output is no larger than the certificate size). We also extend our certificate-complexity analysis to queries with bounded treewidth and the triangle query.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1302.0914v5-abstract-full').style.display = 'none'; document.getElementById('1302.0914v5-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 28 March, 2014; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 4 February, 2013;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2013.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">[This is the full version of our PODS&#39;2014 paper.]</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          H.2.4
        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1205.1462">arXiv:1205.1462</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1205.1462">pdf</a>, <a href="https://arxiv.org/ps/1205.1462">ps</a>, <a href="https://arxiv.org/format/1205.1462">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Information Theory">cs.IT</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computational Complexity">cs.CC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Almost Universal Hash Families are also Storage Enforcing
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Husain%2C+M+I">Mohammad Iftekhar Husain</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Ko%2C+S">Steve Ko</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Rudra%2C+A">Atri Rudra</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Uurtamo%2C+S">Steve Uurtamo</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1205.1462v1-abstract-short" style="display: inline;">
        We show that every almost universal hash function also has the storage enforcement property. Almost universal hash functions have found numerous applications and we show that this new storage enforcement property allows the application of almost universal hash functions in a wide range of remote verification tasks: (i) Proof of Secure Erasure (where we want to remotely erase and securely update th&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1205.1462v1-abstract-full').style.display = 'inline'; document.getElementById('1205.1462v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1205.1462v1-abstract-full" style="display: none;">
        We show that every almost universal hash function also has the storage enforcement property. Almost universal hash functions have found numerous applications and we show that this new storage enforcement property allows the application of almost universal hash functions in a wide range of remote verification tasks: (i) Proof of Secure Erasure (where we want to remotely erase and securely update the code of a compromised machine with memory-bounded adversary), (ii) Proof of Ownership (where a storage server wants to check if a client has the data it claims to have before giving access to deduplicated data) and (iii) Data possession (where the client wants to verify whether the remote storage server is storing its data). Specifically, storage enforcement guarantee in the classical data possession problem removes any practical incentive for the storage server to cheat the client by saving on storage space.
  The proof of our result relies on a natural combination of Kolmogorov Complexity and List Decoding. To the best of our knowledge this is the first work that combines these two techniques. We believe the newly introduced storage enforcement property of almost universal hash functions will open promising avenues of exciting research under memory-bounded (bounded storage) adversary model.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1205.1462v1-abstract-full').style.display = 'none'; document.getElementById('1205.1462v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 May, 2012; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2012.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">arXiv admin note: substantial text overlap with arXiv:1104.3025</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1204.3180">arXiv:1204.3180</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1204.3180">pdf</a>, <a href="https://arxiv.org/format/1204.3180">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Discrete Mathematics">cs.DM</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Networking and Internet Architecture">cs.NI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Analyzing Nonblocking Switching Networks using Linear Programming (Duality)
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Ngo%2C+H+Q">Hung Q. Ngo</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Rudra%2C+A">Atri Rudra</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Le%2C+A+N">Anh N. Le</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Nguyen%2C+T">Thanh-Nhan Nguyen</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1204.3180v1-abstract-short" style="display: inline;">
        The main task in analyzing a switching network design (including circuit-, multirate-, and photonic-switching) is to determine the minimum number of some switching components so that the design is non-blocking in some sense (e.g., strict- or wide-sense). We show that, in many cases, this task can be accomplished with a simple two-step strategy: (1) formulate a linear program whose optimum value is&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1204.3180v1-abstract-full').style.display = 'inline'; document.getElementById('1204.3180v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1204.3180v1-abstract-full" style="display: none;">
        The main task in analyzing a switching network design (including circuit-, multirate-, and photonic-switching) is to determine the minimum number of some switching components so that the design is non-blocking in some sense (e.g., strict- or wide-sense). We show that, in many cases, this task can be accomplished with a simple two-step strategy: (1) formulate a linear program whose optimum value is a bound for the minimum number we are seeking, and (2) specify a solution to the dual program, whose objective value by weak duality immediately yields a sufficient condition for the design to be non-blocking.
  We illustrate this technique through a variety of examples, ranging from circuit to multirate to photonic switching, from unicast to $f$-cast and multicast, and from strict- to wide-sense non-blocking. The switching architectures in the examples are of Clos-type and Banyan-type, which are the two most popular architectural choices for designing non-blocking switching networks.
  To prove the result in the multirate Clos network case, we formulate a new problem called {\sc dynamic weighted edge coloring} which generalizes the {\sc dynamic bin packing} problem. We then design an algorithm with competitive ratio 5.6355 for the problem. The algorithm is analyzed using the linear programming technique. A new upper-bound for multirate wide-sense non-blocking Clos networks follow, improving upon a decade-old bound on the same problem.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1204.3180v1-abstract-full').style.display = 'none'; document.getElementById('1204.3180v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 14 April, 2012; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2012.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1203.1952">arXiv:1203.1952</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1203.1952">pdf</a>, <a href="https://arxiv.org/format/1203.1952">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Databases">cs.DB</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Data Structures and Algorithms">cs.DS</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Combinatorics">math.CO</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Worst-case Optimal Join Algorithms
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Ngo%2C+H+Q">Hung Q. Ngo</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Porat%2C+E">Ely Porat</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=R%C3%A9%2C+C">Christopher Ré</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Rudra%2C+A">Atri Rudra</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1203.1952v1-abstract-short" style="display: inline;">
        Efficient join processing is one of the most fundamental and well-studied tasks in database research. In this work, we examine algorithms for natural join queries over many relations and describe a novel algorithm to process these queries optimally in terms of worst-case data complexity. Our result builds on recent work by Atserias, Grohe, and Marx, who gave bounds on the size of a full conjunctiv&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1203.1952v1-abstract-full').style.display = 'inline'; document.getElementById('1203.1952v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1203.1952v1-abstract-full" style="display: none;">
        Efficient join processing is one of the most fundamental and well-studied tasks in database research. In this work, we examine algorithms for natural join queries over many relations and describe a novel algorithm to process these queries optimally in terms of worst-case data complexity. Our result builds on recent work by Atserias, Grohe, and Marx, who gave bounds on the size of a full conjunctive query in terms of the sizes of the individual relations in the body of the query. These bounds, however, are not constructive: they rely on Shearer&#39;s entropy inequality which is information-theoretic. Thus, the previous results leave open the question of whether there exist algorithms whose running time achieve these optimal bounds. An answer to this question may be interesting to database practice, as it is known that any algorithm based on the traditional select-project-join style plans typically employed in an RDBMS are asymptotically slower than the optimal for some queries. We construct an algorithm whose running time is worst-case optimal for all natural join queries. Our result may be of independent interest, as our algorithm also yields a constructive proof of the general fractional cover bound by Atserias, Grohe, and Marx without using Shearer&#39;s inequality. This bound implies two famous inequalities in geometry: the Loomis-Whitney inequality and the Bollobás-Thomason inequality. Hence, our results algorithmically prove these inequalities as well. Finally, we discuss how our algorithm can be used to compute a relaxed notion of joins.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1203.1952v1-abstract-full').style.display = 'none'; document.getElementById('1203.1952v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 March, 2012; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2012.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1201.3306">arXiv:1201.3306</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1201.3306">pdf</a>, <a href="https://arxiv.org/format/1201.3306">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computational Complexity">cs.CC</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Simulating Special but Natural Quantum Circuits
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Lipton%2C+R+J">Richard J. Lipton</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Regan%2C+K+W">Kenneth W. Regan</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Rudra%2C+A">Atri Rudra</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1201.3306v1-abstract-short" style="display: inline;">
        We identify a sub-class of BQP that captures certain structural commonalities among many quantum algorithms including Shor&#39;s algorithms. This class does not contain all of BQP (e.g. Grover&#39;s algorithm does not fall into this class). Our main result is that any algorithm in this class that measures at most O(log n) qubits can be simulated by classical randomized polynomial time algorithms. This doe&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1201.3306v1-abstract-full').style.display = 'inline'; document.getElementById('1201.3306v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1201.3306v1-abstract-full" style="display: none;">
        We identify a sub-class of BQP that captures certain structural commonalities among many quantum algorithms including Shor&#39;s algorithms. This class does not contain all of BQP (e.g. Grover&#39;s algorithm does not fall into this class). Our main result is that any algorithm in this class that measures at most O(log n) qubits can be simulated by classical randomized polynomial time algorithms. This does not dequantize Shor&#39;s algorithm (as the latter measures n qubits) but our work also highlights a new potentially hard function for cryptographic applications.
  Our main technical contribution is (to the best of our knowledge) a new exact characterization of certain sums of Fourier-type coefficients (with exponentially many summands).
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1201.3306v1-abstract-full').style.display = 'none'; document.getElementById('1201.3306v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 16 January, 2012; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2012.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1104.3025">arXiv:1104.3025</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1104.3025">pdf</a>, <a href="https://arxiv.org/ps/1104.3025">ps</a>, <a href="https://arxiv.org/format/1104.3025">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computational Complexity">cs.CC</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Storage Enforcement with Kolmogorov Complexity and List Decoding
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Husain%2C+M+I">Mohammad Iftekhar Husain</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Ko%2C+S">Steve Ko</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Rudra%2C+A">Atri Rudra</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Uurtamo%2C+S">Steve Uurtamo</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1104.3025v1-abstract-short" style="display: inline;">
        We consider the following problem that arises in outsourced storage: a user stores her data $x$ on a remote server but wants to audit the server at some later point to make sure it actually did store $x$. The goal is to design a (randomized) verification protocol that has the property that if the server passes the verification with some reasonably high probability then the user can rest assured th&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1104.3025v1-abstract-full').style.display = 'inline'; document.getElementById('1104.3025v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1104.3025v1-abstract-full" style="display: none;">
        We consider the following problem that arises in outsourced storage: a user stores her data $x$ on a remote server but wants to audit the server at some later point to make sure it actually did store $x$. The goal is to design a (randomized) verification protocol that has the property that if the server passes the verification with some reasonably high probability then the user can rest assured that the server is storing $x$.
  In this work we present an optimal solution (in terms of the user&#39;s storage and communication) while at the same time ensuring that a server that passes the verification protocol with any reasonable probability will store, to within a small \textit{additive} factor, $C(x)$ bits of information, where $C(x)$ is the plain Kolmogorov complexity of $x$. (Since we cannot prevent the server from compressing $x$, $C(x)$ is a natural upper bound.) The proof of security of our protocol combines Kolmogorov complexity with list decoding and unlike previous work that relies upon cryptographic assumptions, we allow the server to have unlimited computational power. To the best of our knowledge, this is the first work that combines Kolmogorov complexity and list decoding.
  Our framework is general enough to capture extensions where the user splits up $x$ and stores the fragment across multiple servers and our verification protocol can handle non-responsive servers and colluding servers. As a by-product, we also get a proof of retrievability. Finally, our results also have an application in `storage enforcement&#39; schemes, which in turn have an application in trying to update a remote server that is potentially infected with a virus.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1104.3025v1-abstract-full').style.display = 'none'; document.getElementById('1104.3025v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 April, 2011; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2011.
      
    </p>
    

    
      <p class="comments is-size-7">
        

        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          F.2; E.4; H.3
        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1102.4129">arXiv:1102.4129</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1102.4129">pdf</a>, <a href="https://arxiv.org/ps/1102.4129">ps</a>, <a href="https://arxiv.org/format/1102.4129">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Data Structures and Algorithms">cs.DS</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computational Complexity">cs.CC</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Networking and Internet Architecture">cs.NI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        An FPTAS for the Lead-Based Multiple Video Transmission LMVT Problem
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Roy%2C+S">Swapnoneel Roy</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Rudra%2C+A">Atri Rudra</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1102.4129v3-abstract-short" style="display: inline;">
        The Lead-Based Multiple Video Transmission (LMVT) problem is motivated by applications in managing the quality of experience (QoE) of video streaming for mobile clients. In an earlier work, the LMVT problem has been shown to be NP-hard for a specific bit-to-lead conversion function $φ$. In this work, we show the problem to be NP-hard even if the function $φ$ is linear. We then design a fully polyn&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1102.4129v3-abstract-full').style.display = 'inline'; document.getElementById('1102.4129v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1102.4129v3-abstract-full" style="display: none;">
        The Lead-Based Multiple Video Transmission (LMVT) problem is motivated by applications in managing the quality of experience (QoE) of video streaming for mobile clients. In an earlier work, the LMVT problem has been shown to be NP-hard for a specific bit-to-lead conversion function $φ$. In this work, we show the problem to be NP-hard even if the function $φ$ is linear. We then design a fully polynomial time approximation scheme (FPTAS) for the problem. This problem is exactly equivalent to the Santa Clause Problem on which there has been a lot of work done off-late.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1102.4129v3-abstract-full').style.display = 'none'; document.getElementById('1102.4129v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 4 October, 2011; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 20 February, 2011;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2011.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1008.5356">arXiv:1008.5356</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1008.5356">pdf</a>, <a href="https://arxiv.org/ps/1008.5356">ps</a>, <a href="https://arxiv.org/format/1008.5356">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Data Structures and Algorithms">cs.DS</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        When LP is the Cure for Your Matching Woes: Improved Bounds for Stochastic Matchings
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Bansal%2C+N">Nikhil Bansal</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Gupta%2C+A">Anupam Gupta</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Li%2C+J">Jian Li</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Mestre%2C+J">Julian Mestre</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Nagarajan%2C+V">Viswanath Nagarajan</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Rudra%2C+A">Atri Rudra</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1008.5356v1-abstract-short" style="display: inline;">
        Consider a random graph model where each possible edge $e$ is present independently with some probability $p_e$. Given these probabilities, we want to build a large/heavy matching in the randomly generated graph. However, the only way we can find out whether an edge is present or not is to query it, and if the edge is indeed present in the graph, we are forced to add it to our matching. Further, e&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1008.5356v1-abstract-full').style.display = 'inline'; document.getElementById('1008.5356v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1008.5356v1-abstract-full" style="display: none;">
        Consider a random graph model where each possible edge $e$ is present independently with some probability $p_e$. Given these probabilities, we want to build a large/heavy matching in the randomly generated graph. However, the only way we can find out whether an edge is present or not is to query it, and if the edge is indeed present in the graph, we are forced to add it to our matching. Further, each vertex $i$ is allowed to be queried at most $t_i$ times. How should we adaptively query the edges to maximize the expected weight of the matching? We consider several matching problems in this general framework (some of which arise in kidney exchanges and online dating, and others arise in modeling online advertisements); we give LP-rounding based constant-factor approximation algorithms for these problems. Our main results are the following:
  We give a 4 approximation for weighted stochastic matching on general graphs, and a 3 approximation on bipartite graphs. This answers an open question from [Chen etal ICALP 09]. Combining our LP-rounding algorithm with the natural greedy algorithm, we give an improved 3.46 approximation for unweighted stochastic matching on general graphs.
  We introduce a generalization of the stochastic online matching problem [Feldman etal FOCS 09] that also models preference-uncertainty and timeouts of buyers, and give a constant factor approximation algorithm.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1008.5356v1-abstract-full').style.display = 'none'; document.getElementById('1008.5356v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 31 August, 2010; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2010.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">26 pages, preliminary version appears in ESA 2010</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1004.4601">arXiv:1004.4601</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1004.4601">pdf</a>, <a href="https://arxiv.org/ps/1004.4601">ps</a>, <a href="https://arxiv.org/format/1004.4601">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Information Theory">cs.IT</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Data Stream Algorithms for Codeword Testing
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Rudra%2C+A">Atri Rudra</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Uurtamo%2C+S">Steve Uurtamo</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1004.4601v1-abstract-short" style="display: inline;">
        Motivated by applications in storage systems and property testing, we study data stream algorithms for local testing and tolerant testing of codes. Ideally, we would like to know whether there exist asymptotically good codes that can be local/tolerant tested with one-pass, poly-log space data stream algorithms. We show that for the error detection problem (and hence, the local testing problem), th&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1004.4601v1-abstract-full').style.display = 'inline'; document.getElementById('1004.4601v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1004.4601v1-abstract-full" style="display: none;">
        Motivated by applications in storage systems and property testing, we study data stream algorithms for local testing and tolerant testing of codes. Ideally, we would like to know whether there exist asymptotically good codes that can be local/tolerant tested with one-pass, poly-log space data stream algorithms. We show that for the error detection problem (and hence, the local testing problem), there exists a one-pass, log-space data stream algorithm for a broad class of asymptotically good codes, including the Reed-Solomon (RS) code and expander codes. In our technically more involved result, we give a one-pass, $O(e\log^2{n})$-space algorithm for RS (and related) codes with dimension $k$ and block length $n$ that can distinguish between the cases when the Hamming distance between the received word and the code is at most $e$ and at least $a\cdot e$ for some absolute constant $a&gt;1$. For RS codes with random errors, we can obtain $e\le O(n/k)$. For  folded RS codes, we obtain similar results for worst-case errors as long as $e\le (n/k)^{1-\eps}$ for any constant $\eps&gt;0$. These results follow by reducing the tolerant testing problem to the error detection problem using results from group testing and the list decodability of the code. We also show that using our techniques, the space requirement and the upper bound of $e\le O(n/k)$ cannot be improved by more than logarithmic factors.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1004.4601v1-abstract-full').style.display = 'none'; document.getElementById('1004.4601v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 26 April, 2010; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2010.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1003.0167">arXiv:1003.0167</a>
        <span>&nbsp;&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Data Structures and Algorithms">cs.DS</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Discrete Mathematics">cs.DM</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        When LP is the Cure for Your Matching Woes: Approximating Stochastic Matchings
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Bansal%2C+N">Nikhil Bansal</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Gupta%2C+A">Anupam Gupta</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Nagarajan%2C+V">Viswanath Nagarajan</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Rudra%2C+A">Atri Rudra</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1003.0167v2-abstract-short" style="display: inline;">
        This results in this paper have been merged with the result in arXiv:1002.3763v1 

The authors would like to withdraw this version.

Please see arXiv:1008.5356v1 for the merged version.
        
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1003.0167v2-abstract-full" style="display: none;">
        This results in this paper have been merged with the result in arXiv:1002.3763v1 

The authors would like to withdraw this version.

Please see arXiv:1008.5356v1 for the merged version.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1003.0167v2-abstract-full').style.display = 'none'; document.getElementById('1003.0167v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 2 September, 2010; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 28 February, 2010;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2010.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">This paper has been withdrawn due to new merged paper arXiv:1008.5356v1</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1001.1781">arXiv:1001.1781</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1001.1781">pdf</a>, <a href="https://arxiv.org/ps/1001.1781">ps</a>, <a href="https://arxiv.org/format/1001.1781">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Information Theory">cs.IT</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Two Theorems in List Decoding
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Rudra%2C+A">Atri Rudra</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Uurtamo%2C+S">Steve Uurtamo</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1001.1781v1-abstract-short" style="display: inline;">
        We prove the following results concerning the list decoding of error-correcting codes:
  (i) We show that for \textit{any} code with a relative distance of $δ$ (over a large enough alphabet), the following result holds for \textit{random errors}: With high probability, for a $ρ\le δ-\eps$ fraction of random errors (for any $\eps&gt;0$), the received word will have only the transmitted codeword in a&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1001.1781v1-abstract-full').style.display = 'inline'; document.getElementById('1001.1781v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1001.1781v1-abstract-full" style="display: none;">
          We prove the following results concerning the list decoding of error-correcting codes:
  (i) We show that for \textit{any} code with a relative distance of $δ$ (over a large enough alphabet), the following result holds for \textit{random errors}: With high probability, for a $ρ\le δ-\eps$ fraction of random errors (for any $\eps&gt;0$), the received word will have only the transmitted codeword in a Hamming ball of radius $ρ$ around it. Thus, for random errors, one can correct twice the number of errors uniquely correctable from worst-case errors for any code. A variant of our result also gives a simple algorithm to decode Reed-Solomon codes from random errors that, to the best of our knowledge, runs faster than known algorithms for certain ranges of parameters.
  (ii) We show that concatenated codes can achieve the list decoding capacity for erasures. A similar result for worst-case errors was proven by Guruswami and Rudra (SODA 08), although their result does not directly imply our result. Our results show that a subset of the random ensemble of codes considered by Guruswami and Rudra also achieve the list decoding capacity for erasures.
  Our proofs employ simple counting and probabilistic arguments.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1001.1781v1-abstract-full').style.display = 'none'; document.getElementById('1001.1781v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 11 January, 2010; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2010.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">19 pages, 0 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/cs/0511072">arXiv:cs/0511072</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/cs/0511072">pdf</a>, <a href="https://arxiv.org/ps/cs/0511072">ps</a>, <a href="https://arxiv.org/format/cs/0511072">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Information Theory">cs.IT</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Explicit Codes Achieving List Decoding Capacity: Error-correction with Optimal Redundancy
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Guruswami%2C+V">Venkatesan Guruswami</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Rudra%2C+A">Atri Rudra</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="cs/0511072v2-abstract-short" style="display: inline;">
        We present error-correcting codes that achieve the information-theoretically best possible trade-off between the rate and error-correction radius. Specifically, for every $0 &lt; R &lt; 1$ and $\eps&gt; 0$, we present an explicit construction of error-correcting codes of rate $R$ that can be list decoded in polynomial time up to a fraction $(1-R-\eps)$ of {\em worst-case} errors. At least theoretically,&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('cs/0511072v2-abstract-full').style.display = 'inline'; document.getElementById('cs/0511072v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="cs/0511072v2-abstract-full" style="display: none;">
          We present error-correcting codes that achieve the information-theoretically best possible trade-off between the rate and error-correction radius. Specifically, for every $0 &lt; R &lt; 1$ and $\eps&gt; 0$, we present an explicit construction of error-correcting codes of rate $R$ that can be list decoded in polynomial time up to a fraction $(1-R-\eps)$ of {\em worst-case} errors. At least theoretically, this meets one of the central challenges in algorithmic coding theory.
  Our codes are simple to describe: they are {\em folded Reed-Solomon codes}, which are in fact {\em exactly} Reed-Solomon (RS) codes, but viewed as a code over a larger alphabet by careful bundling of codeword symbols. Given the ubiquity of RS codes, this is an appealing feature of our result, and in fact our methods directly yield better decoding algorithms for RS codes when errors occur in {\em phased bursts}.
  The alphabet size of these folded RS codes is polynomial in the block length. We are able to reduce this to a constant (depending on $\eps$) using ideas concerning ``list recovery&#39;&#39; and expander-based codes from \cite{GI-focs01,GI-ieeejl}. Concatenating the folded RS codes with suitable inner codes also gives us polynomial time constructible binary codes that can be efficiently list decoded up to the Zyablov bound, i.e., up to twice the radius achieved by the standard GMD decoding of concatenated codes.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('cs/0511072v2-abstract-full').style.display = 'none'; document.getElementById('cs/0511072v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 October, 2007; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 18 November, 2005;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2005.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">28 pages, 6 figures</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          H.1.1
        
      </p>
    

    
  </li>

</ol>


  


      <div class="is-hidden-tablet">
        <!-- feedback for mobile only -->
        <span class="help" style="display: inline-block;"><a href="https://github.com/arXiv/arxiv-search/releases">Search v0.5.6 released 2020-02-24</a>&nbsp;&nbsp;</span>
        <button class="button is-small" id="feedback-button">Feedback?</button>
      </div>
    </div>

  </main>
  <footer>
    
    <div class="columns is-desktop" role="navigation" aria-label="Secondary">
  <!-- MetaColumn 1 -->
  <div class="column">
    <div class="columns">
      <div class="column">
        <ul class="nav-spaced">
          <li><a href="https://arxiv.org/about">About</a></li>
          <li><a href="https://arxiv.org/help">Help</a></li>
        </ul>
      </div>
      <div class="column">
        <ul class="nav-spaced">
          <li>
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
            <a href="https://arxiv.org/help/contact"> Contact</a>
          </li>
          <li>
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
            <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
          </li>
        </ul>
      </div>
    </div>
  </div> <!-- end MetaColumn 1 -->
  <!-- MetaColumn 2 -->
  <div class="column">
    <div class="columns">
      <div class="column">
        <ul class="nav-spaced">
          <li><a href="https://arxiv.org/help/license">Copyright</a></li>
          <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
        </ul>
      </div>
      <div class="column sorry-app-links">
        <ul class="nav-spaced">
          <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
          <li>
            <p class="help">
              <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
              Get status notifications via
              <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
              or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
            </p>
          </li>
        </ul>
      </div>
    </div>
  </div> <!-- end MetaColumn 2 -->
</div>
    
  </footer>
  </body>
</html>