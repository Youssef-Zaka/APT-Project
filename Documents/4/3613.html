<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<!-- new favicon config and versions by realfavicongenerator.net -->
<link rel="apple-touch-icon" sizes="180x180" href="https://static.arxiv.org/static/base/0.17.4.post2/images/icons/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://static.arxiv.org/static/base/0.17.4.post2/images/icons/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="https://static.arxiv.org/static/base/0.17.4.post2/images/icons/favicon-16x16.png">
<link rel="manifest" href="https://static.arxiv.org/static/base/0.17.4.post2/images/icons/site.webmanifest">
<link rel="mask-icon" href="https://static.arxiv.org/static/base/0.17.4.post2/images/icons/safari-pinned-tab.svg" color="#b31b1b">
<link rel="shortcut icon" href="https://static.arxiv.org/static/base/0.17.4.post2/images/icons/favicon.ico">
<meta name="msapplication-TileColor" content="#b31b1b">
<meta name="msapplication-config" content="images/icons/browserconfig.xml">
<meta name="theme-color" content="#b31b1b">
<!-- end favicon config -->
<title>Search | arXiv e-print repository</title>
<script defer src="https://static.arxiv.org/static/base/0.17.4.post2/fontawesome-free-5.11.2-web/js/all.js"></script>
<link rel="stylesheet" href="https://static.arxiv.org/static/base/0.17.4.post2/css/arxivstyle.css" />
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    messageStyle: "none",
    extensions: ["tex2jax.js"],
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
      processEscapes: true,
      ignoreClass: '.*',
      processClass: 'mathjax.*'
    },
    TeX: {
        extensions: ["AMSmath.js", "AMSsymbols.js", "noErrors.js"],
        noErrors: {
          inlineDelimiters: ["$","$"],
          multiLine: false,
          style: {
            "font-size": "normal",
            "border": ""
          }
        }
    },
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>
<script src='//static.arxiv.org/MathJax-2.7.3/MathJax.js'></script>
<script src="https://static.arxiv.org/static/base/0.17.4.post2/js/notification.js"></script>

    
  <link rel="stylesheet" href="https://static.arxiv.org/static/search/0.5.6/css/bulma-tooltip.min.css" />
  <link rel="stylesheet" href="https://static.arxiv.org/static/search/0.5.6/css/search.css" />
  <script
    src="https://code.jquery.com/jquery-3.2.1.slim.min.js"
    integrity="sha256-k2WSCIexGzOj3Euiig+TlR8gA0EmPjuc79OEeY5L45g="
    crossorigin="anonymous"></script>

  <script src="https://static.arxiv.org/static/search/0.5.6/js/fieldset.js"></script>
  <style>
  radio#cf-customfield_11400 {
    display: none;
  }
  </style>
  <script type="text/javascript" src="https://arxiv-org.atlassian.net/s/d41d8cd98f00b204e9800998ecf8427e-T/-tqqyqk/b/20/a44af77267a987a660377e5c46e0fb64/_/download/batch/com.atlassian.jira.collector.plugin.jira-issue-collector-plugin:issuecollector/com.atlassian.jira.collector.plugin.jira-issue-collector-plugin:issuecollector.js?locale=en-US&collectorId=3b3dcb4c"></script>

    <script type="text/javascript">
    window.ATL_JQ_PAGE_PROPS =  {
    	"triggerFunction": function(showCollectorDialog) {
    		//Requires that jQuery is available!
    		$("#feedback-button").click(function(e) {
    			e.preventDefault();
    			showCollectorDialog();
    		});
    	},
      fieldValues: {
        "components": ["16000"],  // Search component.
        "versions": ["14260"],  // Release search-0.5.6
        "customfield_11401": window.location.href
      }
    };
    </script>

  </head>
  <body>
  
  
  <header><a href="#main-container" class="is-sr-only">Skip to main content</a>
    
    <!-- contains Cornell logo and sponsor statement -->
<div class="attribution level is-marginless" role="banner">
  <div class="level-left">
    <a class="level-item" href="https://cornell.edu/"><img src="https://static.arxiv.org/static/base/0.17.4.post2/images/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" aria-label="logo" /></a>
  </div>
  <div class="level-right is-marginless"><p class="sponsors level-item is-marginless"><a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a></p></div>
</div>
<!-- contains arXiv identity and search bar -->
<div class="identity level is-marginless">
  <div class="level-left">
    <div class="level-item">
      <a class="arxiv" href="https://arxiv.org/" aria-label="arxiv-logo">
        <img src="https://static.arxiv.org/static/base/0.17.4.post2/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;"/>
      </a>
    </div>
  </div>
  
  <div class="search-block level-right">
    <form class="level-item mini-search" method="GET" action="https://arxiv.org/search">
      <div class="field has-addons">
        <div class="control">
          <input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" />
          <p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
        </div>
        <div class="control">
          <div class="select is-small">
            <select name="searchtype" aria-label="Field to search">
              <option value="all" selected="selected">All fields</option>
              <option value="title">Title</option>
              <option value="author">Author</option>
              <option value="abstract">Abstract</option>
              <option value="comments">Comments</option>
              <option value="journal_ref">Journal reference</option>
              <option value="acm_class">ACM classification</option>
              <option value="msc_class">MSC classification</option>
              <option value="report_num">Report number</option>
              <option value="paper_id">arXiv identifier</option>
              <option value="doi">DOI</option>
              <option value="orcid">ORCID</option>
              <option value="author_id">arXiv author ID</option>
              <option value="help">Help pages</option>
              <option value="full_text">Full text</option>
            </select>
          </div>
        </div>
        <input type="hidden" name="source" value="header">
        <button class="button is-small is-cul-darker">Search</button>
      </div>
    </form>
  </div>
</div> <!-- closes identity -->

<div class="container">
    <div class="user-tools is-size-7 has-text-right has-text-weight-bold" role="navigation" aria-label="User menu">
      <a href="https://arxiv.org/login">Login</a>
    </div>
</div>
    
  </header>
  <main class="container" id="main-container">
    


    
  <div class="level is-marginless">
    <div class="level-left">
      <h1 class="title is-clearfix">
    
        Showing 1&ndash;37 of 37 results for author: <span class="mathjax">Narang, S</span>
    
</h1>
    </div>
    <div class="level-right is-hidden-mobile">
      <!-- feedback for mobile is moved to footer -->
      <span class="help" style="display: inline-block;"><a href="https://github.com/arXiv/arxiv-search/releases">Search v0.5.6 released 2020-02-24</a>&nbsp;&nbsp;</span>
      <button class="button is-small" id="feedback-button">Feedback?</button>
    </div>
  </div>
    <div class="content">
      
  <form method="GET" action="/search/cs"  aria-role="search">
    
      Searching in archive <strong>cs</strong>. <a href="/search/?searchtype=author&amp;query=Narang%2C+S">Search in all archives.</a>
    

    
    <div class="field has-addons-tablet">
      <div class="control is-expanded">
        <label for="query" class="hidden-label">Search term or terms</label>
        
          <input class="input is-medium" id="query" name="query" placeholder="Search term..." type="text" value="Narang, S">
        
        
      </div>
      <div class="select control is-medium">
        <label class="is-hidden" for="searchtype">Field</label>
        <select class="is-medium" id="searchtype" name="searchtype"><option value="all">All fields</option><option value="title">Title</option><option selected value="author">Author(s)</option><option value="abstract">Abstract</option><option value="comments">Comments</option><option value="journal_ref">Journal reference</option><option value="acm_class">ACM classification</option><option value="msc_class">MSC classification</option><option value="report_num">Report number</option><option value="paper_id">arXiv identifier</option><option value="doi">DOI</option><option value="orcid">ORCID</option><option value="license">License (URI)</option><option value="author_id">arXiv author ID</option><option value="help">Help pages</option><option value="full_text">Full text</option></select>
      </div>
      <div class="control">
          <button class="button is-link is-medium">Search</button>
      </div>
    </div>
    <div class="field">
      <div class="control is-size-7">
        
        <label class="radio">
          <input checked id="abstracts-0" name="abstracts" type="radio" value="show"> Show abstracts
        </label>
        
        <label class="radio">
          <input id="abstracts-1" name="abstracts" type="radio" value="hide"> Hide abstracts
        </label>
        
      </div>
    </div>
    <div class="is-clearfix" style="height: 2.5em"> 
      <div class="is-pulled-right">
        
        <a href="/search/advanced?terms-0-term=Narang%2C+S&amp;terms-0-field=author&amp;size=50&amp;order=-announced_date_first">Advanced Search</a>
        
      </div>
    </div>
    <input type="hidden" name="order" value="-announced_date_first">
    <input type="hidden" name="size" value="50">
  </form>

  

  
      
<div class="level breathe-horizontal">
  <div class="level-left">
    <form method="GET" action="/search/">
      <div style="display: none;">
        
          
            <select id="searchtype" name="searchtype"><option value="all">All fields</option><option value="title">Title</option><option selected value="author">Author(s)</option><option value="abstract">Abstract</option><option value="comments">Comments</option><option value="journal_ref">Journal reference</option><option value="acm_class">ACM classification</option><option value="msc_class">MSC classification</option><option value="report_num">Report number</option><option value="paper_id">arXiv identifier</option><option value="doi">DOI</option><option value="orcid">ORCID</option><option value="license">License (URI)</option><option value="author_id">arXiv author ID</option><option value="help">Help pages</option><option value="full_text">Full text</option></select>
          
        
          
            <input id="query" name="query" type="text" value="Narang, S">
          
        
          
        
          
        
          
            <ul id="abstracts"><li><input checked id="abstracts-0" name="abstracts" type="radio" value="show"> <label for="abstracts-0">Show abstracts</label></li><li><input id="abstracts-1" name="abstracts" type="radio" value="hide"> <label for="abstracts-1">Hide abstracts</label></li></ul>
          
        
      </div>
      <div class="box field is-grouped is-grouped-multiline level-item">
        <div class="control">
          <span class="select is-small">
            <select id="size" name="size"><option value="25">25</option><option selected value="50">50</option><option value="100">100</option><option value="200">200</option></select>
          </span>
          <label for="size">results per page</label>.
        </div>
        <div class="control">
          <label for="order">Sort results by</label>
          <span class="select is-small">
            <select id="order" name="order"><option selected value="-announced_date_first">Announcement date (newest first)</option><option value="announced_date_first">Announcement date (oldest first)</option><option value="-submitted_date">Submission date (newest first)</option><option value="submitted_date">Submission date (oldest first)</option><option value="">Relevance</option></select>
          </span>
        </div>
        <div class="control">
          <button class="button is-small is-link">Go</button>
        </div>
      </div>
    </form>
  </div>
</div>
      




<ol class="breathe-horizontal" start="1"> 


  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2204.02311">arXiv:2204.02311</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2204.02311">pdf</a>, <a href="https://arxiv.org/format/2204.02311">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        PaLM: Scaling Language Modeling with Pathways
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Chowdhery%2C+A">Aakanksha Chowdhery</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Narang%2C+S">Sharan Narang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Devlin%2C+J">Jacob Devlin</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Bosma%2C+M">Maarten Bosma</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Mishra%2C+G">Gaurav Mishra</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Roberts%2C+A">Adam Roberts</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Barham%2C+P">Paul Barham</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Chung%2C+H+W">Hyung Won Chung</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Sutton%2C+C">Charles Sutton</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Gehrmann%2C+S">Sebastian Gehrmann</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Schuh%2C+P">Parker Schuh</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Shi%2C+K">Kensen Shi</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Tsvyashchenko%2C+S">Sasha Tsvyashchenko</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Maynez%2C+J">Joshua Maynez</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Rao%2C+A">Abhishek Rao</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Barnes%2C+P">Parker Barnes</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Tay%2C+Y">Yi Tay</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Shazeer%2C+N">Noam Shazeer</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Prabhakaran%2C+V">Vinodkumar Prabhakaran</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Reif%2C+E">Emily Reif</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Du%2C+N">Nan Du</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Hutchinson%2C+B">Ben Hutchinson</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Pope%2C+R">Reiner Pope</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Bradbury%2C+J">James Bradbury</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Austin%2C+J">Jacob Austin</a>
      , et al. (42 additional authors not shown)
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2204.02311v3-abstract-short" style="display: inline;">
        Large language models have been shown to achieve remarkable performance across a variety of natural language tasks using few-shot learning, which drastically reduces the number of task-specific training examples needed to adapt the model to a particular application. To further our understanding of the impact of scale on few-shot learning, we trained a 540-billion parameter, densely activated, Tran&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2204.02311v3-abstract-full').style.display = 'inline'; document.getElementById('2204.02311v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2204.02311v3-abstract-full" style="display: none;">
        Large language models have been shown to achieve remarkable performance across a variety of natural language tasks using few-shot learning, which drastically reduces the number of task-specific training examples needed to adapt the model to a particular application. To further our understanding of the impact of scale on few-shot learning, we trained a 540-billion parameter, densely activated, Transformer language model, which we call Pathways Language Model PaLM. We trained PaLM on 6144 TPU v4 chips using Pathways, a new ML system which enables highly efficient training across multiple TPU Pods. We demonstrate continued benefits of scaling by achieving state-of-the-art few-shot learning results on hundreds of language understanding and generation benchmarks. On a number of these tasks, PaLM 540B achieves breakthrough performance, outperforming the finetuned state-of-the-art on a suite of multi-step reasoning tasks, and outperforming average human performance on the recently released BIG-bench benchmark. A significant number of BIG-bench tasks showed discontinuous improvements from model scale, meaning that performance steeply increased as we scaled to our largest model. PaLM also has strong capabilities in multilingual tasks and source code generation, which we demonstrate on a wide array of benchmarks. We additionally provide a comprehensive analysis on bias and toxicity, and study the extent of training data memorization with respect to model scale. Finally, we discuss the ethical considerations related to large language models and discuss potential mitigation strategies.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2204.02311v3-abstract-full').style.display = 'none'; document.getElementById('2204.02311v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 19 April, 2022; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 5 April, 2022;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2022.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2203.17189">arXiv:2203.17189</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2203.17189">pdf</a>, <a href="https://arxiv.org/format/2203.17189">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Scaling Up Models and Data with $\texttt{t5x}$ and $\texttt{seqio}$
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Roberts%2C+A">Adam Roberts</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Chung%2C+H+W">Hyung Won Chung</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Levskaya%2C+A">Anselm Levskaya</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Mishra%2C+G">Gaurav Mishra</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Bradbury%2C+J">James Bradbury</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Andor%2C+D">Daniel Andor</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Narang%2C+S">Sharan Narang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Lester%2C+B">Brian Lester</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Gaffney%2C+C">Colin Gaffney</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Mohiuddin%2C+A">Afroz Mohiuddin</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Hawthorne%2C+C">Curtis Hawthorne</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Lewkowycz%2C+A">Aitor Lewkowycz</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Salcianu%2C+A">Alex Salcianu</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=van+Zee%2C+M">Marc van Zee</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Austin%2C+J">Jacob Austin</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Goodman%2C+S">Sebastian Goodman</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Soares%2C+L+B">Livio Baldini Soares</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Hu%2C+H">Haitang Hu</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Tsvyashchenko%2C+S">Sasha Tsvyashchenko</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Chowdhery%2C+A">Aakanksha Chowdhery</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Bastings%2C+J">Jasmijn Bastings</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Bulian%2C+J">Jannis Bulian</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Garcia%2C+X">Xavier Garcia</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Ni%2C+J">Jianmo Ni</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Chen%2C+A">Andrew Chen</a>
      , et al. (18 additional authors not shown)
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2203.17189v1-abstract-short" style="display: inline;">
        Recent neural network-based language models have benefited greatly from scaling up the size of training datasets and the number of parameters in the models themselves. Scaling can be complicated due to various factors including the need to distribute computation on supercomputer clusters (e.g., TPUs), prevent bottlenecks when infeeding data, and ensure reproducible results. In this work, we presen&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2203.17189v1-abstract-full').style.display = 'inline'; document.getElementById('2203.17189v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2203.17189v1-abstract-full" style="display: none;">
        Recent neural network-based language models have benefited greatly from scaling up the size of training datasets and the number of parameters in the models themselves. Scaling can be complicated due to various factors including the need to distribute computation on supercomputer clusters (e.g., TPUs), prevent bottlenecks when infeeding data, and ensure reproducible results. In this work, we present two software libraries that ease these issues: $\texttt{t5x}$ simplifies the process of building and training large language models at scale while maintaining ease of use, and $\texttt{seqio}$ provides a task-based API for simple creation of fast and reproducible training data and evaluation pipelines. These open-source libraries have been used to train models with hundreds of billions of parameters on datasets with multiple terabytes of training data.
  Along with the libraries, we release configurations and instructions for T5-like encoder-decoder models as well as GPT-like decoder-only architectures.
  $\texttt{t5x}$ and $\texttt{seqio}$ are open source and available at https://github.com/google-research/t5x and https://github.com/google/seqio, respectively.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2203.17189v1-abstract-full').style.display = 'none'; document.getElementById('2203.17189v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 31 March, 2022; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2022.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2203.11171">arXiv:2203.11171</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2203.11171">pdf</a>, <a href="https://arxiv.org/format/2203.11171">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Self-Consistency Improves Chain of Thought Reasoning in Language Models
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Wang%2C+X">Xuezhi Wang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Wei%2C+J">Jason Wei</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Schuurmans%2C+D">Dale Schuurmans</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Le%2C+Q">Quoc Le</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Chi%2C+E">Ed Chi</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Narang%2C+S">Sharan Narang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Chowdhery%2C+A">Aakanksha Chowdhery</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+D">Denny Zhou</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2203.11171v2-abstract-short" style="display: inline;">
        We explore a simple ensemble strategy, self-consistency, that significantly improves the reasoning accuracy of large language models. The idea is to sample a diverse set of reasoning paths from a language model via chain of thought prompting then return the most consistent final answer in the set. We evaluate self-consistency on a range of arithmetic and commonsense reasoning benchmarks, and find&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2203.11171v2-abstract-full').style.display = 'inline'; document.getElementById('2203.11171v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2203.11171v2-abstract-full" style="display: none;">
        We explore a simple ensemble strategy, self-consistency, that significantly improves the reasoning accuracy of large language models. The idea is to sample a diverse set of reasoning paths from a language model via chain of thought prompting then return the most consistent final answer in the set. We evaluate self-consistency on a range of arithmetic and commonsense reasoning benchmarks, and find that it robustly improves accuracy across a variety of language models and model scales without the need for additional training or auxiliary models. When combined with a recent large language model, PaLM-540B, self-consistency increases performance to state-of-the-art levels across several benchmark reasoning tasks, including GSM8K (56.5% -&gt; 74.4%), SVAMP (79.0% -&gt; 86.6%), AQuA (35.8% -&gt; 48.3%), StrategyQA (75.3% -&gt; 81.6%) and ARC-challenge (85.2% -&gt; 88.7%).
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2203.11171v2-abstract-full').style.display = 'none'; document.getElementById('2203.11171v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 6 April, 2022; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 21 March, 2022;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2022.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">V2: added PaLM based results</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2110.00767">arXiv:2110.00767</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2110.00767">pdf</a>, <a href="https://arxiv.org/format/2110.00767">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Science and Game Theory">cs.GT</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Sublinear Approximation Algorithm for Nash Social Welfare with XOS Valuations
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Barman%2C+S">Siddharth Barman</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Krishna%2C+A">Anand Krishna</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Kulkarni%2C+P">Pooja Kulkarni</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Narang%2C+S">Shivika Narang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2110.00767v1-abstract-short" style="display: inline;">
        We study the problem of allocating indivisible goods among $n$ agents with the objective of maximizing Nash social welfare (NSW). This welfare function is defined as the geometric mean of the agents&#39; valuations and, hence, it strikes a balance between the extremes of social welfare (arithmetic mean) and egalitarian welfare (max-min value). Nash social welfare has been extensively studied in recent&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2110.00767v1-abstract-full').style.display = 'inline'; document.getElementById('2110.00767v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2110.00767v1-abstract-full" style="display: none;">
        We study the problem of allocating indivisible goods among $n$ agents with the objective of maximizing Nash social welfare (NSW). This welfare function is defined as the geometric mean of the agents&#39; valuations and, hence, it strikes a balance between the extremes of social welfare (arithmetic mean) and egalitarian welfare (max-min value). Nash social welfare has been extensively studied in recent years for various valuation classes. In particular, a notable negative result is known when the agents&#39; valuations are complement-free and are specified via value queries: for XOS valuations, one necessarily requires exponentially many value queries to find any sublinear (in $n$) approximation for NSW. Indeed, this lower bound implies that stronger query models are needed for finding better approximations. Towards this, we utilize demand oracles and XOS oracles; both of these query models are standard and have been used in prior work on social welfare maximization with XOS valuations.
  We develop the first sublinear approximation algorithm for maximizing Nash social welfare under XOS valuations, specified via demand and XOS oracles. Hence, this work breaks the $O(n)$-approximation barrier for NSW maximization under XOS valuations. We obtain this result by developing a novel connection between NSW and social welfare under a capped version of the agents&#39; valuations. In addition to this insight, which might be of independent interest, this work relies on an intricate combination of multiple technical ideas, including the use of repeated matchings and the discrete moving knife method.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2110.00767v1-abstract-full').style.display = 'none'; document.getElementById('2110.00767v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 2 October, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">31 pages</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2109.10686">arXiv:2109.10686</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2109.10686">pdf</a>, <a href="https://arxiv.org/format/2109.10686">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Scale Efficiently: Insights from Pre-training and Fine-tuning Transformers
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Tay%2C+Y">Yi Tay</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Dehghani%2C+M">Mostafa Dehghani</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Rao%2C+J">Jinfeng Rao</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Fedus%2C+W">William Fedus</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Abnar%2C+S">Samira Abnar</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Chung%2C+H+W">Hyung Won Chung</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Narang%2C+S">Sharan Narang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Yogatama%2C+D">Dani Yogatama</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Vaswani%2C+A">Ashish Vaswani</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Metzler%2C+D">Donald Metzler</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2109.10686v2-abstract-short" style="display: inline;">
        There remain many open questions pertaining to the scaling behaviour of Transformer architectures. These scaling decisions and findings can be critical, as training runs often come with an associated computational cost which have both financial and/or environmental impact. The goal of this paper is to present scaling insights from pretraining and finetuning Transformers. While Kaplan et al. presen&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2109.10686v2-abstract-full').style.display = 'inline'; document.getElementById('2109.10686v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2109.10686v2-abstract-full" style="display: none;">
        There remain many open questions pertaining to the scaling behaviour of Transformer architectures. These scaling decisions and findings can be critical, as training runs often come with an associated computational cost which have both financial and/or environmental impact. The goal of this paper is to present scaling insights from pretraining and finetuning Transformers. While Kaplan et al. presents a comprehensive study of the scaling behaviour of Transformer language models, the scope is only on the upstream (pretraining) loss. Therefore, it is still unclear if these set of findings transfer to downstream task within the context of the pretrain-finetune paradigm. The key findings of this paper are as follows: (1) we show that aside from only the model size, model shape matters for downstream fine-tuning, (2) scaling protocols operate differently at different compute regions, (3) widely adopted T5-base and T5-large sizes are Pareto-inefficient. To this end, we present improved scaling protocols whereby our redesigned models achieve similar downstream fine-tuning quality while having 50\% fewer parameters and training 40\% faster compared to the widely adopted T5-base model. We publicly release over 100 pretrained checkpoints of different T5 configurations to facilitate future research and analysis.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2109.10686v2-abstract-full').style.display = 'none'; document.getElementById('2109.10686v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 30 January, 2022; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 22 September, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">ICLR 2022 + Updated Checkpoint Release</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2108.08990">arXiv:2108.08990</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2108.08990">pdf</a>, <a href="https://arxiv.org/format/2108.08990">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Few Shot Activity Recognition Using Variational Inference
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Kumar%2C+N">Neeraj Kumar</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Narang%2C+S">Siddhansh Narang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2108.08990v1-abstract-short" style="display: inline;">
        There has been a remarkable progress in learning a model which could recognise novel classes with only a few labeled examples in the last few years. Few-shot learning (FSL) for action recognition is a challenging task of recognising novel action categories which are represented by few instances in the training data. We propose a novel variational inference based architectural framework (HF-AR) for&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2108.08990v1-abstract-full').style.display = 'inline'; document.getElementById('2108.08990v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2108.08990v1-abstract-full" style="display: none;">
        There has been a remarkable progress in learning a model which could recognise novel classes with only a few labeled examples in the last few years. Few-shot learning (FSL) for action recognition is a challenging task of recognising novel action categories which are represented by few instances in the training data. We propose a novel variational inference based architectural framework (HF-AR) for few shot activity recognition. Our framework leverages volume-preserving Householder Flow to learn a flexible posterior distribution of the novel classes. This results in better performance as compared to state-of-the-art few shot approaches for human activity recognition. approach consists of base model and an adapter model. Our architecture consists of a base model and an adapter model. The base model is trained on seen classes and it computes an embedding that represent the spatial and temporal insights extracted from the input video, e.g. combination of Resnet-152 and LSTM based encoder-decoder model. The adapter model applies a series of Householder transformations to compute a flexible posterior distribution that lends higher accuracy in the few shot approach. Extensive experiments on three well-known datasets: UCF101, HMDB51 and Something-Something-V2, demonstrate similar or better performance on 1-shot and 5-shot classification as compared to state-of-the-art few shot approaches that use only RGB frame sequence as input. To the best of our knowledge, we are the first to explore variational inference along with householder transformations to capture the full rank covariance matrix of posterior distribution, for few shot learning in activity recognition.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2108.08990v1-abstract-full').style.display = 'none'; document.getElementById('2108.08990v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 19 August, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted in IJCAI 2021 - 3RD INTERNATIONAL WORKSHOP ON DEEP LEARNING FOR HUMAN ACTIVITY RECOGNITION. arXiv admin note: text overlap with arXiv:1611.09630, arXiv:1909.07945 by other authors</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2105.13626">arXiv:2105.13626</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2105.13626">pdf</a>, <a href="https://arxiv.org/format/2105.13626">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        ByT5: Towards a token-free future with pre-trained byte-to-byte models
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Xue%2C+L">Linting Xue</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Barua%2C+A">Aditya Barua</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Constant%2C+N">Noah Constant</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Al-Rfou%2C+R">Rami Al-Rfou</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Narang%2C+S">Sharan Narang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Kale%2C+M">Mihir Kale</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Roberts%2C+A">Adam Roberts</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Raffel%2C+C">Colin Raffel</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2105.13626v3-abstract-short" style="display: inline;">
        Most widely-used pre-trained language models operate on sequences of tokens corresponding to word or subword units. By comparison, token-free models that operate directly on raw text (bytes or characters) have many benefits: they can process text in any language out of the box, they are more robust to noise, and they minimize technical debt by removing complex and error-prone text preprocessing pi&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.13626v3-abstract-full').style.display = 'inline'; document.getElementById('2105.13626v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2105.13626v3-abstract-full" style="display: none;">
        Most widely-used pre-trained language models operate on sequences of tokens corresponding to word or subword units. By comparison, token-free models that operate directly on raw text (bytes or characters) have many benefits: they can process text in any language out of the box, they are more robust to noise, and they minimize technical debt by removing complex and error-prone text preprocessing pipelines. Since byte or character sequences are longer than token sequences, past work on token-free models has often introduced new model architectures designed to amortize the cost of operating directly on raw text. In this paper, we show that a standard Transformer architecture can be used with minimal modifications to process byte sequences. We characterize the trade-offs in terms of parameter count, training FLOPs, and inference speed, and show that byte-level models are competitive with their token-level counterparts. We also demonstrate that byte-level models are significantly more robust to noise and perform better on tasks that are sensitive to spelling and pronunciation. As part of our contribution, we release a new set of pre-trained byte-level Transformer models based on the T5 architecture, as well as all code and data used in our experiments.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.13626v3-abstract-full').style.display = 'none'; document.getElementById('2105.13626v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 March, 2022; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 28 May, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">To be published in TACL 2022</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2104.04631">arXiv:2104.04631</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2104.04631">pdf</a>, <a href="https://arxiv.org/format/2104.04631">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        DexYCB: A Benchmark for Capturing Hand Grasping of Objects
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Chao%2C+Y">Yu-Wei Chao</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Yang%2C+W">Wei Yang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Xiang%2C+Y">Yu Xiang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Molchanov%2C+P">Pavlo Molchanov</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Handa%2C+A">Ankur Handa</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Tremblay%2C+J">Jonathan Tremblay</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Narang%2C+Y+S">Yashraj S. Narang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Van+Wyk%2C+K">Karl Van Wyk</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Iqbal%2C+U">Umar Iqbal</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Birchfield%2C+S">Stan Birchfield</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Kautz%2C+J">Jan Kautz</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Fox%2C+D">Dieter Fox</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2104.04631v1-abstract-short" style="display: inline;">
        We introduce DexYCB, a new dataset for capturing hand grasping of objects. We first compare DexYCB with a related one through cross-dataset evaluation. We then present a thorough benchmark of state-of-the-art approaches on three relevant tasks: 2D object and keypoint detection, 6D object pose estimation, and 3D hand pose estimation. Finally, we evaluate a new robotics-relevant task: generating saf&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.04631v1-abstract-full').style.display = 'inline'; document.getElementById('2104.04631v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2104.04631v1-abstract-full" style="display: none;">
        We introduce DexYCB, a new dataset for capturing hand grasping of objects. We first compare DexYCB with a related one through cross-dataset evaluation. We then present a thorough benchmark of state-of-the-art approaches on three relevant tasks: 2D object and keypoint detection, 6D object pose estimation, and 3D hand pose estimation. Finally, we evaluate a new robotics-relevant task: generating safe robot grasps in human-to-robot object handover. Dataset and code are available at https://dex-ycb.github.io.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.04631v1-abstract-full').style.display = 'none'; document.getElementById('2104.04631v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 9 April, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted to CVPR 2021</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.16388">arXiv:2103.16388</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.16388">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Statistical Finance">q-fin.ST</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.3390/asi4010013">10.3390/asi4010013 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Text Mining of Stocktwits Data for Predicting Stock Prices
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Jaggi%2C+M">Mukul Jaggi</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Mandal%2C+P">Priyanka Mandal</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Narang%2C+S">Shreya Narang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Naseem%2C+U">Usman Naseem</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Khushi%2C+M">Matloob Khushi</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.16388v1-abstract-short" style="display: inline;">
        Stock price prediction can be made more efficient by considering the price fluctuations and understanding the sentiments of people. A limited number of models understand financial jargon or have labelled datasets concerning stock price change. To overcome this challenge, we introduced FinALBERT, an ALBERT based model trained to handle financial domain text classification tasks by labelling Stocktw&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.16388v1-abstract-full').style.display = 'inline'; document.getElementById('2103.16388v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.16388v1-abstract-full" style="display: none;">
        Stock price prediction can be made more efficient by considering the price fluctuations and understanding the sentiments of people. A limited number of models understand financial jargon or have labelled datasets concerning stock price change. To overcome this challenge, we introduced FinALBERT, an ALBERT based model trained to handle financial domain text classification tasks by labelling Stocktwits text data based on stock price change. We collected Stocktwits data for over ten years for 25 different companies, including the major five FAANG (Facebook, Amazon, Apple, Netflix, Google). These datasets were labelled with three labelling techniques based on stock price changes. Our proposed model FinALBERT is fine-tuned with these labels to achieve optimal results. We experimented with the labelled dataset by training it on traditional machine learning, BERT, and FinBERT models, which helped us understand how these labels behaved with different model architectures. Our labelling method competitive advantage is that it can help analyse the historical data effectively, and the mathematical function can be easily customised to predict stock movement.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.16388v1-abstract-full').style.display = 'none'; document.getElementById('2103.16388v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 12 March, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        Appl. Syst. Innov. 2021, 4, 13
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2102.11972">arXiv:2102.11972</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2102.11972">pdf</a>, <a href="https://arxiv.org/format/2102.11972">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Do Transformer Modifications Transfer Across Implementations and Applications?
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Narang%2C+S">Sharan Narang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Chung%2C+H+W">Hyung Won Chung</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Tay%2C+Y">Yi Tay</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Fedus%2C+W">William Fedus</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Fevry%2C+T">Thibault Fevry</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Matena%2C+M">Michael Matena</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Malkan%2C+K">Karishma Malkan</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Fiedel%2C+N">Noah Fiedel</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Shazeer%2C+N">Noam Shazeer</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Lan%2C+Z">Zhenzhong Lan</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+Y">Yanqi Zhou</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Li%2C+W">Wei Li</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Ding%2C+N">Nan Ding</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Marcus%2C+J">Jake Marcus</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Roberts%2C+A">Adam Roberts</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Raffel%2C+C">Colin Raffel</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2102.11972v2-abstract-short" style="display: inline;">
        The research community has proposed copious modifications to the Transformer architecture since it was introduced over three years ago, relatively few of which have seen widespread adoption. In this paper, we comprehensively evaluate many of these modifications in a shared experimental setting that covers most of the common uses of the Transformer in natural language processing. Surprisingly, we f&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.11972v2-abstract-full').style.display = 'inline'; document.getElementById('2102.11972v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2102.11972v2-abstract-full" style="display: none;">
        The research community has proposed copious modifications to the Transformer architecture since it was introduced over three years ago, relatively few of which have seen widespread adoption. In this paper, we comprehensively evaluate many of these modifications in a shared experimental setting that covers most of the common uses of the Transformer in natural language processing. Surprisingly, we find that most modifications do not meaningfully improve performance. Furthermore, most of the Transformer variants we found beneficial were either developed in the same codebase that we used or are relatively minor changes. We conjecture that performance improvements may strongly depend on implementation details and correspondingly make some recommendations for improving the generality of experimental results.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.11972v2-abstract-full').style.display = 'none'; document.getElementById('2102.11972v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 10 September, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 23 February, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">To appear at EMNLP 2021 as a conference paper</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2101.05452">arXiv:2101.05452</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2101.05452">pdf</a>, <a href="https://arxiv.org/format/2101.05452">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Interpreting and Predicting Tactile Signals for the SynTouch BioTac
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Narang%2C+Y+S">Yashraj S. Narang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Sundaralingam%2C+B">Balakumar Sundaralingam</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Van+Wyk%2C+K">Karl Van Wyk</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Mousavian%2C+A">Arsalan Mousavian</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Fox%2C+D">Dieter Fox</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2101.05452v1-abstract-short" style="display: inline;">
        In the human hand, high-density contact information provided by afferent neurons is essential for many human grasping and manipulation capabilities. In contrast, robotic tactile sensors, including the state-of-the-art SynTouch BioTac, are typically used to provide low-density contact information, such as contact location, center of pressure, and net force. Although useful, these data do not convey&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.05452v1-abstract-full').style.display = 'inline'; document.getElementById('2101.05452v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2101.05452v1-abstract-full" style="display: none;">
        In the human hand, high-density contact information provided by afferent neurons is essential for many human grasping and manipulation capabilities. In contrast, robotic tactile sensors, including the state-of-the-art SynTouch BioTac, are typically used to provide low-density contact information, such as contact location, center of pressure, and net force. Although useful, these data do not convey or leverage the rich information content that some tactile sensors naturally measure. This research extends robotic tactile sensing beyond reduced-order models through 1) the automated creation of a precise experimental tactile dataset for the BioTac over a diverse range of physical interactions, 2) a 3D finite element (FE) model of the BioTac, which complements the experimental dataset with high-density, distributed contact data, 3) neural-network-based mappings from raw BioTac signals to not only low-dimensional experimental data, but also high-density FE deformation fields, and 4) mappings from the FE deformation fields to the raw signals themselves. The high-density data streams can provide a far greater quantity of interpretable information for grasping and manipulation algorithms than previously accessible.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.05452v1-abstract-full').style.display = 'none'; document.getElementById('2101.05452v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 13 January, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Submitted to International Journal of Robotics Research (IJRR)</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2011.06822">arXiv:2011.06822</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2011.06822">pdf</a>, <a href="https://arxiv.org/format/2011.06822">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Graphics">cs.GR</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
          
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1109/WACV48630.2021.00366">10.1109/WACV48630.2021.00366 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        SHAD3S: A model to Sketch, Shade and Shadow
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Venkataramaiyer%2C+R+B">Raghav B. Venkataramaiyer</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Joshi%2C+A">Abhishek Joshi</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Narang%2C+S">Saisha Narang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Namboodiri%2C+V+P">Vinay P. Namboodiri</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2011.06822v3-abstract-short" style="display: inline;">
        Hatching is a common method used by artists to accentuate the third dimension of a sketch, and to illuminate the scene. Our system SHAD3S attempts to compete with a human at hatching generic three-dimensional (3D) shapes, and also tries to assist her in a form exploration exercise. The novelty of our approach lies in the fact that we make no assumptions about the input other than that it represent&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2011.06822v3-abstract-full').style.display = 'inline'; document.getElementById('2011.06822v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2011.06822v3-abstract-full" style="display: none;">
        Hatching is a common method used by artists to accentuate the third dimension of a sketch, and to illuminate the scene. Our system SHAD3S attempts to compete with a human at hatching generic three-dimensional (3D) shapes, and also tries to assist her in a form exploration exercise. The novelty of our approach lies in the fact that we make no assumptions about the input other than that it represents a 3D shape, and yet, given a contextual information of illumination and texture, we synthesise an accurate hatch pattern over the sketch, without access to 3D or pseudo 3D. In the process, we contribute towards a) a cheap yet effective method to synthesise a sufficiently large high fidelity dataset, pertinent to task; b) creating a pipeline with conditional generative adversarial network (CGAN); and c) creating an interactive utility with GIMP, that is a tool for artists to engage with automated hatching or a form-exploration exercise. User evaluation of the tool suggests that the model performance does generalise satisfactorily over diverse input, both in terms of style as well as shape. A simple comparison of inception scores suggest that the generated distribution is as diverse as the ground truth.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2011.06822v3-abstract-full').style.display = 'none'; document.getElementById('2011.06822v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 4 September, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 13 November, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">10 pages, 11 figures, 2 tables Accepted to WACV 2021. Project Page: https://bvraghav.com/shad3s/</span>
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        2021 IEEE Winter Conference on Applications of Computer Vision (WACV), 2021, pp. 3615-3624
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2010.04826">arXiv:2010.04826</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2010.04826">pdf</a>, <a href="https://arxiv.org/format/2010.04826">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        On Task-Level Dialogue Composition of Generative Transformer Model
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Parthasarathi%2C+P">Prasanna Parthasarathi</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Neelakantan%2C+A">Arvind Neelakantan</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Narang%2C+S">Sharan Narang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2010.04826v1-abstract-short" style="display: inline;">
        Task-oriented dialogue systems help users accomplish tasks such as booking a movie ticket and ordering food via conversation. Generative models parameterized by a deep neural network are widely used for next turn response generation in such systems. It is natural for users of the system to want to accomplish multiple tasks within the same conversation, but the ability of generative models to compo&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2010.04826v1-abstract-full').style.display = 'inline'; document.getElementById('2010.04826v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2010.04826v1-abstract-full" style="display: none;">
        Task-oriented dialogue systems help users accomplish tasks such as booking a movie ticket and ordering food via conversation. Generative models parameterized by a deep neural network are widely used for next turn response generation in such systems. It is natural for users of the system to want to accomplish multiple tasks within the same conversation, but the ability of generative models to compose multiple tasks is not well studied. In this work, we begin by studying the effect of training human-human task-oriented dialogues towards improving the ability to compose multiple tasks on Transformer generative models. To that end, we propose and explore two solutions: (1) creating synthetic multiple task dialogue data for training from human-human single task dialogue and (2) forcing the encoder representation to be invariant to single and multiple task dialogues using an auxiliary loss. The results from our experiments highlight the difficulty of even the sophisticated variant of transformer model in learning to compose multiple tasks from single task dialogues.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2010.04826v1-abstract-full').style.display = 'none'; document.getElementById('2010.04826v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 9 October, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">8 pages; Accepted at Workshop on Insights from Negative Results in NLP</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2009.05823">arXiv:2009.05823</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2009.05823">pdf</a>, <a href="https://arxiv.org/ps/2009.05823">ps</a>, <a href="https://arxiv.org/format/2009.05823">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Science and Game Theory">cs.GT</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Data Structures and Algorithms">cs.DS</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        On Achieving Fairness and Stability in Many-to-One Matchings
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Narang%2C+S">Shivika Narang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Biswas%2C+A">Arpita Biswas</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Narahari%2C+Y">Y Narahari</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2009.05823v3-abstract-short" style="display: inline;">
        The past few years have seen a surge of work on fairness in social choice literature. This paper initiates the study of finding a stable many-to-one matching, under cardinal valuations, while satisfying fairness among the agents on either side. Specifically, motivated by several real-world settings, we focus on leximin optimal fairness and seek leximin optimality over many-to-one stable matchings.&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2009.05823v3-abstract-full').style.display = 'inline'; document.getElementById('2009.05823v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2009.05823v3-abstract-full" style="display: none;">
        The past few years have seen a surge of work on fairness in social choice literature. This paper initiates the study of finding a stable many-to-one matching, under cardinal valuations, while satisfying fairness among the agents on either side. Specifically, motivated by several real-world settings, we focus on leximin optimal fairness and seek leximin optimality over many-to-one stable matchings. We first consider the special case of ranked valuations where all agents on each side have the same preference orders or rankings over the agents on the other side (but not necessarily the same valuations). For this special case, we provide a complete characterisation of the space of stable matchings. This leads to FaSt, a novel and efficient algorithm to compute a leximin optimal stable matching under ranked isometric valuations (where, for each pair of agents, the valuation of one agent for the other is the same). The running time of FaSt is linear in the number of edges. Building upon FaSt, we present an efficient algorithm, FaSt-Gen, that finds the leximin optimal stable matching for ranked but otherwise unconstrained valuations. The running time of FaSt-Gen is quadratic in the number of edges. We next establish that, in the absence of rankings, finding a leximin optimal stable matching is NP-Hard, even under isometric valuations. In fact, when additivity and non-negativity are the only assumptions on the valuations, we show that, unless P=NP, no efficient polynomial factor approximation is possible. When additivity is relaxed to submodularity, we find that not even an exponential approximation is possible.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2009.05823v3-abstract-full').style.display = 'none'; document.getElementById('2009.05823v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 July, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 12 September, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2006.03777">arXiv:2006.03777</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2006.03777">pdf</a>, <a href="https://arxiv.org/format/2006.03777">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Interpreting and Predicting Tactile Signals via a Physics-Based and Data-Driven Framework
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Narang%2C+Y+S">Yashraj S. Narang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Van+Wyk%2C+K">Karl Van Wyk</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Mousavian%2C+A">Arsalan Mousavian</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Fox%2C+D">Dieter Fox</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2006.03777v1-abstract-short" style="display: inline;">
        High-density afferents in the human hand have long been regarded as essential for human grasping and manipulation abilities. In contrast, robotic tactile sensors are typically used to provide low-density contact data, such as center-of-pressure and resultant force. Although useful, this data does not exploit the rich information content that some tactile sensors (e.g., the SynTouch BioTac) natural&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2006.03777v1-abstract-full').style.display = 'inline'; document.getElementById('2006.03777v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2006.03777v1-abstract-full" style="display: none;">
        High-density afferents in the human hand have long been regarded as essential for human grasping and manipulation abilities. In contrast, robotic tactile sensors are typically used to provide low-density contact data, such as center-of-pressure and resultant force. Although useful, this data does not exploit the rich information content that some tactile sensors (e.g., the SynTouch BioTac) naturally provide. This research extends robotic tactile sensing beyond reduced-order models through 1) the automated creation of a precise tactile dataset for the BioTac over diverse physical interactions, 2) a 3D finite element (FE) model of the BioTac, which complements the experimental dataset with high-resolution, distributed contact data, and 3) neural-network-based mappings from raw BioTac signals to low-dimensional experimental data, and more importantly, high-density FE deformation fields. These data streams can provide a far greater quantity of interpretable information for grasping and manipulation algorithms than previously accessible.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2006.03777v1-abstract-full').style.display = 'none'; document.getElementById('2006.03777v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 6 June, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">To be published in Proc. Robotics: Science and Systems (RSS)</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2004.14546">arXiv:2004.14546</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2004.14546">pdf</a>, <a href="https://arxiv.org/format/2004.14546">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        WT5?! Training Text-to-Text Models to Explain their Predictions
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Narang%2C+S">Sharan Narang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Raffel%2C+C">Colin Raffel</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Lee%2C+K">Katherine Lee</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Roberts%2C+A">Adam Roberts</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Fiedel%2C+N">Noah Fiedel</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Malkan%2C+K">Karishma Malkan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2004.14546v1-abstract-short" style="display: inline;">
        Neural networks have recently achieved human-level performance on various challenging natural language processing (NLP) tasks, but it is notoriously difficult to understand why a neural network produced a particular prediction. In this paper, we leverage the text-to-text framework proposed by Raffel et al.(2019) to train language models to output a natural text explanation alongside their predicti&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2004.14546v1-abstract-full').style.display = 'inline'; document.getElementById('2004.14546v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2004.14546v1-abstract-full" style="display: none;">
        Neural networks have recently achieved human-level performance on various challenging natural language processing (NLP) tasks, but it is notoriously difficult to understand why a neural network produced a particular prediction. In this paper, we leverage the text-to-text framework proposed by Raffel et al.(2019) to train language models to output a natural text explanation alongside their prediction. Crucially, this requires no modifications to the loss function or training and decoding procedures -- we simply train the model to output the explanation after generating the (natural text) prediction. We show that this approach not only obtains state-of-the-art results on explainability benchmarks, but also permits learning from a limited set of labeled explanations and transferring rationalization abilities across datasets. To facilitate reproducibility and future work, we release our code use to train the models.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2004.14546v1-abstract-full').style.display = 'none'; document.getElementById('2004.14546v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 29 April, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2002.03246">arXiv:2002.03246</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2002.03246">pdf</a>, <a href="https://arxiv.org/format/2002.03246">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Multiagent Systems">cs.MA</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        SPA: Verbal Interactions between Agents and Avatars in Shared Virtual Environments using Propositional Planning
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Best%2C+A">Andrew Best</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Narang%2C+S">Sahil Narang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Manocha%2C+D">Dinesh Manocha</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2002.03246v1-abstract-short" style="display: inline;">
        We present a novel approach for generating plausible verbal interactions between virtual human-like agents and user avatars in shared virtual environments. Sense-Plan-Ask, or SPA, extends prior work in propositional planning and natural language processing to enable agents to plan with uncertain information, and leverage question and answer dialogue with other agents and avatars to obtain the need&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2002.03246v1-abstract-full').style.display = 'inline'; document.getElementById('2002.03246v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2002.03246v1-abstract-full" style="display: none;">
        We present a novel approach for generating plausible verbal interactions between virtual human-like agents and user avatars in shared virtual environments. Sense-Plan-Ask, or SPA, extends prior work in propositional planning and natural language processing to enable agents to plan with uncertain information, and leverage question and answer dialogue with other agents and avatars to obtain the needed information and complete their goals. The agents are additionally able to respond to questions from the avatars and other agents using natural-language enabling real-time multi-agent multi-avatar communication environments.
  Our algorithm can simulate tens of virtual agents at interactive rates interacting, moving, communicating, planning, and replanning. We find that our algorithm creates a small runtime cost and enables agents to complete their goals more effectively than agents without the ability to leverage natural-language communication. We demonstrate quantitative results on a set of simulated benchmarks and detail the results of a preliminary user-study conducted to evaluate the plausibility of the virtual interactions generated by SPA. Overall, we find that participants prefer SPA to prior techniques in 84\% of responses including significant benefits in terms of the plausibility of natural-language interactions and the positive impact of those interactions.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2002.03246v1-abstract-full').style.display = 'none'; document.getElementById('2002.03246v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 February, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2001.05655">arXiv:2001.05655</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2001.05655">pdf</a>, <a href="https://arxiv.org/format/2001.05655">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Science and Game Theory">cs.GT</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Design of Trusted Market Platforms using Permissioned Blockchains and Game Theory
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Narang%2C+S">Shivika Narang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2001.05655v1-abstract-short" style="display: inline;">
        The blockchain concept forms the backbone of a new wave technology that promises to be deployed extensively in a wide variety of industrial and societal applications. Governments, financial institutions, banks, industrial supply chains, service companies, and even educational institutions and hospitals are investing in a substantial manner in the hope of improving business efficiency and operation&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2001.05655v1-abstract-full').style.display = 'inline'; document.getElementById('2001.05655v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2001.05655v1-abstract-full" style="display: none;">
        The blockchain concept forms the backbone of a new wave technology that promises to be deployed extensively in a wide variety of industrial and societal applications. Governments, financial institutions, banks, industrial supply chains, service companies, and even educational institutions and hospitals are investing in a substantial manner in the hope of improving business efficiency and operational robustness through deployment of blockchain technology. This thesis work is concerned with designing trustworthy business-to-business (B2B) market platforms drawing upon blockchain technology and game theory.
  The proposed platform is built upon three key ideas. First, we use permissioned blockchains with smart contracts as a technically sound approach for building the B2B platform. The blockchain deploys smart contracts that govern the interactions of enterprise buyers and sellers. Second, the smart contracts are designed using a rigorous analysis of a repeated game model of the strategic interactions between buyers and sellers. We show that such smart contracts induce honest behavior from buyers and sellers. Third, we embed cryptographic regulation protocols into the permissioned blockchain to ensure that business sensitive information is not revealed to the competitors. We believe our work is an important step in the direction of building a powerful B2B platform that maximizes social welfare and enables trusted collaboration between strategic enterprise agents.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2001.05655v1-abstract-full').style.display = 'none'; document.getElementById('2001.05655v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 16 January, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Thesis</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2001.05652">arXiv:2001.05652</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2001.05652">pdf</a>, <a href="https://arxiv.org/format/2001.05652">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Science and Game Theory">cs.GT</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        On the Coexistence of Stability and Incentive Compatibility in Fractional Matchings
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Narang%2C+S">Shivika Narang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Narahari%2C+Y">Y Narahari</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2001.05652v2-abstract-short" style="display: inline;">
        Stable matchings have been studied extensively in social choice literature. The focus has been mostly on integral matchings, in which the nodes on the two sides are wholly matched. A fractional matching, which is a convex combination of integral matchings, is a natural extension of integral matchings. The topic of stability of fractional matchings has started receiving attention only very recently&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2001.05652v2-abstract-full').style.display = 'inline'; document.getElementById('2001.05652v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2001.05652v2-abstract-full" style="display: none;">
        Stable matchings have been studied extensively in social choice literature. The focus has been mostly on integral matchings, in which the nodes on the two sides are wholly matched. A fractional matching, which is a convex combination of integral matchings, is a natural extension of integral matchings. The topic of stability of fractional matchings has started receiving attention only very recently. Further, incentive compatibility in the context of fractional matchings has received very little attention. With this as the backdrop, our paper studies the important topic of incentive compatibility of mechanisms to find stable fractional matchings. We work with preferences expressed in the form of cardinal utilities. Our first result is an impossibility result that there are matching instances for which no mechanism that produces a stable fractional matching can be incentive compatible or even approximately incentive compatible. This provides the motivation to seek special classes of matching instances for which there exist incentive compatible mechanisms that produce stable fractional matchings. Our study leads to a class of matching instances that admit unique stable fractional matchings. We first show that a unique stable fractional matching for a matching instance exists if and only if the given matching instance satisfies the conditional mutual first preference (CMFP) property. To this end, we provide a polynomial-time algorithm that makes ingenious use of envy-graphs to find a non-integral stable matching whenever the preferences are strict and the given instance is not a CMFP matching instance. For this class of CMFP matching instances, we prove that every mechanism that produces the unique stable fractional matching is (a) incentive compatible and further (b) resistant to coalitional manipulations.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2001.05652v2-abstract-full').style.display = 'none'; document.getElementById('2001.05652v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 19 April, 2022; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 16 January, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1910.14613">arXiv:1910.14613</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1910.14613">pdf</a>, <a href="https://arxiv.org/format/1910.14613">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Neural Assistant: Joint Action Prediction, Response Generation, and Latent Knowledge Reasoning
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Neelakantan%2C+A">Arvind Neelakantan</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Yavuz%2C+S">Semih Yavuz</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Narang%2C+S">Sharan Narang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Prasad%2C+V">Vishaal Prasad</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Goodrich%2C+B">Ben Goodrich</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Duckworth%2C+D">Daniel Duckworth</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Sankar%2C+C">Chinnadhurai Sankar</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Yan%2C+X">Xifeng Yan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1910.14613v1-abstract-short" style="display: inline;">
        Task-oriented dialog presents a difficult challenge encompassing multiple problems including multi-turn language understanding and generation, knowledge retrieval and reasoning, and action prediction. Modern dialog systems typically begin by converting conversation history to a symbolic object referred to as belief state by using supervised learning. The belief state is then used to reason on an e&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1910.14613v1-abstract-full').style.display = 'inline'; document.getElementById('1910.14613v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1910.14613v1-abstract-full" style="display: none;">
        Task-oriented dialog presents a difficult challenge encompassing multiple problems including multi-turn language understanding and generation, knowledge retrieval and reasoning, and action prediction. Modern dialog systems typically begin by converting conversation history to a symbolic object referred to as belief state by using supervised learning. The belief state is then used to reason on an external knowledge source whose result along with the conversation history is used in action prediction and response generation tasks independently. Such a pipeline of individually optimized components not only makes the development process cumbersome but also makes it non-trivial to leverage session-level user reinforcement signals. In this paper, we develop Neural Assistant: a single neural network model that takes conversation history and an external knowledge source as input and jointly produces both text response and action to be taken by the system as output. The model learns to reason on the provided knowledge source with weak supervision signal coming from the text generation and the action prediction tasks, hence removing the need for belief state annotations. In the MultiWOZ dataset, we study the effect of distant supervision, and the size of knowledge base on model performance. We find that the Neural Assistant without belief states is able to incorporate external knowledge information achieving higher factual accuracy scores compared to Transformer. In settings comparable to reported baseline systems, Neural Assistant when provided with oracle belief state significantly improves language generation performance.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1910.14613v1-abstract-full').style.display = 'none'; document.getElementById('1910.14613v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 31 October, 2019; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2019.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1910.10683">arXiv:1910.10683</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1910.10683">pdf</a>, <a href="https://arxiv.org/format/1910.10683">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Raffel%2C+C">Colin Raffel</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Shazeer%2C+N">Noam Shazeer</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Roberts%2C+A">Adam Roberts</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Lee%2C+K">Katherine Lee</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Narang%2C+S">Sharan Narang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Matena%2C+M">Michael Matena</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+Y">Yanqi Zhou</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Li%2C+W">Wei Li</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Liu%2C+P+J">Peter J. Liu</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1910.10683v3-abstract-short" style="display: inline;">
        Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned on a downstream task, has emerged as a powerful technique in natural language processing (NLP). The effectiveness of transfer learning has given rise to a diversity of approaches, methodology, and practice. In this paper, we explore the landscape of transfer learning techniques for NLP by introducing&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1910.10683v3-abstract-full').style.display = 'inline'; document.getElementById('1910.10683v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1910.10683v3-abstract-full" style="display: none;">
        Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned on a downstream task, has emerged as a powerful technique in natural language processing (NLP). The effectiveness of transfer learning has given rise to a diversity of approaches, methodology, and practice. In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework that converts all text-based language problems into a text-to-text format. Our systematic study compares pre-training objectives, architectures, unlabeled data sets, transfer approaches, and other factors on dozens of language understanding tasks. By combining the insights from our exploration with scale and our new ``Colossal Clean Crawled Corpus&#39;&#39;, we achieve state-of-the-art results on many benchmarks covering summarization, question answering, text classification, and more. To facilitate future work on transfer learning for NLP, we release our data set, pre-trained models, and code.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1910.10683v3-abstract-full').style.display = 'none'; document.getElementById('1910.10683v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 28 July, 2020; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 23 October, 2019;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2019.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Final version as published in JMLR</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1901.09427">arXiv:1901.09427</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1901.09427">pdf</a>, <a href="https://arxiv.org/ps/1901.09427">ps</a>, <a href="https://arxiv.org/format/1901.09427">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Science and Game Theory">cs.GT</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Fair Division of Indivisible Goods Among Strategic Agents
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Barman%2C+S">Siddharth Barman</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Ghalme%2C+G">Ganesh Ghalme</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Jain%2C+S">Shweta Jain</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Kulkarni%2C+P">Pooja Kulkarni</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Narang%2C+S">Shivika Narang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1901.09427v1-abstract-short" style="display: inline;">
        We study fair division of indivisible goods in a single-parameter environment. In particular, we develop truthful social welfare maximizing mechanisms for fairly allocating indivisible goods. Our fairness guarantees are in terms of solution concepts which are tailored to address allocation of indivisible goods and, hence, provide an appropriate framework for fair division of goods. This work speci&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1901.09427v1-abstract-full').style.display = 'inline'; document.getElementById('1901.09427v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1901.09427v1-abstract-full" style="display: none;">
        We study fair division of indivisible goods in a single-parameter environment. In particular, we develop truthful social welfare maximizing mechanisms for fairly allocating indivisible goods. Our fairness guarantees are in terms of solution concepts which are tailored to address allocation of indivisible goods and, hence, provide an appropriate framework for fair division of goods. This work specifically considers fairness in terms of envy freeness up to one good (EF1), maximin share guarantee (MMS), and Nash social welfare (NSW).
  Our first result shows that (in a single-parameter environment) the problem of maximizing welfare, subject to the constraint that the allocation of the indivisible goods is EF1, admits a polynomial-time, 1/2-approximate, truthful auction. We further prove that this problem is NP-Hard and, hence, an approximation is warranted. This hardness result also complements prior works which show that an arbitrary EF1 allocation can be computed efficiently.
  We also establish a bi-criteria approximation guarantee for the problem of maximizing social welfare under MMS constraints. In particular, we develop a truthful auction which efficiently finds an allocation wherein each agent gets a bundle of value at least $\left(1/2 - \varepsilon \right)$ times her maximin share and the welfare of the computed allocation is at least the optimal, here $\varepsilon &gt;0$ is a fixed constant. We complement this result by showing that maximizing welfare is computationally hard even if one aims to only satisfy the MMS constraint approximately.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1901.09427v1-abstract-full').style.display = 'none'; document.getElementById('1901.09427v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 27 January, 2019; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2019.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1712.00409">arXiv:1712.00409</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1712.00409">pdf</a>, <a href="https://arxiv.org/format/1712.00409">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Deep Learning Scaling is Predictable, Empirically
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Hestness%2C+J">Joel Hestness</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Narang%2C+S">Sharan Narang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Ardalani%2C+N">Newsha Ardalani</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Diamos%2C+G">Gregory Diamos</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Jun%2C+H">Heewoo Jun</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Kianinejad%2C+H">Hassan Kianinejad</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Patwary%2C+M+M+A">Md. Mostofa Ali Patwary</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Yang%2C+Y">Yang Yang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+Y">Yanqi Zhou</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1712.00409v1-abstract-short" style="display: inline;">
        Deep learning (DL) creates impactful advances following a virtuous recipe: model architecture search, creating large training data sets, and scaling computation. It is widely believed that growing training sets and models should improve accuracy and result in better products. As DL application domains grow, we would like a deeper understanding of the relationships between training set size, comput&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1712.00409v1-abstract-full').style.display = 'inline'; document.getElementById('1712.00409v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1712.00409v1-abstract-full" style="display: none;">
        Deep learning (DL) creates impactful advances following a virtuous recipe: model architecture search, creating large training data sets, and scaling computation. It is widely believed that growing training sets and models should improve accuracy and result in better products. As DL application domains grow, we would like a deeper understanding of the relationships between training set size, computational scale, and model accuracy improvements to advance the state-of-the-art.
  This paper presents a large scale empirical characterization of generalization error and model size growth as training sets grow. We introduce a methodology for this measurement and test four machine learning domains: machine translation, language modeling, image processing, and speech recognition. Our empirical results show power-law generalization error scaling across a breadth of factors, resulting in power-law exponents---the &#34;steepness&#34; of the learning curve---yet to be explained by theoretical work. Further, model improvements only shift the error but do not appear to affect the power-law exponent. We also show that model size scales sublinearly with data size. These scaling relationships have significant implications on deep learning research, practice, and systems. They can assist model debugging, setting accuracy targets, and decisions about data set growth. They can also guide computing system design and underscore the importance of continued computational scaling.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1712.00409v1-abstract-full').style.display = 'none'; document.getElementById('1712.00409v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 1 December, 2017; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2017.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">19 pages, 11 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1711.02782">arXiv:1711.02782</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1711.02782">pdf</a>, <a href="https://arxiv.org/format/1711.02782">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Block-Sparse Recurrent Neural Networks
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Narang%2C+S">Sharan Narang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Undersander%2C+E">Eric Undersander</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Diamos%2C+G">Gregory Diamos</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1711.02782v1-abstract-short" style="display: inline;">
        Recurrent Neural Networks (RNNs) are used in state-of-the-art models in domains such as speech recognition, machine translation, and language modelling. Sparsity is a technique to reduce compute and memory requirements of deep learning models. Sparse RNNs are easier to deploy on devices and high-end server processors. Even though sparse operations need less compute and memory relative to their den&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1711.02782v1-abstract-full').style.display = 'inline'; document.getElementById('1711.02782v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1711.02782v1-abstract-full" style="display: none;">
        Recurrent Neural Networks (RNNs) are used in state-of-the-art models in domains such as speech recognition, machine translation, and language modelling. Sparsity is a technique to reduce compute and memory requirements of deep learning models. Sparse RNNs are easier to deploy on devices and high-end server processors. Even though sparse operations need less compute and memory relative to their dense counterparts, the speed-up observed by using sparse operations is less than expected on different hardware platforms. In order to address this issue, we investigate two different approaches to induce block sparsity in RNNs: pruning blocks of weights in a layer and using group lasso regularization to create blocks of weights with zeros. Using these techniques, we demonstrate that we can create block-sparse RNNs with sparsity ranging from 80% to 90% with small loss in accuracy. This allows us to reduce the model size by roughly 10x. Additionally, we can prune a larger dense network to recover this loss in accuracy while maintaining high block sparsity and reducing the overall parameter count. Our technique works with a variety of block sizes up to 32x32. Block-sparse RNNs eliminate overheads related to data storage and irregular memory accesses while increasing hardware efficiency compared to unstructured sparsity.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1711.02782v1-abstract-full').style.display = 'none'; document.getElementById('1711.02782v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 November, 2017; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2017.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1710.07654">arXiv:1710.07654</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1710.07654">pdf</a>, <a href="https://arxiv.org/format/1710.07654">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Sound">cs.SD</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Audio and Speech Processing">eess.AS</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Deep Voice 3: Scaling Text-to-Speech with Convolutional Sequence Learning
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Ping%2C+W">Wei Ping</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Peng%2C+K">Kainan Peng</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Gibiansky%2C+A">Andrew Gibiansky</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Arik%2C+S+O">Sercan O. Arik</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Kannan%2C+A">Ajay Kannan</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Narang%2C+S">Sharan Narang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Raiman%2C+J">Jonathan Raiman</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Miller%2C+J">John Miller</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1710.07654v3-abstract-short" style="display: inline;">
        We present Deep Voice 3, a fully-convolutional attention-based neural text-to-speech (TTS) system. Deep Voice 3 matches state-of-the-art neural speech synthesis systems in naturalness while training ten times faster. We scale Deep Voice 3 to data set sizes unprecedented for TTS, training on more than eight hundred hours of audio from over two thousand speakers. In addition, we identify common erro&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1710.07654v3-abstract-full').style.display = 'inline'; document.getElementById('1710.07654v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1710.07654v3-abstract-full" style="display: none;">
        We present Deep Voice 3, a fully-convolutional attention-based neural text-to-speech (TTS) system. Deep Voice 3 matches state-of-the-art neural speech synthesis systems in naturalness while training ten times faster. We scale Deep Voice 3 to data set sizes unprecedented for TTS, training on more than eight hundred hours of audio from over two thousand speakers. In addition, we identify common error modes of attention-based speech synthesis networks, demonstrate how to mitigate them, and compare several different waveform synthesis methods. We also describe how to scale inference to ten million queries per day on one single-GPU server.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1710.07654v3-abstract-full').style.display = 'none'; document.getElementById('1710.07654v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 22 February, 2018; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 20 October, 2017;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2017.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Published as a conference paper at ICLR 2018. (v3 changed paper title)</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1710.03740">arXiv:1710.03740</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1710.03740">pdf</a>, <a href="https://arxiv.org/format/1710.03740">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Mixed Precision Training
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Micikevicius%2C+P">Paulius Micikevicius</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Narang%2C+S">Sharan Narang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Alben%2C+J">Jonah Alben</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Diamos%2C+G">Gregory Diamos</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Elsen%2C+E">Erich Elsen</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Garcia%2C+D">David Garcia</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Ginsburg%2C+B">Boris Ginsburg</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Houston%2C+M">Michael Houston</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Kuchaiev%2C+O">Oleksii Kuchaiev</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Venkatesh%2C+G">Ganesh Venkatesh</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Wu%2C+H">Hao Wu</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1710.03740v3-abstract-short" style="display: inline;">
        Deep neural networks have enabled progress in a wide variety of applications. Growing the size of the neural network typically results in improved accuracy. As model sizes grow, the memory and compute requirements for training these models also increases. We introduce a technique to train deep neural networks using half precision floating point numbers. In our technique, weights, activations and g&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1710.03740v3-abstract-full').style.display = 'inline'; document.getElementById('1710.03740v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1710.03740v3-abstract-full" style="display: none;">
        Deep neural networks have enabled progress in a wide variety of applications. Growing the size of the neural network typically results in improved accuracy. As model sizes grow, the memory and compute requirements for training these models also increases. We introduce a technique to train deep neural networks using half precision floating point numbers. In our technique, weights, activations and gradients are stored in IEEE half-precision format. Half-precision floating numbers have limited numerical range compared to single-precision numbers. We propose two techniques to handle this loss of information. Firstly, we recommend maintaining a single-precision copy of the weights that accumulates the gradients after each optimizer step. This single-precision copy is rounded to half-precision format during training. Secondly, we propose scaling the loss appropriately to handle the loss of information with half-precision gradients. We demonstrate that this approach works for a wide variety of models including convolution neural networks, recurrent neural networks and generative adversarial networks. This technique works for large scale models with more than 100 million parameters trained on large datasets. Using this approach, we can reduce the memory consumption of deep learning models by nearly 2x. In future processors, we can also expect a significant computation speedup using half-precision hardware units.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1710.03740v3-abstract-full').style.display = 'none'; document.getElementById('1710.03740v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 February, 2018; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 10 October, 2017;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2017.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Published as a conference paper at ICLR 2018</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1704.05119">arXiv:1704.05119</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1704.05119">pdf</a>, <a href="https://arxiv.org/format/1704.05119">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Exploring Sparsity in Recurrent Neural Networks
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Narang%2C+S">Sharan Narang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Elsen%2C+E">Erich Elsen</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Diamos%2C+G">Gregory Diamos</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Sengupta%2C+S">Shubho Sengupta</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1704.05119v2-abstract-short" style="display: inline;">
        Recurrent Neural Networks (RNN) are widely used to solve a variety of problems and as the quantity of data and the amount of available compute have increased, so have model sizes. The number of parameters in recent state-of-the-art networks makes them hard to deploy, especially on mobile phones and embedded devices. The challenge is due to both the size of the model and the time it takes to evalua&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1704.05119v2-abstract-full').style.display = 'inline'; document.getElementById('1704.05119v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1704.05119v2-abstract-full" style="display: none;">
        Recurrent Neural Networks (RNN) are widely used to solve a variety of problems and as the quantity of data and the amount of available compute have increased, so have model sizes. The number of parameters in recent state-of-the-art networks makes them hard to deploy, especially on mobile phones and embedded devices. The challenge is due to both the size of the model and the time it takes to evaluate it. In order to deploy these RNNs efficiently, we propose a technique to reduce the parameters of a network by pruning weights during the initial training of the network. At the end of training, the parameters of the network are sparse while accuracy is still close to the original dense neural network. The network size is reduced by 8x and the time required to train the model remains constant. Additionally, we can prune a larger dense network to achieve better than baseline performance while still reducing the total number of parameters significantly. Pruning RNNs reduces the size of the model and can also help achieve significant inference time speed-up using sparse matrix multiply. Benchmarks show that using our technique model size can be reduced by 90% and speed-up is around 2x to 7x.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1704.05119v2-abstract-full').style.display = 'none'; document.getElementById('1704.05119v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 6 November, 2017; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 17 April, 2017;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2017.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Published as a conference paper at ICLR 2017</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1703.08561">arXiv:1703.08561</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1703.08561">pdf</a>, <a href="https://arxiv.org/format/1703.08561">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Multiagent Systems">cs.MA</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        AutonoVi: Autonomous Vehicle Planning with Dynamic Maneuvers and Traffic Constraints
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Best%2C+A">Andrew Best</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Narang%2C+S">Sahil Narang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Barber%2C+D">Daniel Barber</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Manocha%2C+D">Dinesh Manocha</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1703.08561v2-abstract-short" style="display: inline;">
        We present AutonoVi:, a novel algorithm for autonomous vehicle navigation that supports dynamic maneuvers and satisfies traffic constraints and norms. Our approach is based on optimization-based maneuver planning that supports dynamic lane-changes, swerving, and braking in all traffic scenarios and guides the vehicle to its goal position. We take into account various traffic constraints, including&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1703.08561v2-abstract-full').style.display = 'inline'; document.getElementById('1703.08561v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1703.08561v2-abstract-full" style="display: none;">
        We present AutonoVi:, a novel algorithm for autonomous vehicle navigation that supports dynamic maneuvers and satisfies traffic constraints and norms. Our approach is based on optimization-based maneuver planning that supports dynamic lane-changes, swerving, and braking in all traffic scenarios and guides the vehicle to its goal position. We take into account various traffic constraints, including collision avoidance with other vehicles, pedestrians, and cyclists using control velocity obstacles. We use a data-driven approach to model the vehicle dynamics for control and collision avoidance. Furthermore, our trajectory computation algorithm takes into account traffic rules and behaviors, such as stopping at intersections and stoplights, based on an arc-spline representation. We have evaluated our algorithm in a simulated environment and tested its interactive performance in urban and highway driving scenarios with tens of vehicles, pedestrians, and cyclists. These scenarios include jaywalking pedestrians, sudden stops from high speeds, safely passing cyclists, a vehicle suddenly swerving into the roadway, and high-density traffic where the vehicle must change lanes to progress more effectively.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1703.08561v2-abstract-full').style.display = 'none'; document.getElementById('1703.08561v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 29 March, 2017; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 24 March, 2017;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2017.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">9 pages, 6 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1607.04381">arXiv:1607.04381</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1607.04381">pdf</a>, <a href="https://arxiv.org/format/1607.04381">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        DSD: Dense-Sparse-Dense Training for Deep Neural Networks
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Han%2C+S">Song Han</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Pool%2C+J">Jeff Pool</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Narang%2C+S">Sharan Narang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Mao%2C+H">Huizi Mao</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Gong%2C+E">Enhao Gong</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Tang%2C+S">Shijian Tang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Elsen%2C+E">Erich Elsen</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Vajda%2C+P">Peter Vajda</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Paluri%2C+M">Manohar Paluri</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Tran%2C+J">John Tran</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Catanzaro%2C+B">Bryan Catanzaro</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Dally%2C+W+J">William J. Dally</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1607.04381v2-abstract-short" style="display: inline;">
        Modern deep neural networks have a large number of parameters, making them very hard to train. We propose DSD, a dense-sparse-dense training flow, for regularizing deep neural networks and achieving better optimization performance. In the first D (Dense) step, we train a dense network to learn connection weights and importance. In the S (Sparse) step, we regularize the network by pruning the unimp&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1607.04381v2-abstract-full').style.display = 'inline'; document.getElementById('1607.04381v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1607.04381v2-abstract-full" style="display: none;">
        Modern deep neural networks have a large number of parameters, making them very hard to train. We propose DSD, a dense-sparse-dense training flow, for regularizing deep neural networks and achieving better optimization performance. In the first D (Dense) step, we train a dense network to learn connection weights and importance. In the S (Sparse) step, we regularize the network by pruning the unimportant connections with small weights and retraining the network given the sparsity constraint. In the final D (re-Dense) step, we increase the model capacity by removing the sparsity constraint, re-initialize the pruned parameters from zero and retrain the whole dense network. Experiments show that DSD training can improve the performance for a wide range of CNNs, RNNs and LSTMs on the tasks of image classification, caption generation and speech recognition. On ImageNet, DSD improved the Top1 accuracy of GoogLeNet by 1.1%, VGG-16 by 4.3%, ResNet-18 by 1.2% and ResNet-50 by 1.1%, respectively. On the WSJ&#39;93 dataset, DSD improved DeepSpeech and DeepSpeech2 WER by 2.0% and 1.1%. On the Flickr-8K dataset, DSD improved the NeuralTalk BLEU score by over 1.7. DSD is easy to use in practice: at training time, DSD incurs only one extra hyper-parameter: the sparsity ratio in the S step. At testing time, DSD doesn&#39;t change the network architecture or incur any inference overhead. The consistent and significant performance gain of DSD experiments shows the inadequacy of the current training methods for finding the best local optimum, while DSD effectively achieves superior optimization performance for finding a better solution. DSD models are available to download at https://songhan.github.io/DSD.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1607.04381v2-abstract-full').style.display = 'none'; document.getElementById('1607.04381v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 21 February, 2017; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 15 July, 2016;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2016.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Published as a conference paper at ICLR 2017</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1602.03623">arXiv:1602.03623</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1602.03623">pdf</a>, <a href="https://arxiv.org/format/1602.03623">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Multiagent Systems">cs.MA</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Dynamic Group Behaviors for Interactive Crowd Simulation
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=He%2C+L">Liang He</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Pan%2C+J">Jia Pan</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Narang%2C+S">Sahil Narang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Wang%2C+W">Wenping Wang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Manocha%2C+D">Dinesh Manocha</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1602.03623v1-abstract-short" style="display: inline;">
        We present a new algorithm to simulate dynamic group behaviors for interactive multi-agent crowd simulation. Our approach is general and makes no assumption about the environment, shape, or size of the groups. We use the least effort principle to perform coherent group navigation and present efficient inter-group and intra-group maintenance techniques. We extend the reciprocal collision avoidance&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1602.03623v1-abstract-full').style.display = 'inline'; document.getElementById('1602.03623v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1602.03623v1-abstract-full" style="display: none;">
        We present a new algorithm to simulate dynamic group behaviors for interactive multi-agent crowd simulation. Our approach is general and makes no assumption about the environment, shape, or size of the groups. We use the least effort principle to perform coherent group navigation and present efficient inter-group and intra-group maintenance techniques. We extend the reciprocal collision avoidance scheme to perform agent-group and group-group collision avoidance that can generate collision-free as well as coherent and trajectories. The additional overhead of dynamic group simulation is relatively small. We highlight its interactive performance on complex scenarios with hundreds of agents and compare the trajectory behaviors with real-world videos.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1602.03623v1-abstract-full').style.display = 'none'; document.getElementById('1602.03623v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 11 February, 2016; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2016.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1512.02595">arXiv:1512.02595</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1512.02595">pdf</a>, <a href="https://arxiv.org/format/1512.02595">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Deep Speech 2: End-to-End Speech Recognition in English and Mandarin
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Amodei%2C+D">Dario Amodei</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Anubhai%2C+R">Rishita Anubhai</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Battenberg%2C+E">Eric Battenberg</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Case%2C+C">Carl Case</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Casper%2C+J">Jared Casper</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Catanzaro%2C+B">Bryan Catanzaro</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Chen%2C+J">Jingdong Chen</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Chrzanowski%2C+M">Mike Chrzanowski</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Coates%2C+A">Adam Coates</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Diamos%2C+G">Greg Diamos</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Elsen%2C+E">Erich Elsen</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Engel%2C+J">Jesse Engel</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Fan%2C+L">Linxi Fan</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Fougner%2C+C">Christopher Fougner</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Han%2C+T">Tony Han</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Hannun%2C+A">Awni Hannun</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Jun%2C+B">Billy Jun</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=LeGresley%2C+P">Patrick LeGresley</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Lin%2C+L">Libby Lin</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Narang%2C+S">Sharan Narang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Ng%2C+A">Andrew Ng</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Ozair%2C+S">Sherjil Ozair</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Prenger%2C+R">Ryan Prenger</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Raiman%2C+J">Jonathan Raiman</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Satheesh%2C+S">Sanjeev Satheesh</a>
      , et al. (9 additional authors not shown)
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1512.02595v1-abstract-short" style="display: inline;">
        We show that an end-to-end deep learning approach can be used to recognize either English or Mandarin Chinese speech--two vastly different languages. Because it replaces entire pipelines of hand-engineered components with neural networks, end-to-end learning allows us to handle a diverse variety of speech including noisy environments, accents and different languages. Key to our approach is our app&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1512.02595v1-abstract-full').style.display = 'inline'; document.getElementById('1512.02595v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1512.02595v1-abstract-full" style="display: none;">
        We show that an end-to-end deep learning approach can be used to recognize either English or Mandarin Chinese speech--two vastly different languages. Because it replaces entire pipelines of hand-engineered components with neural networks, end-to-end learning allows us to handle a diverse variety of speech including noisy environments, accents and different languages. Key to our approach is our application of HPC techniques, resulting in a 7x speedup over our previous system. Because of this efficiency, experiments that previously took weeks now run in days. This enables us to iterate more quickly to identify superior architectures and algorithms. As a result, in several cases, our system is competitive with the transcription of human workers when benchmarked on standard datasets. Finally, using a technique called Batch Dispatch with GPUs in the data center, we show that our system can be inexpensively deployed in an online setting, delivering low latency when serving users at scale.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1512.02595v1-abstract-full').style.display = 'none'; document.getElementById('1512.02595v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 December, 2015; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2015.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1310.2646">arXiv:1310.2646</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1310.2646">pdf</a>, <a href="https://arxiv.org/ps/1310.2646">ps</a>, <a href="https://arxiv.org/format/1310.2646">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Localized Iterative Methods for Interpolation in Graph Structured Data
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Narang%2C+S+K">Sunil K. Narang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Gadde%2C+A">Akshay Gadde</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Sanou%2C+E">Eduard Sanou</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Ortega%2C+A">Antonio Ortega</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1310.2646v1-abstract-short" style="display: inline;">
        In this paper, we present two localized graph filtering based methods for interpolating graph signals defined on the vertices of arbitrary graphs from only a partial set of samples. The first method is an extension of previous work on reconstructing bandlimited graph signals from partially observed samples. The iterative graph filtering approach very closely approximates the solution proposed in t&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1310.2646v1-abstract-full').style.display = 'inline'; document.getElementById('1310.2646v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1310.2646v1-abstract-full" style="display: none;">
        In this paper, we present two localized graph filtering based methods for interpolating graph signals defined on the vertices of arbitrary graphs from only a partial set of samples. The first method is an extension of previous work on reconstructing bandlimited graph signals from partially observed samples. The iterative graph filtering approach very closely approximates the solution proposed in the that work, while being computationally more efficient. As an alternative, we propose a regularization based framework in which we define the cost of reconstruction to be a combination of smoothness of the graph signal and the reconstruction error with respect to the known samples, and find solutions that minimize this cost. We provide both a closed form solution and a computationally efficient iterative solution of the optimization problem. The experimental results on the recommendation system datasets demonstrate effectiveness of the proposed methods.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1310.2646v1-abstract-full').style.display = 'none'; document.getElementById('1310.2646v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 9 October, 2013; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2013.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1303.2685">arXiv:1303.2685</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1303.2685">pdf</a>, <a href="https://arxiv.org/format/1303.2685">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Bilateral Filter: Graph Spectral Interpretation and Extensions
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Gadde%2C+A">Akshay Gadde</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Narang%2C+S+K">Sunil K Narang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Ortega%2C+A">Antonio Ortega</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1303.2685v1-abstract-short" style="display: inline;">
        In this paper we study the bilateral filter proposed by Tomasi and Manduchi, as a spectral domain transform defined on a weighted graph. The nodes of this graph represent the pixels in the image and a graph signal defined on the nodes represents the intensity values. Edge weights in the graph correspond to the bilateral filter coefficients and hence are data adaptive. Spectrum of a graph is define&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1303.2685v1-abstract-full').style.display = 'inline'; document.getElementById('1303.2685v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1303.2685v1-abstract-full" style="display: none;">
        In this paper we study the bilateral filter proposed by Tomasi and Manduchi, as a spectral domain transform defined on a weighted graph. The nodes of this graph represent the pixels in the image and a graph signal defined on the nodes represents the intensity values. Edge weights in the graph correspond to the bilateral filter coefficients and hence are data adaptive. Spectrum of a graph is defined in terms of the eigenvalues and eigenvectors of the graph Laplacian matrix. We use this spectral interpretation to generalize the bilateral filter and propose more flexible and application specific spectral designs of bilateral-like filters. We show that these spectral filters can be implemented with k-iterative bilateral filtering operations and do not require expensive diagonalization of the Laplacian matrix.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1303.2685v1-abstract-full').style.display = 'none'; document.getElementById('1303.2685v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 11 March, 2013; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2013.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1211.0053">arXiv:1211.0053</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1211.0053">pdf</a>, <a href="https://arxiv.org/format/1211.0053">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Discrete Mathematics">cs.DM</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Social and Information Networks">cs.SI</span>
          
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1109/MSP.2012.2235192">10.1109/MSP.2012.2235192 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        The Emerging Field of Signal Processing on Graphs: Extending High-Dimensional Data Analysis to Networks and Other Irregular Domains
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Shuman%2C+D+I">David I Shuman</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Narang%2C+S+K">Sunil K. Narang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Frossard%2C+P">Pascal Frossard</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Ortega%2C+A">Antonio Ortega</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Vandergheynst%2C+P">Pierre Vandergheynst</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1211.0053v2-abstract-short" style="display: inline;">
        In applications such as social, energy, transportation, sensor, and neuronal networks, high-dimensional data naturally reside on the vertices of weighted graphs. The emerging field of signal processing on graphs merges algebraic and spectral graph theoretic concepts with computational harmonic analysis to process such signals on graphs. In this tutorial overview, we outline the main challenges of&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1211.0053v2-abstract-full').style.display = 'inline'; document.getElementById('1211.0053v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1211.0053v2-abstract-full" style="display: none;">
        In applications such as social, energy, transportation, sensor, and neuronal networks, high-dimensional data naturally reside on the vertices of weighted graphs. The emerging field of signal processing on graphs merges algebraic and spectral graph theoretic concepts with computational harmonic analysis to process such signals on graphs. In this tutorial overview, we outline the main challenges of the area, discuss different ways to define graph spectral domains, which are the analogues to the classical frequency domain, and highlight the importance of incorporating the irregular structures of graph data domains when processing signals on graphs. We then review methods to generalize fundamental operations such as filtering, translation, modulation, dilation, and downsampling to the graph setting, and survey the localized, multiscale transforms that have been proposed to efficiently extract information from high-dimensional data on graphs. We conclude with a brief discussion of open issues and possible extensions.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1211.0053v2-abstract-full').style.display = 'none'; document.getElementById('1211.0053v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 10 March, 2013; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 31 October, 2012;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2012.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">To appear in the IEEE Signal Processing Magazine</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1210.8129">arXiv:1210.8129</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1210.8129">pdf</a>, <a href="https://arxiv.org/format/1210.8129">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Information Theory">cs.IT</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Distributed, Parallel, and Cluster Computing">cs.DC</span>
          
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1109/TSP.2013.2273197">10.1109/TSP.2013.2273197 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Compact Support Biorthogonal Wavelet Filterbanks for Arbitrary Undirected Graphs
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Narang%2C+S+K">Sunil K. Narang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Ortega%2C+A">Antonio Ortega</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1210.8129v2-abstract-short" style="display: inline;">
        In our recent work, we proposed the design of perfect reconstruction orthogonal wavelet filterbanks, called graph- QMF, for arbitrary undirected weighted graphs. In that formulation we first designed &#34;one-dimensional&#34; two-channel filterbanks on bipartite graphs, and then extended them to &#34;multi-dimensional&#34; separable two-channel filterbanks for arbitrary graphs via a bipartite subgraph decompositi&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1210.8129v2-abstract-full').style.display = 'inline'; document.getElementById('1210.8129v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1210.8129v2-abstract-full" style="display: none;">
        In our recent work, we proposed the design of perfect reconstruction orthogonal wavelet filterbanks, called graph- QMF, for arbitrary undirected weighted graphs. In that formulation we first designed &#34;one-dimensional&#34; two-channel filterbanks on bipartite graphs, and then extended them to &#34;multi-dimensional&#34; separable two-channel filterbanks for arbitrary graphs via a bipartite subgraph decomposition. We specifically designed wavelet filters based on the spectral decomposition of the graph, and stated necessary and sufficient conditions for a two-channel graph filter-bank on bipartite graphs to provide aliasing-cancellation, perfect reconstruction and orthogonal set of basis (orthogonality). While, the exact graph-QMF designs satisfy all the above conditions, they are not exactly k-hop localized on the graph. In this paper, we relax the condition of orthogonality to design a biorthogonal pair of graph-wavelets that can have compact spatial spread and still satisfy the perfect reconstruction conditions. The design is analogous to the standard Cohen-Daubechies-Feauveau&#39;s (CDF) construction of factorizing a maximally-flat Daubechies half-band filter. Preliminary results demonstrate that the proposed filterbanks can be useful for both standard signal processing applications as well as for signals defined on arbitrary graphs.
  Note: Code examples from this paper are available at http://biron.usc.edu/wiki/index.php/Graph Filterbanks
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1210.8129v2-abstract-full').style.display = 'none'; document.getElementById('1210.8129v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 19 November, 2012; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 30 October, 2012;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2012.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Submitted for review in IEEE TSP</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1111.1564">arXiv:1111.1564</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1111.1564">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Neural and Evolutionary Computing">cs.NE</span>
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.5121/ijaia.2011.2302">10.5121/ijaia.2011.2302 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Particle Swarm Optimization Framework for Low Power Testing of VLSI Circuits
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Singh%2C+B">Balwnder Singh</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Narang%2C+S+B">Sukhleen Bindra Narang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Khosla%2C+A">Arun Khosla</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1111.1564v1-abstract-short" style="display: inline;">
        Power dissipation in sequential circuits is due to increased toggling count of Circuit under Test, which depends upon test vectors applied. If successive test vectors sequences have more toggling nature then it is sure that toggling rate of flip flops is higher. Higher toggling for flip flops results more power dissipation. To overcome this problem, one method is to use GA to have test vectors of&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1111.1564v1-abstract-full').style.display = 'inline'; document.getElementById('1111.1564v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1111.1564v1-abstract-full" style="display: none;">
        Power dissipation in sequential circuits is due to increased toggling count of Circuit under Test, which depends upon test vectors applied. If successive test vectors sequences have more toggling nature then it is sure that toggling rate of flip flops is higher. Higher toggling for flip flops results more power dissipation. To overcome this problem, one method is to use GA to have test vectors of high fault coverage in short interval, followed by Hamming distance management on test patterns. This approach is time consuming and needs more efforts. Another method which is purposed in this paper is a PSO based Frame Work to optimize power dissipation. Here target is to set the entire test vector in a frame for time period &#39;T&#39;, so that the frame consists of all those vectors strings which not only provide high fault coverage but also arrange vectors in frame to produce minimum toggling.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1111.1564v1-abstract-full').style.display = 'none'; document.getElementById('1111.1564v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 November, 2011; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2011.
      
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        International Journal of Artificial Intelligence &amp; Applications (IJAIA), Vol.2, No.3, July 2011
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1106.3693">arXiv:1106.3693</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1106.3693">pdf</a>, <a href="https://arxiv.org/format/1106.3693">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Distributed, Parallel, and Cluster Computing">cs.DC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Social and Information Networks">cs.SI</span>
          
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1109/TSP.2012.2188718">10.1109/TSP.2012.2188718 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Perfect Reconstruction Two-Channel Wavelet Filter-Banks for Graph Structured Data
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Narang%2C+S+K">Sunil K. Narang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Ortega%2C+A">Antonio Ortega</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1106.3693v3-abstract-short" style="display: inline;">
        In this work we propose the construction of two-channel wavelet filterbanks for analyzing functions defined on the vertices of any arbitrary finite weighted undirected graph. These graph based functions are referred to as graph-signals as we build a framework in which many concepts from the classical signal processing domain, such as Fourier decomposition, signal filtering and downsampling can be&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1106.3693v3-abstract-full').style.display = 'inline'; document.getElementById('1106.3693v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1106.3693v3-abstract-full" style="display: none;">
        In this work we propose the construction of two-channel wavelet filterbanks for analyzing functions defined on the vertices of any arbitrary finite weighted undirected graph. These graph based functions are referred to as graph-signals as we build a framework in which many concepts from the classical signal processing domain, such as Fourier decomposition, signal filtering and downsampling can be extended to graph domain. Especially, we observe a spectral folding phenomenon in bipartite graphs which occurs during downsampling of these graphs and produces aliasing in graph signals. This property of bipartite graphs, allows us to design critically sampled two-channel filterbanks, and we propose quadrature mirror filters (referred to as graph-QMF) for bipartite graph which cancel aliasing and lead to perfect reconstruction. For arbitrary graphs we present a bipartite subgraph decomposition which produces an edge-disjoint collection of bipartite subgraphs. Graph-QMFs are then constructed on each bipartite subgraph leading to &#34;multi-dimensional&#34; separable wavelet filterbanks on graphs. Our proposed filterbanks are critically sampled and we state necessary and sufficient conditions for orthogonality, aliasing cancellation and perfect reconstruction. The filterbanks are realized by Chebychev polynomial approximations.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1106.3693v3-abstract-full').style.display = 'none'; document.getElementById('1106.3693v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 1 December, 2011; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 18 June, 2011;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2011.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">32 pages double spaced 12 Figures, to appear in IEEE Transactions of Signal Processing</span>
    </p>
    

    

    
  </li>

</ol>


  


      <div class="is-hidden-tablet">
        <!-- feedback for mobile only -->
        <span class="help" style="display: inline-block;"><a href="https://github.com/arXiv/arxiv-search/releases">Search v0.5.6 released 2020-02-24</a>&nbsp;&nbsp;</span>
        <button class="button is-small" id="feedback-button">Feedback?</button>
      </div>
    </div>

  </main>
  <footer>
    
    <div class="columns is-desktop" role="navigation" aria-label="Secondary">
  <!-- MetaColumn 1 -->
  <div class="column">
    <div class="columns">
      <div class="column">
        <ul class="nav-spaced">
          <li><a href="https://arxiv.org/about">About</a></li>
          <li><a href="https://arxiv.org/help">Help</a></li>
        </ul>
      </div>
      <div class="column">
        <ul class="nav-spaced">
          <li>
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
            <a href="https://arxiv.org/help/contact"> Contact</a>
          </li>
          <li>
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
            <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
          </li>
        </ul>
      </div>
    </div>
  </div> <!-- end MetaColumn 1 -->
  <!-- MetaColumn 2 -->
  <div class="column">
    <div class="columns">
      <div class="column">
        <ul class="nav-spaced">
          <li><a href="https://arxiv.org/help/license">Copyright</a></li>
          <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
        </ul>
      </div>
      <div class="column sorry-app-links">
        <ul class="nav-spaced">
          <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
          <li>
            <p class="help">
              <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
              Get status notifications via
              <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
              or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
            </p>
          </li>
        </ul>
      </div>
    </div>
  </div> <!-- end MetaColumn 2 -->
</div>
    
  </footer>
  </body>
</html>