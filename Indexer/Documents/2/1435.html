<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<!-- new favicon config and versions by realfavicongenerator.net -->
<link rel="apple-touch-icon" sizes="180x180" href="https://static.arxiv.org/static/base/0.17.4.post2/images/icons/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://static.arxiv.org/static/base/0.17.4.post2/images/icons/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="https://static.arxiv.org/static/base/0.17.4.post2/images/icons/favicon-16x16.png">
<link rel="manifest" href="https://static.arxiv.org/static/base/0.17.4.post2/images/icons/site.webmanifest">
<link rel="mask-icon" href="https://static.arxiv.org/static/base/0.17.4.post2/images/icons/safari-pinned-tab.svg" color="#b31b1b">
<link rel="shortcut icon" href="https://static.arxiv.org/static/base/0.17.4.post2/images/icons/favicon.ico">
<meta name="msapplication-TileColor" content="#b31b1b">
<meta name="msapplication-config" content="images/icons/browserconfig.xml">
<meta name="theme-color" content="#b31b1b">
<!-- end favicon config -->
<title>Search | arXiv e-print repository</title>
<script defer src="https://static.arxiv.org/static/base/0.17.4.post2/fontawesome-free-5.11.2-web/js/all.js"></script>
<link rel="stylesheet" href="https://static.arxiv.org/static/base/0.17.4.post2/css/arxivstyle.css" />
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    messageStyle: "none",
    extensions: ["tex2jax.js"],
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
      processEscapes: true,
      ignoreClass: '.*',
      processClass: 'mathjax.*'
    },
    TeX: {
        extensions: ["AMSmath.js", "AMSsymbols.js", "noErrors.js"],
        noErrors: {
          inlineDelimiters: ["$","$"],
          multiLine: false,
          style: {
            "font-size": "normal",
            "border": ""
          }
        }
    },
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>
<script src='//static.arxiv.org/MathJax-2.7.3/MathJax.js'></script>
<script src="https://static.arxiv.org/static/base/0.17.4.post2/js/notification.js"></script>

    
  <link rel="stylesheet" href="https://static.arxiv.org/static/search/0.5.6/css/bulma-tooltip.min.css" />
  <link rel="stylesheet" href="https://static.arxiv.org/static/search/0.5.6/css/search.css" />
  <script
    src="https://code.jquery.com/jquery-3.2.1.slim.min.js"
    integrity="sha256-k2WSCIexGzOj3Euiig+TlR8gA0EmPjuc79OEeY5L45g="
    crossorigin="anonymous"></script>

  <script src="https://static.arxiv.org/static/search/0.5.6/js/fieldset.js"></script>
  <style>
  radio#cf-customfield_11400 {
    display: none;
  }
  </style>
  <script type="text/javascript" src="https://arxiv-org.atlassian.net/s/d41d8cd98f00b204e9800998ecf8427e-T/-tqqyqk/b/20/a44af77267a987a660377e5c46e0fb64/_/download/batch/com.atlassian.jira.collector.plugin.jira-issue-collector-plugin:issuecollector/com.atlassian.jira.collector.plugin.jira-issue-collector-plugin:issuecollector.js?locale=en-US&collectorId=3b3dcb4c"></script>

    <script type="text/javascript">
    window.ATL_JQ_PAGE_PROPS =  {
    	"triggerFunction": function(showCollectorDialog) {
    		//Requires that jQuery is available!
    		$("#feedback-button").click(function(e) {
    			e.preventDefault();
    			showCollectorDialog();
    		});
    	},
      fieldValues: {
        "components": ["16000"],  // Search component.
        "versions": ["14260"],  // Release search-0.5.6
        "customfield_11401": window.location.href
      }
    };
    </script>

  </head>
  <body>
  
  
  <header><a href="#main-container" class="is-sr-only">Skip to main content</a>
    
    <!-- contains Cornell logo and sponsor statement -->
<div class="attribution level is-marginless" role="banner">
  <div class="level-left">
    <a class="level-item" href="https://cornell.edu/"><img src="https://static.arxiv.org/static/base/0.17.4.post2/images/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" aria-label="logo" /></a>
  </div>
  <div class="level-right is-marginless"><p class="sponsors level-item is-marginless"><a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a></p></div>
</div>
<!-- contains arXiv identity and search bar -->
<div class="identity level is-marginless">
  <div class="level-left">
    <div class="level-item">
      <a class="arxiv" href="https://arxiv.org/" aria-label="arxiv-logo">
        <img src="https://static.arxiv.org/static/base/0.17.4.post2/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;"/>
      </a>
    </div>
  </div>
  
  <div class="search-block level-right">
    <form class="level-item mini-search" method="GET" action="https://arxiv.org/search">
      <div class="field has-addons">
        <div class="control">
          <input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" />
          <p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
        </div>
        <div class="control">
          <div class="select is-small">
            <select name="searchtype" aria-label="Field to search">
              <option value="all" selected="selected">All fields</option>
              <option value="title">Title</option>
              <option value="author">Author</option>
              <option value="abstract">Abstract</option>
              <option value="comments">Comments</option>
              <option value="journal_ref">Journal reference</option>
              <option value="acm_class">ACM classification</option>
              <option value="msc_class">MSC classification</option>
              <option value="report_num">Report number</option>
              <option value="paper_id">arXiv identifier</option>
              <option value="doi">DOI</option>
              <option value="orcid">ORCID</option>
              <option value="author_id">arXiv author ID</option>
              <option value="help">Help pages</option>
              <option value="full_text">Full text</option>
            </select>
          </div>
        </div>
        <input type="hidden" name="source" value="header">
        <button class="button is-small is-cul-darker">Search</button>
      </div>
    </form>
  </div>
</div> <!-- closes identity -->

<div class="container">
    <div class="user-tools is-size-7 has-text-right has-text-weight-bold" role="navigation" aria-label="User menu">
      <a href="https://arxiv.org/login">Login</a>
    </div>
</div>
    
  </header>
  <main class="container" id="main-container">
    


    
  <div class="level is-marginless">
    <div class="level-left">
      <h1 class="title is-clearfix">
    
        Showing 1&ndash;50 of 193 results for author: <span class="mathjax">He, K</span>
    
</h1>
    </div>
    <div class="level-right is-hidden-mobile">
      <!-- feedback for mobile is moved to footer -->
      <span class="help" style="display: inline-block;"><a href="https://github.com/arXiv/arxiv-search/releases">Search v0.5.6 released 2020-02-24</a>&nbsp;&nbsp;</span>
      <button class="button is-small" id="feedback-button">Feedback?</button>
    </div>
  </div>
    <div class="content">
      
  <form method="GET" action="/search/cs"  aria-role="search">
    
      Searching in archive <strong>cs</strong>. <a href="/search/?searchtype=author&amp;query=He%2C+K">Search in all archives.</a>
    

    
    <div class="field has-addons-tablet">
      <div class="control is-expanded">
        <label for="query" class="hidden-label">Search term or terms</label>
        
          <input class="input is-medium" id="query" name="query" placeholder="Search term..." type="text" value="He, K">
        
        
      </div>
      <div class="select control is-medium">
        <label class="is-hidden" for="searchtype">Field</label>
        <select class="is-medium" id="searchtype" name="searchtype"><option value="all">All fields</option><option value="title">Title</option><option selected value="author">Author(s)</option><option value="abstract">Abstract</option><option value="comments">Comments</option><option value="journal_ref">Journal reference</option><option value="acm_class">ACM classification</option><option value="msc_class">MSC classification</option><option value="report_num">Report number</option><option value="paper_id">arXiv identifier</option><option value="doi">DOI</option><option value="orcid">ORCID</option><option value="license">License (URI)</option><option value="author_id">arXiv author ID</option><option value="help">Help pages</option><option value="full_text">Full text</option></select>
      </div>
      <div class="control">
          <button class="button is-link is-medium">Search</button>
      </div>
    </div>
    <div class="field">
      <div class="control is-size-7">
        
        <label class="radio">
          <input checked id="abstracts-0" name="abstracts" type="radio" value="show"> Show abstracts
        </label>
        
        <label class="radio">
          <input id="abstracts-1" name="abstracts" type="radio" value="hide"> Hide abstracts
        </label>
        
      </div>
    </div>
    <div class="is-clearfix" style="height: 2.5em"> 
      <div class="is-pulled-right">
        
        <a href="/search/advanced?terms-0-term=He%2C+K&amp;terms-0-field=author&amp;size=50&amp;order=-announced_date_first">Advanced Search</a>
        
      </div>
    </div>
    <input type="hidden" name="order" value="-announced_date_first">
    <input type="hidden" name="size" value="50">
  </form>

  

  
      
<div class="level breathe-horizontal">
  <div class="level-left">
    <form method="GET" action="/search/">
      <div style="display: none;">
        
          
            <select id="searchtype" name="searchtype"><option value="all">All fields</option><option value="title">Title</option><option selected value="author">Author(s)</option><option value="abstract">Abstract</option><option value="comments">Comments</option><option value="journal_ref">Journal reference</option><option value="acm_class">ACM classification</option><option value="msc_class">MSC classification</option><option value="report_num">Report number</option><option value="paper_id">arXiv identifier</option><option value="doi">DOI</option><option value="orcid">ORCID</option><option value="license">License (URI)</option><option value="author_id">arXiv author ID</option><option value="help">Help pages</option><option value="full_text">Full text</option></select>
          
        
          
            <input id="query" name="query" type="text" value="He, K">
          
        
          
        
          
        
          
            <ul id="abstracts"><li><input checked id="abstracts-0" name="abstracts" type="radio" value="show"> <label for="abstracts-0">Show abstracts</label></li><li><input id="abstracts-1" name="abstracts" type="radio" value="hide"> <label for="abstracts-1">Hide abstracts</label></li></ul>
          
        
      </div>
      <div class="box field is-grouped is-grouped-multiline level-item">
        <div class="control">
          <span class="select is-small">
            <select id="size" name="size"><option value="25">25</option><option selected value="50">50</option><option value="100">100</option><option value="200">200</option></select>
          </span>
          <label for="size">results per page</label>.
        </div>
        <div class="control">
          <label for="order">Sort results by</label>
          <span class="select is-small">
            <select id="order" name="order"><option selected value="-announced_date_first">Announcement date (newest first)</option><option value="announced_date_first">Announcement date (oldest first)</option><option value="-submitted_date">Submission date (newest first)</option><option value="submitted_date">Submission date (oldest first)</option><option value="">Relevance</option></select>
          </span>
        </div>
        <div class="control">
          <button class="button is-small is-link">Go</button>
        </div>
      </div>
    </form>
  </div>
</div>
      


  <nav class="pagination is-small is-centered breathe-horizontal" role="navigation" aria-label="pagination">
    
    <a href=""
      class="pagination-previous is-invisible">Previous
    </a>
    
    
      <a href="/search/?searchtype=author&amp;query=He%2C+K&amp;start=50"
        class="pagination-next" >Next
      </a>
    
    <ul class="pagination-list">

      <li>
        <a href="/search/?searchtype=author&amp;query=He%2C+K&amp;start=0"
          class="pagination-link is-current"
          aria-label="Goto page 1">1
        </a>
      </li>

      
        
        <li>
          <a href="/search/?searchtype=author&amp;query=He%2C+K&amp;start=50"
            class="pagination-link "
            aria-label="Page 2"
            aria-current="page">2
          </a>
        </li>
        
        <li>
          <a href="/search/?searchtype=author&amp;query=He%2C+K&amp;start=100"
            class="pagination-link "
            aria-label="Page 3"
            aria-current="page">3
          </a>
        </li>
        
        <li>
          <a href="/search/?searchtype=author&amp;query=He%2C+K&amp;start=150"
            class="pagination-link "
            aria-label="Page 4"
            aria-current="page">4
          </a>
        </li>
        
      
    </ul>
  </nav>
  



<ol class="breathe-horizontal" start="1"> 


  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2204.06113">arXiv:2204.06113</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2204.06113">pdf</a>, <a href="https://arxiv.org/format/2204.06113">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Cryptography and Security">cs.CR</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Liuer Mihou: A Practical Framework for Generating and Evaluating Grey-box Adversarial Attacks against NIDS
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=He%2C+K">Ke He</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Kim%2C+D+D">Dan Dongseong Kim</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Sun%2C+J">Jing Sun</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Yoo%2C+J+D">Jeong Do Yoo</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Lee%2C+Y+H">Young Hun Lee</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Kim%2C+H+K">Huy Kang Kim</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2204.06113v1-abstract-short" style="display: inline;">
        Due to its high expressiveness and speed, Deep Learning (DL) has become an increasingly popular choice as the detection algorithm for Network-based Intrusion Detection Systems (NIDSes). Unfortunately, DL algorithms are vulnerable to adversarial examples that inject imperceptible modifications to the input and cause the DL algorithm to misclassify the input. Existing adversarial attacks in the NIDS&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2204.06113v1-abstract-full').style.display = 'inline'; document.getElementById('2204.06113v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2204.06113v1-abstract-full" style="display: none;">
        Due to its high expressiveness and speed, Deep Learning (DL) has become an increasingly popular choice as the detection algorithm for Network-based Intrusion Detection Systems (NIDSes). Unfortunately, DL algorithms are vulnerable to adversarial examples that inject imperceptible modifications to the input and cause the DL algorithm to misclassify the input. Existing adversarial attacks in the NIDS domain often manipulate the traffic features directly, which hold no practical significance because traffic features cannot be replayed in a real network. It remains a research challenge to generate practical and evasive adversarial attacks.
  This paper presents the Liuer Mihou attack that generates practical and replayable adversarial network packets that can bypass anomaly-based NIDS deployed in the Internet of Things (IoT) networks. The core idea behind Liuer Mihou is to exploit adversarial transferability and generate adversarial packets on a surrogate NIDS constrained by predefined mutation operations to ensure practicality. We objectively analyse the evasiveness of Liuer Mihou against four ML-based algorithms (LOF, OCSVM, RRCF, and SOM) and the state-of-the-art NIDS, Kitsune. From the results of our experiment, we gain valuable insights into necessary conditions on the adversarial transferability of anomaly detection algorithms. Going beyond a theoretical setting, we replay the adversarial attack in a real IoT testbed to examine the practicality of Liuer Mihou. Furthermore, we demonstrate that existing feature-level adversarial defence cannot defend against Liuer Mihou and constructively criticise the limitations of feature-level adversarial defences.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2204.06113v1-abstract-full').style.display = 'none'; document.getElementById('2204.06113v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 12 April, 2022; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2022.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">16 pages, 8 figures, planning on submitting to ACM CCS 2022</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          I.2.1
        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2204.04681">arXiv:2204.04681</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2204.04681">pdf</a>, <a href="https://arxiv.org/format/2204.04681">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Enhancing the Robustness, Efficiency, and Diversity of Differentiable Architecture Search
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Li%2C+C">Chao Li</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Ning%2C+J">Jia Ning</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Hu%2C+H">Han Hu</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=He%2C+K">Kun He</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2204.04681v1-abstract-short" style="display: inline;">
        Differentiable architecture search (DARTS) has attracted much attention due to its simplicity and significant improvement in efficiency. However, the excessive accumulation of the skip connection makes it suffer from long-term weak stability and low robustness. Many works attempt to restrict the accumulation of skip connections by indicators or manual design, however, these methods are susceptible&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2204.04681v1-abstract-full').style.display = 'inline'; document.getElementById('2204.04681v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2204.04681v1-abstract-full" style="display: none;">
        Differentiable architecture search (DARTS) has attracted much attention due to its simplicity and significant improvement in efficiency. However, the excessive accumulation of the skip connection makes it suffer from long-term weak stability and low robustness. Many works attempt to restrict the accumulation of skip connections by indicators or manual design, however, these methods are susceptible to thresholds and human priors. In this work, we suggest a more subtle and direct approach that removes skip connections from the operation space. Then, by introducing an adaptive channel allocation strategy, we redesign the DARTS framework to automatically refill the skip connections in the evaluation stage, resolving the performance degradation caused by the absence of skip connections. Our method, dubbed Adaptive-Channel-Allocation-DARTS (ACA-DRATS), could eliminate the inconsistency in operation strength and significantly expand the architecture diversity. We continue to explore smaller search space under our framework, and offer a direct search on the entire ImageNet dataset. Experiments show that ACA-DRATS improves the search stability and significantly speeds up DARTS by more than ten times while yielding higher accuracy.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2204.04681v1-abstract-full').style.display = 'none'; document.getElementById('2204.04681v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 10 April, 2022; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2022.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2204.04582">arXiv:2204.04582</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2204.04582">pdf</a>, <a href="https://arxiv.org/ps/2204.04582">ps</a>, <a href="https://arxiv.org/format/2204.04582">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Analysis of PDEs">math.AP</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Real order total variation with applications to the loss functions in learning schemes
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Liu%2C+P">Pan Liu</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Lu%2C+X+Y">Xin Yang Lu</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=He%2C+K">Kunlun He</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2204.04582v1-abstract-short" style="display: inline;">
        Loss function are an essential part in modern data-driven approach, such as bi-level training scheme and machine learnings. In this paper we propose a loss function consisting of a $r$-order (an)-isotropic total variation semi-norms $TV^r$, $r\in \mathbb{R}^+$, defined via the Riemann-Liouville (R-L) fractional derivative. We focus on studying key theoretical properties, such as the lower semi-con&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2204.04582v1-abstract-full').style.display = 'inline'; document.getElementById('2204.04582v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2204.04582v1-abstract-full" style="display: none;">
        Loss function are an essential part in modern data-driven approach, such as bi-level training scheme and machine learnings. In this paper we propose a loss function consisting of a $r$-order (an)-isotropic total variation semi-norms $TV^r$, $r\in \mathbb{R}^+$, defined via the Riemann-Liouville (R-L) fractional derivative. We focus on studying key theoretical properties, such as the lower semi-continuity and compactness with respect to both the function and the order of derivative $r$, of such loss functions.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2204.04582v1-abstract-full').style.display = 'none'; document.getElementById('2204.04582v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 9 April, 2022; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2022.
      
    </p>
    

    
      <p class="comments is-size-7">
        

        
          <span class="has-text-black-bis has-text-weight-semibold">MSC Class:</span>
          26B30; 94A08; 47J20
        

        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2204.04362">arXiv:2204.04362</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2204.04362">pdf</a>, <a href="https://arxiv.org/format/2204.04362">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Domain-Oriented Prefix-Tuning: Towards Efficient and Generalizable Fine-tuning for Zero-Shot Dialogue Summarization
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+L">Lulu Zhao</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Zheng%2C+F">Fujia Zheng</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Zeng%2C+W">Weihao Zeng</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=He%2C+K">Keqing He</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Xu%2C+W">Weiran Xu</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+H">Huixing Jiang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Wu%2C+W">Wei Wu</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Wu%2C+Y">Yanan Wu</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2204.04362v1-abstract-short" style="display: inline;">
        The most advanced abstractive dialogue summarizers lack generalization ability on new domains and the existing researches for domain adaptation in summarization generally rely on large-scale pre-trainings. To explore the lightweight fine-tuning methods for domain adaptation of dialogue summarization, in this paper, we propose an efficient and generalizable Domain-Oriented Prefix-tuning model, whic&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2204.04362v1-abstract-full').style.display = 'inline'; document.getElementById('2204.04362v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2204.04362v1-abstract-full" style="display: none;">
        The most advanced abstractive dialogue summarizers lack generalization ability on new domains and the existing researches for domain adaptation in summarization generally rely on large-scale pre-trainings. To explore the lightweight fine-tuning methods for domain adaptation of dialogue summarization, in this paper, we propose an efficient and generalizable Domain-Oriented Prefix-tuning model, which utilizes a domain word initialized prefix module to alleviate domain entanglement and adopts discrete prompts to guide the model to focus on key contents of dialogues and enhance model generalization. We conduct zero-shot experiments and build domain adaptation benchmarks on two multi-domain dialogue summarization datasets, TODSum and QMSum. Adequate experiments and qualitative analysis prove the effectiveness of our methods.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2204.04362v1-abstract-full').style.display = 'none'; document.getElementById('2204.04362v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 April, 2022; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2022.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">NAACL 2022 main conference(long paper)</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2204.02887">arXiv:2204.02887</a>
        <span>&nbsp;&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Sampling-based Fast Gradient Rescaling Method for Highly Transferable Adversarial Attacks
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Han%2C+X">Xu Han</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Liu%2C+A">Anmin Liu</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Xiong%2C+Y">Yifeng Xiong</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Fan%2C+Y">Yanbo Fan</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=He%2C+K">Kun He</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2204.02887v2-abstract-short" style="display: inline;">
        Deep neural networks have shown to be very vulnerable to adversarial examples crafted by adding human-imperceptible perturbations to benign inputs. After achieving impressive attack success rates in the white-box setting, more focus is shifted to black-box attacks. In either case, the common gradient-based approaches generally use the $sign$ function to generate perturbations at the end of the pro&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2204.02887v2-abstract-full').style.display = 'inline'; document.getElementById('2204.02887v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2204.02887v2-abstract-full" style="display: none;">
        Deep neural networks have shown to be very vulnerable to adversarial examples crafted by adding human-imperceptible perturbations to benign inputs. After achieving impressive attack success rates in the white-box setting, more focus is shifted to black-box attacks. In either case, the common gradient-based approaches generally use the $sign$ function to generate perturbations at the end of the process. However, only a few works pay attention to the limitation of the $sign$ function. Deviation between the original gradient and the generated noises may lead to inaccurate gradient update estimation and suboptimal solutions for adversarial transferability, which is crucial for black-box attacks. To address this issue, we propose a Sampling-based Fast Gradient Rescaling Method (S-FGRM) to improve the transferability of the crafted adversarial examples. Specifically, we use data rescaling to substitute the inefficient $sign$ function in gradient-based attacks without extra computational cost. We also propose a Depth First Sampling method to eliminate the fluctuation of rescaling and stabilize the gradient update. Our method can be used in any gradient-based optimizations and is extensible to be integrated with various input transformation or ensemble methods for further improving the adversarial transferability. Extensive experiments on the standard ImageNet dataset show that our S-FGRM could significantly boost the transferability of gradient-based attacks and outperform the state-of-the-art baselines.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2204.02887v2-abstract-full').style.display = 'none'; document.getElementById('2204.02887v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 23 April, 2022; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 6 April, 2022;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2022.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">The writing and experiment of the article need to be further strengthened</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2204.01520">arXiv:2204.01520</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2204.01520">pdf</a>, <a href="https://arxiv.org/ps/2204.01520">ps</a>, <a href="https://arxiv.org/format/2204.01520">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Data Structures and Algorithms">cs.DS</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Discrete Mathematics">cs.DM</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Sampling Lovász Local Lemma For General Constraint Satisfaction Solutions In Near-Linear Time
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=He%2C+K">Kun He</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Wang%2C+C">Chunyang Wang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Yin%2C+Y">Yitong Yin</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2204.01520v2-abstract-short" style="display: inline;">
        We give a fast algorithm for sampling uniform solutions of general constraint satisfaction problems (CSPs) in a local lemma regime. The expected running time of our algorithm is near-linear in $n$ and a fixed polynomial in $Δ$, where $n$ is the number of variables and $Δ$ is the max degree of constraints. Previously, up to similar conditions, sampling algorithms with running time polynomial in bot&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2204.01520v2-abstract-full').style.display = 'inline'; document.getElementById('2204.01520v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2204.01520v2-abstract-full" style="display: none;">
        We give a fast algorithm for sampling uniform solutions of general constraint satisfaction problems (CSPs) in a local lemma regime. The expected running time of our algorithm is near-linear in $n$ and a fixed polynomial in $Δ$, where $n$ is the number of variables and $Δ$ is the max degree of constraints. Previously, up to similar conditions, sampling algorithms with running time polynomial in both $n$ and $Δ$, only existed for the almost atomic case, where each constraint is violated by a small number of forbidden local configurations.
  Our sampling approach departs from all previous fast algorithms for sampling LLL, which were based on Markov chains. A crucial step of our algorithm is a recursive marginal sampler that is of independent interests. Within a local lemma regime, this marginal sampler can draw a random value for a variable according to its marginal distribution, at a local cost independent of the size of the CSP.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2204.01520v2-abstract-full').style.display = 'none'; document.getElementById('2204.01520v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 19 April, 2022; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 4 April, 2022;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2022.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2203.16527">arXiv:2203.16527</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2203.16527">pdf</a>, <a href="https://arxiv.org/format/2203.16527">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Exploring Plain Vision Transformer Backbones for Object Detection
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Li%2C+Y">Yanghao Li</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Mao%2C+H">Hanzi Mao</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Girshick%2C+R">Ross Girshick</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=He%2C+K">Kaiming He</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2203.16527v1-abstract-short" style="display: inline;">
        We explore the plain, non-hierarchical Vision Transformer (ViT) as a backbone network for object detection. This design enables the original ViT architecture to be fine-tuned for object detection without needing to redesign a hierarchical backbone for pre-training. With minimal adaptations for fine-tuning, our plain-backbone detector can achieve competitive results. Surprisingly, we observe: (i) i&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2203.16527v1-abstract-full').style.display = 'inline'; document.getElementById('2203.16527v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2203.16527v1-abstract-full" style="display: none;">
        We explore the plain, non-hierarchical Vision Transformer (ViT) as a backbone network for object detection. This design enables the original ViT architecture to be fine-tuned for object detection without needing to redesign a hierarchical backbone for pre-training. With minimal adaptations for fine-tuning, our plain-backbone detector can achieve competitive results. Surprisingly, we observe: (i) it is sufficient to build a simple feature pyramid from a single-scale feature map (without the common FPN design) and (ii) it is sufficient to use window attention (without shifting) aided with very few cross-window propagation blocks. With plain ViT backbones pre-trained as Masked Autoencoders (MAE), our detector, named ViTDet, can compete with the previous leading methods that were all based on hierarchical backbones, reaching up to 61.3 box AP on the COCO dataset using only ImageNet-1K pre-training. We hope our study will draw attention to research on plain-backbone detectors. Code will be made available.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2203.16527v1-abstract-full').style.display = 'none'; document.getElementById('2203.16527v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 30 March, 2022; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2022.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Tech report</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2203.14712">arXiv:2203.14712</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2203.14712">pdf</a>, <a href="https://arxiv.org/format/2203.14712">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Assembly101: A Large-Scale Multi-View Video Dataset for Understanding Procedural Activities
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Sener%2C+F">Fadime Sener</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Chatterjee%2C+D">Dibyadip Chatterjee</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Shelepov%2C+D">Daniel Shelepov</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=He%2C+K">Kun He</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Singhania%2C+D">Dipika Singhania</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Wang%2C+R">Robert Wang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Yao%2C+A">Angela Yao</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2203.14712v2-abstract-short" style="display: inline;">
        Assembly101 is a new procedural activity dataset featuring 4321 videos of people assembling and disassembling 101 &#34;take-apart&#34; toy vehicles. Participants work without fixed instructions, and the sequences feature rich and natural variations in action ordering, mistakes, and corrections. Assembly101 is the first multi-view action dataset, with simultaneous static (8) and egocentric (4) recordings.&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2203.14712v2-abstract-full').style.display = 'inline'; document.getElementById('2203.14712v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2203.14712v2-abstract-full" style="display: none;">
        Assembly101 is a new procedural activity dataset featuring 4321 videos of people assembling and disassembling 101 &#34;take-apart&#34; toy vehicles. Participants work without fixed instructions, and the sequences feature rich and natural variations in action ordering, mistakes, and corrections. Assembly101 is the first multi-view action dataset, with simultaneous static (8) and egocentric (4) recordings. Sequences are annotated with more than 100K coarse and 1M fine-grained action segments, and 18M 3D hand poses. We benchmark on three action understanding tasks: recognition, anticipation and temporal segmentation. Additionally, we propose a novel task of detecting mistakes. The unique recording format and rich set of annotations allow us to investigate generalization to new toys, cross-view transfer, long-tailed distributions, and pose vs. appearance. We envision that Assembly101 will serve as a new challenge to investigate various activity understanding problems.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2203.14712v2-abstract-full').style.display = 'none'; document.getElementById('2203.14712v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 1 May, 2022; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 28 March, 2022;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2022.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">CVPR 2022, https://assembly-101.github.io/</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2203.08423">arXiv:2203.08423</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2203.08423">pdf</a>, <a href="https://arxiv.org/format/2203.08423">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        On-The-Go Robot-to-Human Handovers with a Mobile Manipulator
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=He%2C+K">Kerry He</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Simini%2C+P">Pradeepsundar Simini</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Chan%2C+W">Wesley Chan</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Kuli%C4%87%2C+D">Dana Kulić</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Croft%2C+E">Elizabeth Croft</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Cosgun%2C+A">Akansel Cosgun</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2203.08423v1-abstract-short" style="display: inline;">
        Existing approaches to direct robot-to-human handovers are typically implemented on fixed-base robot arms, or on mobile manipulators that come to a full stop before performing the handover. We propose &#34;on-the-go&#34; handovers which permit a moving mobile manipulator to hand over an object to a human without stopping. The on-the-go handover motion is generated with a reactive controller that allows si&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2203.08423v1-abstract-full').style.display = 'inline'; document.getElementById('2203.08423v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2203.08423v1-abstract-full" style="display: none;">
        Existing approaches to direct robot-to-human handovers are typically implemented on fixed-base robot arms, or on mobile manipulators that come to a full stop before performing the handover. We propose &#34;on-the-go&#34; handovers which permit a moving mobile manipulator to hand over an object to a human without stopping. The on-the-go handover motion is generated with a reactive controller that allows simultaneous control of the base and the arm. In a user study, human receivers subjectively assessed on-the-go handovers to be more efficient, predictable, natural, better timed and safer than handovers that implemented a &#34;stop-and-deliver&#34; behavior.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2203.08423v1-abstract-full').style.display = 'none'; document.getElementById('2203.08423v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 16 March, 2022; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2022.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">6 pages, 7 figures, 2 tables, submitted to RO-MAN 2022</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2202.13817">arXiv:2202.13817</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2202.13817">pdf</a>, <a href="https://arxiv.org/format/2202.13817">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Robust Textual Embedding against Word-level Adversarial Attacks
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Yang%2C+Y">Yichen Yang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Wang%2C+X">Xiaosen Wang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=He%2C+K">Kun He</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2202.13817v1-abstract-short" style="display: inline;">
        We attribute the vulnerability of natural language processing models to the fact that similar inputs are converted to dissimilar representations in the embedding space, leading to inconsistent outputs, and propose a novel robust training method, termed Fast Triplet Metric Learning (FTML). Specifically, we argue that the original sample should have similar representation with its adversarial counte&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2202.13817v1-abstract-full').style.display = 'inline'; document.getElementById('2202.13817v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2202.13817v1-abstract-full" style="display: none;">
        We attribute the vulnerability of natural language processing models to the fact that similar inputs are converted to dissimilar representations in the embedding space, leading to inconsistent outputs, and propose a novel robust training method, termed Fast Triplet Metric Learning (FTML). Specifically, we argue that the original sample should have similar representation with its adversarial counterparts and distinguish its representation from other samples for better robustness. To this end, we adopt the triplet metric learning into the standard training to pull the words closer to their positive samples (i.e., synonyms) and push away their negative samples (i.e., non-synonyms) in the embedding space. Extensive experiments demonstrate that FTML can significantly promote the model robustness against various advanced adversarial attacks while keeping competitive classification accuracy on original samples. Besides, our method is efficient as it only needs to adjust the embedding and introduces very little overhead on the standard training. Our work shows the great potential of improving the textual robustness through robust word embedding.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2202.13817v1-abstract-full').style.display = 'none'; document.getElementById('2202.13817v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 28 February, 2022; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2022.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2202.12557">arXiv:2202.12557</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2202.12557">pdf</a>, <a href="https://arxiv.org/format/2202.12557">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Visibility Maximization Controller for Robotic Manipulation
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=He%2C+K">Kerry He</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Newbury%2C+R">Rhys Newbury</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Tran%2C+T">Tin Tran</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Haviland%2C+J">Jesse Haviland</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Burgess-Limerick%2C+B">Ben Burgess-Limerick</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Kuli%C4%87%2C+D">Dana Kulić</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Corke%2C+P">Peter Corke</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Cosgun%2C+A">Akansel Cosgun</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2202.12557v1-abstract-short" style="display: inline;">
        Occlusions caused by a robot&#39;s own body is a common problem for closed-loop control methods employed in eye-to-hand camera setups. We propose an optimization-based reactive controller that minimizes self-occlusions while achieving a desired goal pose. The approach allows coordinated control between the robot&#39;s base, arm and head by encoding the line-of-sight visibility to the target as a soft cons&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2202.12557v1-abstract-full').style.display = 'inline'; document.getElementById('2202.12557v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2202.12557v1-abstract-full" style="display: none;">
        Occlusions caused by a robot&#39;s own body is a common problem for closed-loop control methods employed in eye-to-hand camera setups. We propose an optimization-based reactive controller that minimizes self-occlusions while achieving a desired goal pose. The approach allows coordinated control between the robot&#39;s base, arm and head by encoding the line-of-sight visibility to the target as a soft constraint along with other task-related constraints, and solving for feasible joint and base velocities. The generalizability of the approach is demonstrated in simulated and real-world experiments, on robots with fixed or mobile bases, with moving or fixed objects, and multiple objects. The experiments revealed a trade-off between occlusion rates and other task metrics. While a planning-based baseline achieved lower occlusion rates than the proposed controller, it came at the expense of highly inefficient paths and a significant drop in the task success. On the other hand, the proposed controller is shown to improve visibility to the line target object(s) without sacrificing too much from the task success and efficiency. Videos and code can be found at: rhys-newbury.github.io/projects/vmc/.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2202.12557v1-abstract-full').style.display = 'none'; document.getElementById('2202.12557v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 25 February, 2022; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2022.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">8 pages, 6 figures, 7 tables, submitted to RA-L and IROS 2022</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2202.12165">arXiv:2202.12165</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2202.12165">pdf</a>, <a href="https://arxiv.org/format/2202.12165">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Transformers in Medical Image Analysis: A Review
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=He%2C+K">Kelei He</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Gan%2C+C">Chen Gan</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Li%2C+Z">Zhuoyuan Li</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Rekik%2C+I">Islem Rekik</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Yin%2C+Z">Zihao Yin</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Ji%2C+W">Wen Ji</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Gao%2C+Y">Yang Gao</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Q">Qian Wang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+J">Junfeng Zhang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Shen%2C+D">Dinggang Shen</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2202.12165v1-abstract-short" style="display: inline;">
        Transformers have dominated the field of natural language processing, and recently impacted the computer vision area. In the field of medical image analysis, Transformers have also been successfully applied to full-stack clinical applications, including image synthesis/reconstruction, registration, segmentation, detection, and diagnosis. Our paper presents both a position paper and a primer, promo&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2202.12165v1-abstract-full').style.display = 'inline'; document.getElementById('2202.12165v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2202.12165v1-abstract-full" style="display: none;">
        Transformers have dominated the field of natural language processing, and recently impacted the computer vision area. In the field of medical image analysis, Transformers have also been successfully applied to full-stack clinical applications, including image synthesis/reconstruction, registration, segmentation, detection, and diagnosis. Our paper presents both a position paper and a primer, promoting awareness and application of Transformers in the field of medical image analysis. Specifically, we first overview the core concepts of the attention mechanism built into Transformers and other basic components. Second, we give a new taxonomy of various Transformer architectures tailored for medical image applications and discuss their limitations. Within this review, we investigate key challenges revolving around the use of Transformers in different learning paradigms, improving the model efficiency, and their coupling with other techniques. We hope this review can give a comprehensive picture of Transformers to the readers in the field of medical image analysis.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2202.12165v1-abstract-full').style.display = 'none'; document.getElementById('2202.12165v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 24 February, 2022; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2022.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2202.11269">arXiv:2202.11269</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2202.11269">pdf</a>, <a href="https://arxiv.org/format/2202.11269">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Networking and Internet Architecture">cs.NI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Signal Processing">eess.SP</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        NetRCA: An Effective Network Fault Cause Localization Algorithm
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+C">Chaoli Zhang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+Z">Zhiqiang Zhou</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yingying Zhang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Yang%2C+L">Linxiao Yang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=He%2C+K">Kai He</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Wen%2C+Q">Qingsong Wen</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Sun%2C+L">Liang Sun</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2202.11269v2-abstract-short" style="display: inline;">
        Localizing the root cause of network faults is crucial to network operation and maintenance. However, due to the complicated network architectures and wireless environments, as well as limited labeled data, accurately localizing the true root cause is challenging. In this paper, we propose a novel algorithm named NetRCA to deal with this problem. Firstly, we extract effective derived features from&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2202.11269v2-abstract-full').style.display = 'inline'; document.getElementById('2202.11269v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2202.11269v2-abstract-full" style="display: none;">
        Localizing the root cause of network faults is crucial to network operation and maintenance. However, due to the complicated network architectures and wireless environments, as well as limited labeled data, accurately localizing the true root cause is challenging. In this paper, we propose a novel algorithm named NetRCA to deal with this problem. Firstly, we extract effective derived features from the original raw data by considering temporal, directional, attribution, and interaction characteristics. Secondly, we adopt multivariate time series similarity and label propagation to generate new training data from both labeled and unlabeled data to overcome the lack of labeled samples. Thirdly, we design an ensemble model which combines XGBoost, rule set learning, attribution model, and graph algorithm, to fully utilize all data information and enhance performance. Finally, experiments and analysis are conducted on the real-world dataset from ICASSP 2022 AIOps Challenge to demonstrate the superiority and effectiveness of our approach.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2202.11269v2-abstract-full').style.display = 'none'; document.getElementById('2202.11269v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 6 March, 2022; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 22 February, 2022;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2022.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted by ICASSP 2022. NetRCA is the solution of the First Place of 2022 ICASSP AIOps Challenge. All authors are contributed equally, and Qingsong Wen is the team leader (Team Name: MindOps). The website of 2022 ICASSP AIOps Challenge is https://www.aiops.sribd.cn/home/introduction</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2202.03093">arXiv:2202.03093</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2202.03093">pdf</a>, <a href="https://arxiv.org/format/2202.03093">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Data Structures and Algorithms">cs.DS</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Effective Variable Depth Local Search for the Budgeted Maximum Coverage Problem
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+J">Jianrong Zhou</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Zheng%2C+J">Jiongzhi Zheng</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=He%2C+K">Kun He</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2202.03093v1-abstract-short" style="display: inline;">
        We address the Budgeted Maximum Coverage Problem (BMCP), which is a natural and more practical extension of the standard 0-1 knapsack problem and the set cover problem. Given m elements with nonnegative weights, n subsets of elements with nonnegative costs, and a total budget, BMCP aims to select some subsets such that the total cost of selected subsets does not exceed the budget, and the total we&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2202.03093v1-abstract-full').style.display = 'inline'; document.getElementById('2202.03093v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2202.03093v1-abstract-full" style="display: none;">
        We address the Budgeted Maximum Coverage Problem (BMCP), which is a natural and more practical extension of the standard 0-1 knapsack problem and the set cover problem. Given m elements with nonnegative weights, n subsets of elements with nonnegative costs, and a total budget, BMCP aims to select some subsets such that the total cost of selected subsets does not exceed the budget, and the total weight of associated elements is maximized. In this paper, we propose a variable depth local search algorithm (VDLS) for the BMCP. VDLS first generates an initial solution by a greedy algorithm, then iteratively improves the solution through a partial depth-first search method, that can improve the solution by simultaneously changing the states (selected or not) of multiple subsets. Such method allows VDLS to explore the solution space widely and deeply, and to yield high-quality solutions. We further propose a neighbour structure to boost the algorithm performance, that is, both subsets have a neighbour relation if they have at least one common associated element. By applying the neighbour structure, VDLS can adjust the selected subsets while losing as few covered elements as possible. Since the existing BMCP benchmarks only have simple structures and small scales, we design 60 new instances with relatively large scales and complex structures to enrich the diversity of the BMCP instances. Experimental results on 30 public instances and 60 new instances we designed demonstrate that VDLS significantly outperforms the existing heuristic and the general CPLEX exact solver, for the BMCP.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2202.03093v1-abstract-full').style.display = 'none'; document.getElementById('2202.03093v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 February, 2022; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2022.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2201.10049">arXiv:2201.10049</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2201.10049">pdf</a>, <a href="https://arxiv.org/format/2201.10049">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Data Structures and Algorithms">cs.DS</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        An Efficient Algorithm for the Partitioning Min-Max Weighted Matching Problem
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yuxuan Wang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Xie%2C+J">Jinyao Xie</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Zheng%2C+J">Jiongzhi Zheng</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=He%2C+K">Kun He</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2201.10049v1-abstract-short" style="display: inline;">
        The Partitioning Min-Max Weighted Matching (PMMWM) problem is an NP-hard problem that combines the problem of partitioning a group of vertices of a bipartite graph into disjoint subsets with limited size and the classical Min-Max Weighted Matching (MMWM) problem. Kress et al. proposed this problem in 2015 and they also provided several algorithms, among which MP$_{\text{LS}}$ is the state-of-the-a&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2201.10049v1-abstract-full').style.display = 'inline'; document.getElementById('2201.10049v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2201.10049v1-abstract-full" style="display: none;">
        The Partitioning Min-Max Weighted Matching (PMMWM) problem is an NP-hard problem that combines the problem of partitioning a group of vertices of a bipartite graph into disjoint subsets with limited size and the classical Min-Max Weighted Matching (MMWM) problem. Kress et al. proposed this problem in 2015 and they also provided several algorithms, among which MP$_{\text{LS}}$ is the state-of-the-art. In this work, we observe there is a time bottleneck in the matching phase of MP$_{\text{LS}}$. Hence, we optimize the redundant operations during the matching iterations, and propose an efficient algorithm called the MP$_{\text{KM-M}}$ that greatly speeds up MP$_{\text{LS}}$. The bottleneck time complexity is optimized from $O(n^3)$ to $O(n^2)$. We also prove the correctness of MP$_{\text{KM-M}}$ by the primal-dual method. To test the performance on diverse instances, we generate various types and sizes of benchmarks, and carried out an extensive computational study on the performance of MP$_{\text{KM-M}}$ and MP$_{\text{LS}}$. The evaluation results show that our MP$_{\text{KM-M}}$ greatly shortens the runtime as compared with MP$_{\text{LS}}$ while yielding the same solution quality.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2201.10049v1-abstract-full').style.display = 'none'; document.getElementById('2201.10049v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 24 January, 2022; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2022.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2201.08193">arXiv:2201.08193</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2201.08193">pdf</a>, <a href="https://arxiv.org/format/2201.08193">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Learning-based Hybrid Local Search for the Hard-label Textual Attack
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Yu%2C+Z">Zhen Yu</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Wang%2C+X">Xiaosen Wang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Che%2C+W">Wanxiang Che</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=He%2C+K">Kun He</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2201.08193v1-abstract-short" style="display: inline;">
        Deep neural networks are vulnerable to adversarial examples in Natural Language Processing. However, existing textual adversarial attacks usually utilize the gradient or prediction confidence to generate adversarial examples, making it hard to be deployed in real-world applications. To this end, we consider a rarely investigated but more rigorous setting, namely hard-label attack, in which the att&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2201.08193v1-abstract-full').style.display = 'inline'; document.getElementById('2201.08193v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2201.08193v1-abstract-full" style="display: none;">
        Deep neural networks are vulnerable to adversarial examples in Natural Language Processing. However, existing textual adversarial attacks usually utilize the gradient or prediction confidence to generate adversarial examples, making it hard to be deployed in real-world applications. To this end, we consider a rarely investigated but more rigorous setting, namely hard-label attack, in which the attacker could only access the prediction label. In particular, we find that the changes on prediction label caused by word substitutions on the adversarial example could precisely reflect the importance of different words. Based on this observation, we propose a novel hard-label attack, called Learning-based Hybrid Local Search (LHLS) algorithm, which effectively estimates word importance with the prediction label from the attack history and integrate such information into hybrid local search algorithm to optimize the adversarial perturbation. Extensive evaluations for text classification and textual entailment using various datasets and models show that our LHLS significantly outperforms existing hard-label attacks regarding the attack performance as well as adversary quality.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2201.08193v1-abstract-full').style.display = 'none'; document.getElementById('2201.08193v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 20 January, 2022; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2022.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">8 pages</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2201.06252">arXiv:2201.06252</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2201.06252">pdf</a>, <a href="https://arxiv.org/format/2201.06252">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Data Structures and Algorithms">cs.DS</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        A Strengthened Branch and Bound Algorithm for the Maximum Common (Connected) Subgraph Problem
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+J">Jianrong Zhou</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=He%2C+K">Kun He</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Zheng%2C+J">Jiongzhi Zheng</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Li%2C+C">Chu-Min Li</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yanli Liu</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2201.06252v1-abstract-short" style="display: inline;">
        We propose a new and strengthened Branch-and-Bound (BnB) algorithm for the maximum common (connected) induced subgraph problem based on two new operators, Long-Short Memory (LSM) and Leaf vertex Union Match (LUM). Given two graphs for which we search for the maximum common (connected) induced subgraph, the first operator of LSM maintains a score for the branching node using the short-term reward o&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2201.06252v1-abstract-full').style.display = 'inline'; document.getElementById('2201.06252v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2201.06252v1-abstract-full" style="display: none;">
        We propose a new and strengthened Branch-and-Bound (BnB) algorithm for the maximum common (connected) induced subgraph problem based on two new operators, Long-Short Memory (LSM) and Leaf vertex Union Match (LUM). Given two graphs for which we search for the maximum common (connected) induced subgraph, the first operator of LSM maintains a score for the branching node using the short-term reward of each vertex of the first graph and the long-term reward of each vertex pair of the two graphs. In this way, the BnB process learns to reduce the search tree size significantly and improve the algorithm performance. The second operator of LUM further improves the performance by simultaneously matching the leaf vertices connected to the current matched vertices, and allows the algorithm to match multiple vertex pairs without affecting the solution optimality. We incorporate the two operators into the state-of-the-art BnB algorithm McSplit, and denote the resulting algorithm as McSplit+LL. Experiments show that McSplit+LL outperforms McSplit+RL, a more recent variant of McSplit using reinforcement learning that is superior than McSplit.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2201.06252v1-abstract-full').style.display = 'none'; document.getElementById('2201.06252v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 17 January, 2022; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2022.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2201.05544">arXiv:2201.05544</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2201.05544">pdf</a>, <a href="https://arxiv.org/ps/2201.05544">ps</a>, <a href="https://arxiv.org/format/2201.05544">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        BandMaxSAT: A Local Search MaxSAT Solver with Multi-armed Bandit
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Zheng%2C+J">Jiongzhi Zheng</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=He%2C+K">Kun He</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+J">Jianrong Zhou</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Jin%2C+Y">Yan Jin</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Li%2C+C">Chu-min Li</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Manya%2C+F">Felip Manya</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2201.05544v1-abstract-short" style="display: inline;">
        We address Partial MaxSAT (PMS) and Weighted PMS (WPMS), two practical generalizations of the MaxSAT problem, and propose a local search algorithm called BandMaxSAT, that applies a multi-armed bandit to guide the search direction, for these problems. The bandit in our method is associated with all the soft clauses in the input (W)PMS instance. Each arm corresponds to a soft clause. The bandit mode&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2201.05544v1-abstract-full').style.display = 'inline'; document.getElementById('2201.05544v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2201.05544v1-abstract-full" style="display: none;">
        We address Partial MaxSAT (PMS) and Weighted PMS (WPMS), two practical generalizations of the MaxSAT problem, and propose a local search algorithm called BandMaxSAT, that applies a multi-armed bandit to guide the search direction, for these problems. The bandit in our method is associated with all the soft clauses in the input (W)PMS instance. Each arm corresponds to a soft clause. The bandit model can help BandMaxSAT to select a good direction to escape from local optima by selecting a soft clause to be satisfied in the current step, that is, selecting an arm to be pulled. We further propose an initialization method for (W)PMS that prioritizes both unit and binary clauses when producing the initial solutions. Extensive experiments demonstrate that BandMaxSAT significantly outperforms the state-of-the-art (W)PMS local search algorithm SATLike3.0. Specifically, the number of instances in which BandMaxSAT obtains better results is about twice that obtained by SATLike3.0. We further combine BandMaxSAT with the complete solver TT-Open-WBO-Inc. The resulting solver BandMaxSAT-c also outperforms some of the best state-of-the-art complete (W)PMS solvers, including SATLike-c, Loandra and TT-Open-WBO-Inc.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2201.05544v1-abstract-full').style.display = 'none'; document.getElementById('2201.05544v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 14 January, 2022; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2022.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2112.14356">arXiv:2112.14356</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2112.14356">pdf</a>, <a href="https://arxiv.org/ps/2112.14356">ps</a>, <a href="https://arxiv.org/format/2112.14356">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Theoretical Economics">econ.TH</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computer Science and Game Theory">cs.GT</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Probability">math.PR</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Private Private Information
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=He%2C+K">Kevin He</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Sandomirskiy%2C+F">Fedor Sandomirskiy</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Tamuz%2C+O">Omer Tamuz</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2112.14356v2-abstract-short" style="display: inline;">
        In a private private information structure, agents&#39; signals contain no information about the signals of their peers. We study how informative such structures can be, and characterize those that are on the Pareto frontier, in the sense that it is impossible to give more information to any agent without violating privacy. In our main application, we show how to optimally disclose information about a&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2112.14356v2-abstract-full').style.display = 'inline'; document.getElementById('2112.14356v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2112.14356v2-abstract-full" style="display: none;">
        In a private private information structure, agents&#39; signals contain no information about the signals of their peers. We study how informative such structures can be, and characterize those that are on the Pareto frontier, in the sense that it is impossible to give more information to any agent without violating privacy. In our main application, we show how to optimally disclose information about an unknown state under the constraint of not revealing anything about a correlated variable that contains sensitive information.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2112.14356v2-abstract-full').style.display = 'none'; document.getElementById('2112.14356v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 13 April, 2022; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 28 December, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2112.13709">arXiv:2112.13709</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2112.13709">pdf</a>, <a href="https://arxiv.org/format/2112.13709">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Active Learning with Pseudo-Labels for Multi-View 3D Pose Estimation
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Feng%2C+Q">Qi Feng</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=He%2C+K">Kun He</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Wen%2C+H">He Wen</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Keskin%2C+C">Cem Keskin</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Ye%2C+Y">Yuting Ye</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2112.13709v1-abstract-short" style="display: inline;">
        Pose estimation of the human body/hand is a fundamental problem in computer vision, and learning-based solutions require a large amount of annotated data. Given limited annotation budgets, a common approach to increasing label efficiency is Active Learning (AL), which selects examples with the highest value to annotate, but choosing the selection strategy is often nontrivial.
  In this work, we im&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2112.13709v1-abstract-full').style.display = 'inline'; document.getElementById('2112.13709v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2112.13709v1-abstract-full" style="display: none;">
        Pose estimation of the human body/hand is a fundamental problem in computer vision, and learning-based solutions require a large amount of annotated data. Given limited annotation budgets, a common approach to increasing label efficiency is Active Learning (AL), which selects examples with the highest value to annotate, but choosing the selection strategy is often nontrivial.
  In this work, we improve Active Learning for the problem of 3D pose estimation in a multi-view setting, which is of increasing importance in many application scenarios. We develop a framework that allows us to efficiently extend existing single-view AL strategies, and then propose two novel AL strategies that make full use of multi-view geometry. Moreover, we demonstrate additional performance gains by incorporating predicted pseudo-labels, which is a form of self-training. Our system significantly outperforms baselines in 3D body and hand pose estimation on two large-scale benchmarks: CMU Panoptic Studio and InterHand2.6M. Notably, on CMU Panoptic Studio, we are able to match the performance of a fully-supervised model using only 20% of labeled training data.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2112.13709v1-abstract-full').style.display = 'none'; document.getElementById('2112.13709v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 27 December, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Work done during internship at Meta Reality Labs</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2112.06569">arXiv:2112.06569</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2112.06569">pdf</a>, <a href="https://arxiv.org/format/2112.06569">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Triangle Attack: A Query-efficient Decision-based Adversarial Attack
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Wang%2C+X">Xiaosen Wang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zeliang Zhang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Tong%2C+K">Kangheng Tong</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Gong%2C+D">Dihong Gong</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=He%2C+K">Kun He</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Li%2C+Z">Zhifeng Li</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Liu%2C+W">Wei Liu</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2112.06569v1-abstract-short" style="display: inline;">
        Decision-based attack poses a severe threat to real-world applications since it regards the target model as a black box and only accesses the hard prediction label. Great efforts have been made recently to decrease the number of queries; however, existing decision-based attacks still require thousands of queries in order to generate good quality adversarial examples. In this work, we find that a b&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2112.06569v1-abstract-full').style.display = 'inline'; document.getElementById('2112.06569v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2112.06569v1-abstract-full" style="display: none;">
        Decision-based attack poses a severe threat to real-world applications since it regards the target model as a black box and only accesses the hard prediction label. Great efforts have been made recently to decrease the number of queries; however, existing decision-based attacks still require thousands of queries in order to generate good quality adversarial examples. In this work, we find that a benign sample, the current and the next adversarial examples could naturally construct a triangle in a subspace for any iterative attacks. Based on the law of sines, we propose a novel Triangle Attack (TA) to optimize the perturbation by utilizing the geometric information that the longer side is always opposite the larger angle in any triangle. However, directly applying such information on the input image is ineffective because it cannot thoroughly explore the neighborhood of the input sample in the high dimensional space. To address this issue, TA optimizes the perturbation in the low frequency space for effective dimensionality reduction owing to the generality of such geometric property. Extensive evaluations on the ImageNet dataset demonstrate that TA achieves a much higher attack success rate within 1,000 queries and needs a much less number of queries to achieve the same attack success rate under various perturbation budgets than existing decision-based attacks. With such high efficiency, we further demonstrate the applicability of TA on real-world API, i.e., Tencent Cloud API.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2112.06569v1-abstract-full').style.display = 'none'; document.getElementById('2112.06569v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 13 December, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">10 pages</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2112.04100">arXiv:2112.04100</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2112.04100">pdf</a>, <a href="https://arxiv.org/format/2112.04100">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Social and Information Networks">cs.SI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Uncovering the Local Hidden Community Structure in Social Networks
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Wang%2C+M">Meng Wang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Li%2C+B">Boyu Li</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=He%2C+K">Kun He</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Hopcroft%2C+J+E">John E. Hopcroft</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2112.04100v1-abstract-short" style="display: inline;">
        Hidden community is a useful concept proposed recently for social network analysis. To handle the rapid growth of network scale, in this work, we explore the detection of hidden communities from the local perspective, and propose a new method that detects and boosts each layer iteratively on a subgraph sampled from the original network. We first expand the seed set from a single seed node based on&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2112.04100v1-abstract-full').style.display = 'inline'; document.getElementById('2112.04100v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2112.04100v1-abstract-full" style="display: none;">
        Hidden community is a useful concept proposed recently for social network analysis. To handle the rapid growth of network scale, in this work, we explore the detection of hidden communities from the local perspective, and propose a new method that detects and boosts each layer iteratively on a subgraph sampled from the original network. We first expand the seed set from a single seed node based on our modified local spectral method and detect an initial dominant local community. Then we temporarily remove the members of this community as well as their connections to other nodes, and detect all the neighborhood communities in the remaining subgraph, including some &#34;broken communities&#34; that only contain a fraction of members in the original network. The local community and neighborhood communities form a dominant layer, and by reducing the edge weights inside these communities, we weaken this layer&#39;s structure to reveal the hidden layers. Eventually, we repeat the whole process and all communities containing the seed node can be detected and boosted iteratively. We theoretically show that our method can avoid some situations that a broken community and the local community are regarded as one community in the subgraph, leading to the inaccuracy on detection which can be caused by global hidden community detection methods. Extensive experiments show that our method could significantly outperform the state-of-the-art baselines designed for either global hidden community detection or multiple local community detection.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2112.04100v1-abstract-full').style.display = 'none'; document.getElementById('2112.04100v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 December, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">22 pages, 9 figures, submitted to a journal</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2111.11429">arXiv:2111.11429</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2111.11429">pdf</a>, <a href="https://arxiv.org/format/2111.11429">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Benchmarking Detection Transfer Learning with Vision Transformers
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Li%2C+Y">Yanghao Li</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Xie%2C+S">Saining Xie</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Chen%2C+X">Xinlei Chen</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Dollar%2C+P">Piotr Dollar</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=He%2C+K">Kaiming He</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Girshick%2C+R">Ross Girshick</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2111.11429v1-abstract-short" style="display: inline;">
        Object detection is a central downstream task used to test if pre-trained network parameters confer benefits, such as improved accuracy or training speed. The complexity of object detection methods can make this benchmarking non-trivial when new architectures, such as Vision Transformer (ViT) models, arrive. These difficulties (e.g., architectural incompatibility, slow training, high memory consum&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2111.11429v1-abstract-full').style.display = 'inline'; document.getElementById('2111.11429v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2111.11429v1-abstract-full" style="display: none;">
        Object detection is a central downstream task used to test if pre-trained network parameters confer benefits, such as improved accuracy or training speed. The complexity of object detection methods can make this benchmarking non-trivial when new architectures, such as Vision Transformer (ViT) models, arrive. These difficulties (e.g., architectural incompatibility, slow training, high memory consumption, unknown training formulae, etc.) have prevented recent studies from benchmarking detection transfer learning with standard ViT models. In this paper, we present training techniques that overcome these challenges, enabling the use of standard ViT models as the backbone of Mask R-CNN. These tools facilitate the primary goal of our study: we compare five ViT initializations, including recent state-of-the-art self-supervised learning methods, supervised initialization, and a strong random initialization baseline. Our results show that recent masking-based unsupervised learning methods may, for the first time, provide convincing transfer learning improvements on COCO, increasing box AP up to 4% (absolute) over supervised and prior self-supervised pre-training methods. Moreover, these masking-based initializations scale better, with the improvement growing as model size increases.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2111.11429v1-abstract-full').style.display = 'none'; document.getElementById('2111.11429v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 22 November, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2111.10752">arXiv:2111.10752</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2111.10752">pdf</a>, <a href="https://arxiv.org/format/2111.10752">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Cryptography and Security">cs.CR</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Stochastic Variance Reduced Ensemble Adversarial Attack for Boosting the Adversarial Transferability
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Xiong%2C+Y">Yifeng Xiong</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Lin%2C+J">Jiadong Lin</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+M">Min Zhang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Hopcroft%2C+J+E">John E. Hopcroft</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=He%2C+K">Kun He</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2111.10752v2-abstract-short" style="display: inline;">
        The black-box adversarial attack has attracted impressive attention for its practical use in the field of deep learning security. Meanwhile, it is very challenging as there is no access to the network architecture or internal weights of the target model. Based on the hypothesis that if an example remains adversarial for multiple models, then it is more likely to transfer the attack capability to o&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2111.10752v2-abstract-full').style.display = 'inline'; document.getElementById('2111.10752v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2111.10752v2-abstract-full" style="display: none;">
        The black-box adversarial attack has attracted impressive attention for its practical use in the field of deep learning security. Meanwhile, it is very challenging as there is no access to the network architecture or internal weights of the target model. Based on the hypothesis that if an example remains adversarial for multiple models, then it is more likely to transfer the attack capability to other models, the ensemble-based adversarial attack methods are efficient and widely used for black-box attacks. However, ways of ensemble attack are rather less investigated, and existing ensemble attacks simply fuse the outputs of all the models evenly. In this work, we treat the iterative ensemble attack as a stochastic gradient descent optimization process, in which the variance of the gradients on different models may lead to poor local optima. To this end, we propose a novel attack method called the stochastic variance reduced ensemble (SVRE) attack, which could reduce the gradient variance of the ensemble models and take full advantage of the ensemble attack. Empirical results on the standard ImageNet dataset demonstrate that the proposed method could boost the adversarial transferability and outperforms existing ensemble attacks significantly. Code is available at https://github.com/JHL-HUST/SVRE.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2111.10752v2-abstract-full').style.display = 'none'; document.getElementById('2111.10752v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 23 April, 2022; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 21 November, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">11 pages, 6 figures, accepted by CVPR 2022</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2111.08954">arXiv:2111.08954</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2111.08954">pdf</a>, <a href="https://arxiv.org/format/2111.08954">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        TraSw: Tracklet-Switch Adversarial Attacks against Multi-Object Tracking
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Lin%2C+D">Delv Lin</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Q">Qi Chen</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+C">Chengyu Zhou</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=He%2C+K">Kun He</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2111.08954v2-abstract-short" style="display: inline;">
        Multi-Object Tracking (MOT) has achieved aggressive progress and derives many excellent deep learning models. However, the robustness of the trackers is rarely studied, and it is challenging to attack the MOT system since its mature association algorithms are designed to be robust against errors during the tracking. In this work, we analyze the vulnerability of popular pedestrian MOT trackers and&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2111.08954v2-abstract-full').style.display = 'inline'; document.getElementById('2111.08954v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2111.08954v2-abstract-full" style="display: none;">
        Multi-Object Tracking (MOT) has achieved aggressive progress and derives many excellent deep learning models. However, the robustness of the trackers is rarely studied, and it is challenging to attack the MOT system since its mature association algorithms are designed to be robust against errors during the tracking. In this work, we analyze the vulnerability of popular pedestrian MOT trackers and propose a novel adversarial attack method called Tracklet-Switch (TraSw) against the complete tracking pipeline of MOT. TraSw can fool the advanced deep trackers (i.e., FairMOT and ByteTrack) to fail to track the targets in the subsequent frames by attacking very few frames. Experiments on the MOT-Challenge datasets (i.e., 2DMOT15, MOT17, and MOT20) show that TraSw can achieve an extraordinarily high success rate of over 95% by attacking only four frames on average. To our knowledge, this is the first work on the adversarial attack against pedestrian MOT trackers. The code is available at https://github.com/DerryHub/FairMOT-attack .
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2111.08954v2-abstract-full').style.display = 'none'; document.getElementById('2111.08954v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 10 March, 2022; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 17 November, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2111.06527">arXiv:2111.06527</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2111.06527">pdf</a>, <a href="https://arxiv.org/format/2111.06527">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Data Structures and Algorithms">cs.DS</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Moser-Tardos Algorithm: Beyond Shearer&#39;s Bound
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=He%2C+K">Kun He</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Li%2C+Q">Qian Li</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Sun%2C+X">Xiaoming Sun</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2111.06527v1-abstract-short" style="display: inline;">
        In a seminal paper (Moser and Tardos, JACM&#39;10), Moser and Tardos developed a simple and powerful algorithm to find solutions to combinatorial problems in the variable Lov{á}sz Local Lemma (LLL) setting. Kolipaka and Szegedy (STOC&#39;11) proved that the Moser-Tardos algorithm is efficient up to the tight condition of the abstract Lov{á}sz Local Lemma, known as Shearer&#39;s bound. A fundamental problem ar&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2111.06527v1-abstract-full').style.display = 'inline'; document.getElementById('2111.06527v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2111.06527v1-abstract-full" style="display: none;">
        In a seminal paper (Moser and Tardos, JACM&#39;10), Moser and Tardos developed a simple and powerful algorithm to find solutions to combinatorial problems in the variable Lov{á}sz Local Lemma (LLL) setting. Kolipaka and Szegedy (STOC&#39;11) proved that the Moser-Tardos algorithm is efficient up to the tight condition of the abstract Lov{á}sz Local Lemma, known as Shearer&#39;s bound. A fundamental problem around LLL is whether the efficient region of the Moser-Tardos algorithm can be further extended. In this paper, we give a positive answer to this problem. We show that the efficient region of the Moser-Tardos algorithm goes beyond the Shearer&#39;s bound of the underlying dependency graph, if the graph is not chordal. Otherwise, the dependency graph is chordal, and it has been shown that Shearer&#39;s bound exactly characterizes the efficient region for such graphs (Kolipaka and Szegedy, STOC&#39;11; He, Li, Liu, Wang and Xia, FOCS&#39;17). Moreover, we demonstrate that the efficient region can exceed Shearer&#39;s bound by a constant by explicitly calculating the gaps on several infinite lattices. The core of our proof is a new criterion on the efficiency of the Moser-Tardos algorithm which takes the intersection between dependent events into consideration. Our criterion is strictly better than Shearer&#39;s bound whenever the intersection exists between dependent events. Meanwhile, if any two dependent events are mutually exclusive, our criterion becomes the Shearer&#39;s bound, which is known to be tight in this situation for the Moser-Tardos algorithm (Kolipaka and Szegedy, STOC&#39;11; Guo, Jerrum and Liu, JACM&#39;19).
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2111.06527v1-abstract-full').style.display = 'none'; document.getElementById('2111.06527v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 11 November, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">32 pages</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2111.06377">arXiv:2111.06377</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2111.06377">pdf</a>, <a href="https://arxiv.org/format/2111.06377">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Masked Autoencoders Are Scalable Vision Learners
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=He%2C+K">Kaiming He</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Chen%2C+X">Xinlei Chen</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Xie%2C+S">Saining Xie</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Li%2C+Y">Yanghao Li</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Doll%C3%A1r%2C+P">Piotr Dollár</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Girshick%2C+R">Ross Girshick</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2111.06377v3-abstract-short" style="display: inline;">
        This paper shows that masked autoencoders (MAE) are scalable self-supervised learners for computer vision. Our MAE approach is simple: we mask random patches of the input image and reconstruct the missing pixels. It is based on two core designs. First, we develop an asymmetric encoder-decoder architecture, with an encoder that operates only on the visible subset of patches (without mask tokens), a&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2111.06377v3-abstract-full').style.display = 'inline'; document.getElementById('2111.06377v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2111.06377v3-abstract-full" style="display: none;">
        This paper shows that masked autoencoders (MAE) are scalable self-supervised learners for computer vision. Our MAE approach is simple: we mask random patches of the input image and reconstruct the missing pixels. It is based on two core designs. First, we develop an asymmetric encoder-decoder architecture, with an encoder that operates only on the visible subset of patches (without mask tokens), along with a lightweight decoder that reconstructs the original image from the latent representation and mask tokens. Second, we find that masking a high proportion of the input image, e.g., 75%, yields a nontrivial and meaningful self-supervisory task. Coupling these two designs enables us to train large models efficiently and effectively: we accelerate training (by 3x or more) and improve accuracy. Our scalable approach allows for learning high-capacity models that generalize well: e.g., a vanilla ViT-Huge model achieves the best accuracy (87.8%) among methods that use only ImageNet-1K data. Transfer performance in downstream tasks outperforms supervised pre-training and shows promising scaling behavior.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2111.06377v3-abstract-full').style.display = 'none'; document.getElementById('2111.06377v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 19 December, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 11 November, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Tech report. arXiv v2: add more transfer learning results; v3: add robustness evaluation</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2110.14972">arXiv:2110.14972</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2110.14972">pdf</a>, <a href="https://arxiv.org/ps/2110.14972">ps</a>, <a href="https://arxiv.org/format/2110.14972">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Social and Information Networks">cs.SI</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Streaming Local Community Detection through Approximate Conductance
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Yang%2C+Y">Yanhao Yang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Wang%2C+M">Meng Wang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Bindel%2C+D">David Bindel</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=He%2C+K">Kun He</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2110.14972v1-abstract-short" style="display: inline;">
        Community is a universal structure in various complex networks, and community detection is a fundamental task for network analysis. With the rapid growth of network scale, networks are massive, changing rapidly and could naturally be modeled as graph streams. Due to the limited memory and access constraint in graph streams, existing non-streaming community detection methods are no longer applicabl&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2110.14972v1-abstract-full').style.display = 'inline'; document.getElementById('2110.14972v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2110.14972v1-abstract-full" style="display: none;">
        Community is a universal structure in various complex networks, and community detection is a fundamental task for network analysis. With the rapid growth of network scale, networks are massive, changing rapidly and could naturally be modeled as graph streams. Due to the limited memory and access constraint in graph streams, existing non-streaming community detection methods are no longer applicable. This raises an emerging need for online approaches. In this work, we consider the problem of uncovering the local community containing a few query nodes in graph streams, termed streaming local community detection. This is a new problem raised recently that is more challenging for community detection and only a few works address this online setting. Correspondingly, we design an online single-pass streaming local community detection approach. Inspired by the &#34;local&#34; property of communities, our method samples the local structure around the query nodes in graph streams, and extracts the target community on the sampled subgraph using our proposed metric called the approximate conductance. Comprehensive experiments show that our method remarkably outperforms the streaming baseline on both effectiveness and efficiency, and even achieves similar accuracy comparing to the state-of-the-art non-streaming local community detection methods that use static and complete graphs.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2110.14972v1-abstract-full').style.display = 'none'; document.getElementById('2110.14972v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 28 October, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2110.12680">arXiv:2110.12680</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2110.12680">pdf</a>, <a href="https://arxiv.org/format/2110.12680">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        TODSum: Task-Oriented Dialogue Summarization with State Tracking
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+L">Lulu Zhao</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Zheng%2C+F">Fujia Zheng</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=He%2C+K">Keqing He</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Zeng%2C+W">Weihao Zeng</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Lei%2C+Y">Yuejie Lei</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+H">Huixing Jiang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Wu%2C+W">Wei Wu</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Xu%2C+W">Weiran Xu</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Guo%2C+J">Jun Guo</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Meng%2C+F">Fanyu Meng</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2110.12680v1-abstract-short" style="display: inline;">
        Previous dialogue summarization datasets mainly focus on open-domain chitchat dialogues, while summarization datasets for the broadly used task-oriented dialogue haven&#39;t been explored yet. Automatically summarizing such task-oriented dialogues can help a business collect and review needs to improve the service. Besides, previous datasets pay more attention to generate good summaries with higher RO&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2110.12680v1-abstract-full').style.display = 'inline'; document.getElementById('2110.12680v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2110.12680v1-abstract-full" style="display: none;">
        Previous dialogue summarization datasets mainly focus on open-domain chitchat dialogues, while summarization datasets for the broadly used task-oriented dialogue haven&#39;t been explored yet. Automatically summarizing such task-oriented dialogues can help a business collect and review needs to improve the service. Besides, previous datasets pay more attention to generate good summaries with higher ROUGE scores, but they hardly understand the structured information of dialogues and ignore the factuality of summaries. In this paper, we introduce a large-scale public Task-Oriented Dialogue Summarization dataset, TODSum, which aims to summarize the key points of the agent completing certain tasks with the user. Compared to existing work, TODSum suffers from severe scattered information issues and requires strict factual consistency, which makes it hard to directly apply recent dialogue summarization models. Therefore, we introduce additional dialogue state knowledge for TODSum to enhance the faithfulness of generated summaries. We hope a better understanding of conversational content helps summarization models generate concise and coherent summaries. Meanwhile, we establish a comprehensive benchmark for TODSum and propose a state-aware structured dialogue summarization model to integrate dialogue state information and dialogue history. Exhaustive experiments and qualitative analysis prove the effectiveness of dialogue structure guidance. Finally, we discuss the current issues of TODSum and potential development directions for future work.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2110.12680v1-abstract-full').style.display = 'none'; document.getElementById('2110.12680v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 25 October, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Preprint</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2110.03572">arXiv:2110.03572</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2110.03572">pdf</a>, <a href="https://arxiv.org/format/2110.03572">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Bridge to Target Domain by Prototypical Contrastive Learning and Label Confusion: Re-explore Zero-Shot Learning for Slot Filling
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Wang%2C+L">Liwen Wang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Li%2C+X">Xuefeng Li</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Liu%2C+J">Jiachi Liu</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=He%2C+K">Keqing He</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Yan%2C+Y">Yuanmeng Yan</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Xu%2C+W">Weiran Xu</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2110.03572v1-abstract-short" style="display: inline;">
        Zero-shot cross-domain slot filling alleviates the data dependence in the case of data scarcity in the target domain, which has aroused extensive research. However, as most of the existing methods do not achieve effective knowledge transfer to the target domain, they just fit the distribution of the seen slot and show poor performance on unseen slot in the target domain. To solve this, we propose&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2110.03572v1-abstract-full').style.display = 'inline'; document.getElementById('2110.03572v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2110.03572v1-abstract-full" style="display: none;">
        Zero-shot cross-domain slot filling alleviates the data dependence in the case of data scarcity in the target domain, which has aroused extensive research. However, as most of the existing methods do not achieve effective knowledge transfer to the target domain, they just fit the distribution of the seen slot and show poor performance on unseen slot in the target domain. To solve this, we propose a novel approach based on prototypical contrastive learning with a dynamic label confusion strategy for zero-shot slot filling. The prototypical contrastive learning aims to reconstruct the semantic constraints of labels, and we introduce the label confusion strategy to establish the label dependence between the source domains and the target domain on-the-fly. Experimental results show that our model achieves significant improvement on the unseen slots, while also set new state-of-the-arts on slot filling task.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2110.03572v1-abstract-full').style.display = 'none'; document.getElementById('2110.03572v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 October, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted by EMNLP 2021</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2109.05698">arXiv:2109.05698</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2109.05698">pdf</a>, <a href="https://arxiv.org/format/2109.05698">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Randomized Substitution and Vote for Textual Adversarial Example Detection
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Wang%2C+X">Xiaosen Wang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Xiong%2C+Y">Yifeng Xiong</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=He%2C+K">Kun He</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2109.05698v1-abstract-short" style="display: inline;">
        A line of work has shown that natural text processing models are vulnerable to adversarial examples. Correspondingly, various defense methods are proposed to mitigate the threat of textual adversarial examples, e.g. adversarial training, certified defense, input pre-processing, detection, etc. In this work, we treat the optimization process for synonym substitution based textual adversarial attack&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2109.05698v1-abstract-full').style.display = 'inline'; document.getElementById('2109.05698v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2109.05698v1-abstract-full" style="display: none;">
        A line of work has shown that natural text processing models are vulnerable to adversarial examples. Correspondingly, various defense methods are proposed to mitigate the threat of textual adversarial examples, e.g. adversarial training, certified defense, input pre-processing, detection, etc. In this work, we treat the optimization process for synonym substitution based textual adversarial attacks as a specific sequence of word replacement, in which each word mutually influences other words. We identify that we could destroy such mutual interaction and eliminate the adversarial perturbation by randomly substituting a word with its synonyms. Based on this observation, we propose a novel textual adversarial example detection method, termed Randomized Substitution and Vote (RS&amp;V), which votes the prediction label by accumulating the logits of k samples generated by randomly substituting the words in the input text with synonyms. The proposed RS&amp;V is generally applicable to any existing neural networks without modification on the architecture or extra training, and it is orthogonal to prior work on making the classification network itself more robust. Empirical evaluations on three benchmark datasets demonstrate that RS&amp;V could detect the textual adversarial examples more successfully than the existing detection methods while maintaining the high classification accuracy on benign samples.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2109.05698v1-abstract-full').style.display = 'none'; document.getElementById('2109.05698v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 13 September, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">8 pages</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2109.04101">arXiv:2109.04101</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2109.04101">pdf</a>, <a href="https://arxiv.org/format/2109.04101">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        TimeTraveler: Reinforcement Learning for Temporal Knowledge Graph Forecasting
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Sun%2C+H">Haohai Sun</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Zhong%2C+J">Jialun Zhong</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Ma%2C+Y">Yunpu Ma</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Han%2C+Z">Zhen Han</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=He%2C+K">Kun He</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2109.04101v1-abstract-short" style="display: inline;">
        Temporal knowledge graph (TKG) reasoning is a crucial task that has gained increasing research interest in recent years. Most existing methods focus on reasoning at past timestamps to complete the missing facts, and there are only a few works of reasoning on known TKGs to forecast future facts. Compared with the completion task, the forecasting task is more difficult that faces two main challenges&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2109.04101v1-abstract-full').style.display = 'inline'; document.getElementById('2109.04101v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2109.04101v1-abstract-full" style="display: none;">
        Temporal knowledge graph (TKG) reasoning is a crucial task that has gained increasing research interest in recent years. Most existing methods focus on reasoning at past timestamps to complete the missing facts, and there are only a few works of reasoning on known TKGs to forecast future facts. Compared with the completion task, the forecasting task is more difficult that faces two main challenges: (1) how to effectively model the time information to handle future timestamps? (2) how to make inductive inference to handle previously unseen entities that emerge over time? To address these challenges, we propose the first reinforcement learning method for forecasting. Specifically, the agent travels on historical knowledge graph snapshots to search for the answer. Our method defines a relative time encoding function to capture the timespan information, and we design a novel time-shaped reward based on Dirichlet distribution to guide the model learning. Furthermore, we propose a novel representation method for unseen entities to improve the inductive inference ability of the model. We evaluate our method for this link prediction task at future timestamps. Extensive experiments on four benchmark datasets demonstrate substantial performance improvement meanwhile with higher explainability, less calculation, and fewer parameters when compared with existing state-of-the-art methods.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2109.04101v1-abstract-full').style.display = 'none'; document.getElementById('2109.04101v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 9 September, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">EMNLP 2021</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2109.00678">arXiv:2109.00678</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2109.00678">pdf</a>, <a href="https://arxiv.org/format/2109.00678">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Regional Adversarial Training for Better Robust Generalization
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Song%2C+C">Chuanbiao Song</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Fan%2C+Y">Yanbo Fan</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Yang%2C+Y">Yichen Yang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Wu%2C+B">Baoyuan Wu</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Li%2C+Y">Yiming Li</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Li%2C+Z">Zhifeng Li</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=He%2C+K">Kun He</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2109.00678v2-abstract-short" style="display: inline;">
        Adversarial training (AT) has been demonstrated as one of the most promising defense methods against various adversarial attacks. To our knowledge, existing AT-based methods usually train with the locally most adversarial perturbed points and treat all the perturbed points equally, which may lead to considerably weaker adversarial robust generalization on test data. In this work, we introduce a ne&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2109.00678v2-abstract-full').style.display = 'inline'; document.getElementById('2109.00678v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2109.00678v2-abstract-full" style="display: none;">
        Adversarial training (AT) has been demonstrated as one of the most promising defense methods against various adversarial attacks. To our knowledge, existing AT-based methods usually train with the locally most adversarial perturbed points and treat all the perturbed points equally, which may lead to considerably weaker adversarial robust generalization on test data. In this work, we introduce a new adversarial training framework that considers the diversity as well as characteristics of the perturbed points in the vicinity of benign samples. To realize the framework, we propose a Regional Adversarial Training (RAT) defense method that first utilizes the attack path generated by the typical iterative attack method of projected gradient descent (PGD), and constructs an adversarial region based on the attack path. Then, RAT samples diverse perturbed training points efficiently inside this region, and utilizes a distance-aware label smoothing mechanism to capture our intuition that perturbed points at different locations should have different impact on the model performance. Extensive experiments on several benchmark datasets show that RAT consistently makes significant improvement on standard adversarial training (SAT), and exhibits better robust generalization.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2109.00678v2-abstract-full').style.display = 'none'; document.getElementById('2109.00678v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 3 September, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 1 September, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">10 pages, 8 figures, 4 tables</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2108.09988">arXiv:2108.09988</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2108.09988">pdf</a>, <a href="https://arxiv.org/ps/2108.09988">ps</a>, <a href="https://arxiv.org/format/2108.09988">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Farsighted Probabilistic Sampling: A General Strategy for Boosting MaxSAT Local Search Solvers
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Zheng%2C+J">Jiongzhi Zheng</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+J">Jianrong Zhou</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=He%2C+K">Kun He</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2108.09988v3-abstract-short" style="display: inline;">
        Local search has been demonstrated as an efficient approach for both Partial MaxSAT (PMS) and Weighted PMS (WPMS), denoted as (W)PMS, two practical generalizations to the typical combinatorial problem of MaxSAT. In this work, we observe that most (W)PMS local search solvers usually flip a single variable per iteration. Such a mechanism may lead to relatively low-quality local optimal solutions, an&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2108.09988v3-abstract-full').style.display = 'inline'; document.getElementById('2108.09988v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2108.09988v3-abstract-full" style="display: none;">
        Local search has been demonstrated as an efficient approach for both Partial MaxSAT (PMS) and Weighted PMS (WPMS), denoted as (W)PMS, two practical generalizations to the typical combinatorial problem of MaxSAT. In this work, we observe that most (W)PMS local search solvers usually flip a single variable per iteration. Such a mechanism may lead to relatively low-quality local optimal solutions, and may limit the diversity of the search directions to escape from local optima. To this end, we propose a general strategy called farsighted probabilistic sampling (FPS) to replace the single flipping mechanism to boost the (W)PMS local search algorithms. FPS considers the benefit of continuously flipping a pair of variables, so as to find higher-quality local optimal solutions. Moreover, FPS presents an effective approach to escape from local optima by preferring the best to flip among the best sampled single variable and the best sampled variable pair. Extensive experiments demonstrate that our proposed FPS strategy significantly improves the (W)PMS state-of-the-art (local search) solvers, and FPS has an excellent generalization to various (Max)SAT local search solvers.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2108.09988v3-abstract-full').style.display = 'none'; document.getElementById('2108.09988v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 14 January, 2022; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 23 August, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2108.06444">arXiv:2108.06444</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2108.06444">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Signal Processing">eess.SP</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        A New Entity Extraction Method Based on Machine Reading Comprehension
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+X">Xiaobo Jiang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=He%2C+K">Kun He</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=He%2C+J">Jiajun He</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Yan%2C+G">Guangyu Yan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2108.06444v2-abstract-short" style="display: inline;">
        Entity extraction is a key technology for obtaining information from massive texts in natural language processing. The further interaction between them does not meet the standards of human reading comprehension, thus limiting the understanding of the model, and also the omission or misjudgment of the answer (ie the target entity) due to the reasoning question. An effective MRC-based entity extract&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2108.06444v2-abstract-full').style.display = 'inline'; document.getElementById('2108.06444v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2108.06444v2-abstract-full" style="display: none;">
        Entity extraction is a key technology for obtaining information from massive texts in natural language processing. The further interaction between them does not meet the standards of human reading comprehension, thus limiting the understanding of the model, and also the omission or misjudgment of the answer (ie the target entity) due to the reasoning question. An effective MRC-based entity extraction model-MRC-I2DP, which uses the proposed gated attention-attracting mechanism to adjust the restoration of each part of the text pair, creating problems and thinking for multi-level interactive attention calculations to increase the target entity It also uses the proposed 2D probability coding module, TALU function and mask mechanism to strengthen the detection of all possible targets of the target, thereby improving the probability and accuracy of prediction. Experiments have proved that MRC-I2DP represents an overall state-of-the-art model in 7 from the scientific and public domains, achieving a performance improvement of up to compared to the model model in F1.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2108.06444v2-abstract-full').style.display = 'none'; document.getElementById('2108.06444v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 20 August, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 13 August, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2108.03203">arXiv:2108.03203</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2108.03203">pdf</a>, <a href="https://arxiv.org/format/2108.03203">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computational Geometry">cs.CG</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Adaptive Simulated Annealing with Greedy Search for the Circle Bin Packing Problem
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Yuan%2C+Y">Yong Yuan</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Tole%2C+K">Kevin Tole</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Ni%2C+F">Fei Ni</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=He%2C+K">Kun He</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Xiong%2C+Z">Zhengda Xiong</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Liu%2C+J">Jinfa Liu</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2108.03203v1-abstract-short" style="display: inline;">
        We introduce a new bin packing problem, termed the circle bin packing problem with circular items (CBPP-CI). The problem involves packing all the circular items into multiple identical circle bins as compact as possible with the objective of minimizing the number of used bins. We first define the tangent occupying action (TOA) and propose a constructive greedy algorithm that sequentially packs the&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2108.03203v1-abstract-full').style.display = 'inline'; document.getElementById('2108.03203v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2108.03203v1-abstract-full" style="display: none;">
        We introduce a new bin packing problem, termed the circle bin packing problem with circular items (CBPP-CI). The problem involves packing all the circular items into multiple identical circle bins as compact as possible with the objective of minimizing the number of used bins. We first define the tangent occupying action (TOA) and propose a constructive greedy algorithm that sequentially packs the items into places tangent to the packed items or the bin boundaries. Moreover, to avoid falling into a local minimum trap and efficiently judge whether an optimal solution has been established, we continue to present the adaptive simulated annealing with greedy search (ASA-GS) algorithm that explores and exploits the search space efficiently. Specifically, we offer two novel local perturbation strategies to jump out of the local optimum and incorporate the greedy search to achieve faster convergence. The parameters of ASA-GS are adaptive according to the number of items so that they can be size-agnostic across the problem scale. We design two sets of new benchmark instances, and the empirical results show that ASA-GS completely outperforms the constructive greedy algorithm. Moreover, the packing density of ASA-GS on the top few dense bins is much higher than that of the state-of-the-art algorithm for the single circle packing problem, inferring the high quality of the packing solutions for CBPP-CI.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2108.03203v1-abstract-full').style.display = 'none'; document.getElementById('2108.03203v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 6 August, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">14 pages, 8 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2108.00127">arXiv:2108.00127</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2108.00127">pdf</a>, <a href="https://arxiv.org/format/2108.00127">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Social and Information Networks">cs.SI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Structure Amplification on Multi-layer Stochastic Block Models
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Xin%2C+X">Xiaodong Xin</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=He%2C+K">Kun He</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Bao%2C+J">Jialu Bao</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Selman%2C+B">Bart Selman</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Hopcroft%2C+J+E">John E. Hopcroft</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2108.00127v1-abstract-short" style="display: inline;">
        Much of the complexity of social, biological, and engineered systems arises from a network of complex interactions connecting many basic components. Network analysis tools have been successful at uncovering latent structure termed communities in such networks. However, some of the most interesting structure can be difficult to uncover because it is obscured by the more dominant structure. Our prev&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2108.00127v1-abstract-full').style.display = 'inline'; document.getElementById('2108.00127v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2108.00127v1-abstract-full" style="display: none;">
        Much of the complexity of social, biological, and engineered systems arises from a network of complex interactions connecting many basic components. Network analysis tools have been successful at uncovering latent structure termed communities in such networks. However, some of the most interesting structure can be difficult to uncover because it is obscured by the more dominant structure. Our previous work proposes a general structure amplification technique called HICODE that uncovers many layers of functional hidden structure in complex networks. HICODE incrementally weakens dominant structure through randomization allowing the hidden functionality to emerge, and uncovers these hidden structure in real-world networks that previous methods rarely uncover. In this work, we conduct a comprehensive and systematic theoretical analysis on the hidden community structure. In what follows, we define multi-layer stochastic block model, and provide theoretical support using the model on why the existence of hidden structure will make the detection of dominant structure harder compared with equivalent random noise. We then provide theoretical proofs that the iterative reducing methods could help promote the uncovering of hidden structure as well as boosting the detection quality of dominant structure.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2108.00127v1-abstract-full').style.display = 'none'; document.getElementById('2108.00127v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 30 July, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">27 pages, 6 figures, 1 table, submitted to a journal</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2107.06870">arXiv:2107.06870</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2107.06870">pdf</a>, <a href="https://arxiv.org/format/2107.06870">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Neural and Evolutionary Computing">cs.NE</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Reinforced Hybrid Genetic Algorithm for the Traveling Salesman Problem
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Zheng%2C+J">Jiongzhi Zheng</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Zhong%2C+J">Jialun Zhong</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Chen%2C+M">Menglei Chen</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=He%2C+K">Kun He</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2107.06870v2-abstract-short" style="display: inline;">
        We propose a novel method called the Reinforced Hybrid Genetic Algorithm (RHGA) for solving the famous NP-hard Traveling Salesman Problem (TSP). Specifically, we combine a reinforcement learning technique with the well-known Edge Assembly Crossover genetic algorithm (EAX-GA) and the Lin-Kernighan-Helsgaun (LKH) local search heuristic. With the help of the proposed hybrid mechanism, the genetic evo&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2107.06870v2-abstract-full').style.display = 'inline'; document.getElementById('2107.06870v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2107.06870v2-abstract-full" style="display: none;">
        We propose a novel method called the Reinforced Hybrid Genetic Algorithm (RHGA) for solving the famous NP-hard Traveling Salesman Problem (TSP). Specifically, we combine a reinforcement learning technique with the well-known Edge Assembly Crossover genetic algorithm (EAX-GA) and the Lin-Kernighan-Helsgaun (LKH) local search heuristic. With the help of the proposed hybrid mechanism, the genetic evolution of EAX-GA and the local search of LKH can boost each other&#39;s performance. And the reinforcement learning technique based on Q-learning further promotes the hybrid genetic algorithm. Experimental results on 138 well-known and widely used TSP benchmarks with the number of cities ranging from 1,000 to 85,900 demonstrate the excellent performance of RHGA, that outperforms EAX-GA and LKH significantly.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2107.06870v2-abstract-full').style.display = 'none'; document.getElementById('2107.06870v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 6 November, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 9 July, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2107.03932">arXiv:2107.03932</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2107.03932">pdf</a>, <a href="https://arxiv.org/ps/2107.03932">ps</a>, <a href="https://arxiv.org/format/2107.03932">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Data Structures and Algorithms">cs.DS</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Discrete Mathematics">cs.DM</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Probability">math.PR</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Perfect Sampling for (Atomic) Lovász Local Lemma
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=He%2C+K">Kun He</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Sun%2C+X">Xiaoming Sun</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Wu%2C+K">Kewen Wu</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2107.03932v1-abstract-short" style="display: inline;">
        We give a Markov chain based perfect sampler for uniform sampling solutions of constraint satisfaction problems (CSP). Under some mild Lovász local lemma conditions where each constraint of the CSP has a small number of forbidden local configurations, our algorithm is accurate and efficient: it outputs a perfect uniform random solution and its expected running time is quasilinear in the number of&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2107.03932v1-abstract-full').style.display = 'inline'; document.getElementById('2107.03932v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2107.03932v1-abstract-full" style="display: none;">
        We give a Markov chain based perfect sampler for uniform sampling solutions of constraint satisfaction problems (CSP). Under some mild Lovász local lemma conditions where each constraint of the CSP has a small number of forbidden local configurations, our algorithm is accurate and efficient: it outputs a perfect uniform random solution and its expected running time is quasilinear in the number of variables. Prior to our work, perfect samplers are only shown to exist for CSPs under much more restrictive conditions (Guo, Jerrum, and Liu, JACM&#39;19).
  Our algorithm has two components:
  1. A simple perfect sampling algorithm using bounding chains (Huber, STOC&#39;98; Haggstrom and Nelander, Scandinavian Journal of Statistics&#39;99). This sampler is efficient if each variable domain is small.
  2. A simple but powerful state tensorization trick to reduce large domains to smaller ones. This trick is a generalization of state compression (Feng, He, and Yin, STOC&#39;21).
  The crux of our analysis is a simple information percolation argument which allows us to achieve bounds even beyond current best approximate samplers (Jain, Pham, and Vuong, ArXiv&#39;21).
  Previous related works either use intricate algorithms or need sophisticated analysis or even both. Thus we view the simplicity of both our algorithm and analysis as a strength of our work.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2107.03932v1-abstract-full').style.display = 'none'; document.getElementById('2107.03932v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 July, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">56 pages, 1 table, 5 figures, 9 algorithms</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2107.02451">arXiv:2107.02451</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2107.02451">pdf</a>, <a href="https://arxiv.org/format/2107.02451">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Integrating Large Circular Kernels into CNNs through Neural Architecture Search
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=He%2C+K">Kun He</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Li%2C+C">Chao Li</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Yang%2C+Y">Yixiao Yang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Huang%2C+G">Gao Huang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Hopcroft%2C+J+E">John E. Hopcroft</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2107.02451v4-abstract-short" style="display: inline;">
        The square kernel is a standard unit for contemporary CNNs, as it fits well on the tensor computation for convolution operation. However, the retinal ganglion cells in the biological visual system have approximately concentric receptive fields. Motivated by this observation, we propose to use circular kernel with a concentric and isotropic receptive field as an option for the convolution operation&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2107.02451v4-abstract-full').style.display = 'inline'; document.getElementById('2107.02451v4-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2107.02451v4-abstract-full" style="display: none;">
        The square kernel is a standard unit for contemporary CNNs, as it fits well on the tensor computation for convolution operation. However, the retinal ganglion cells in the biological visual system have approximately concentric receptive fields. Motivated by this observation, we propose to use circular kernel with a concentric and isotropic receptive field as an option for the convolution operation. We first propose a simple yet efficient implementation of the convolution using circular kernels, and empirically show the significant advantages of large circular kernels over the counterpart square kernels. We then expand the operation space of several typical Neural Architecture Search (NAS) methods with the convolutions of large circular kernels. The searched new neural architectures do contain large circular kernels and outperform the original searched models considerably. Our additional analysis also reveals that large circular kernels could help the model to be more robust to the rotated or sheared images due to their better rotation invariance. Our work shows the potential of designing new convolutional kernels for CNNs, bringing up the prospect of expanding the search space of NAS with new variants of convolutions.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2107.02451v4-abstract-full').style.display = 'none'; document.getElementById('2107.02451v4-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 April, 2022; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 6 July, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">20 pages, 10 figures, submitted to a conference</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.15357">arXiv:2106.15357</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.15357">pdf</a>, <a href="https://arxiv.org/format/2106.15357">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Multi-stage Optimization based Adversarial Training
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Wang%2C+X">Xiaosen Wang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Song%2C+C">Chuanbiao Song</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Wang%2C+L">Liwei Wang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=He%2C+K">Kun He</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.15357v1-abstract-short" style="display: inline;">
        In the field of adversarial robustness, there is a common practice that adopts the single-step adversarial training for quickly developing adversarially robust models. However, the single-step adversarial training is most likely to cause catastrophic overfitting, as after a few training epochs it will be hard to generate strong adversarial examples to continuously boost the adversarial robustness.&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.15357v1-abstract-full').style.display = 'inline'; document.getElementById('2106.15357v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.15357v1-abstract-full" style="display: none;">
        In the field of adversarial robustness, there is a common practice that adopts the single-step adversarial training for quickly developing adversarially robust models. However, the single-step adversarial training is most likely to cause catastrophic overfitting, as after a few training epochs it will be hard to generate strong adversarial examples to continuously boost the adversarial robustness. In this work, we aim to avoid the catastrophic overfitting by introducing multi-step adversarial examples during the single-step adversarial training. Then, to balance the large training overhead of generating multi-step adversarial examples, we propose a Multi-stage Optimization based Adversarial Training (MOAT) method that periodically trains the model on mixed benign examples, single-step adversarial examples, and multi-step adversarial examples stage by stage. In this way, the overall training overhead is reduced significantly, meanwhile, the model could avoid catastrophic overfitting. Extensive experiments on CIFAR-10 and CIFAR-100 datasets demonstrate that under similar amount of training overhead, the proposed MOAT exhibits better robustness than either single-step or multi-step adversarial training methods.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.15357v1-abstract-full').style.display = 'none'; document.getElementById('2106.15357v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 26 June, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">13 pages</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.09825">arXiv:2106.09825</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.09825">pdf</a>, <a href="https://arxiv.org/format/2106.09825">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Multiagent Systems">cs.MA</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Many Agent Reinforcement Learning Under Partial Observability
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=He%2C+K">Keyang He</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Doshi%2C+P">Prashant Doshi</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Banerjee%2C+B">Bikramjit Banerjee</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.09825v1-abstract-short" style="display: inline;">
        Recent renewed interest in multi-agent reinforcement learning (MARL) has generated an impressive array of techniques that leverage deep reinforcement learning, primarily actor-critic architectures, and can be applied to a limited range of settings in terms of observability and communication. However, a continuing limitation of much of this work is the curse of dimensionality when it comes to repre&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.09825v1-abstract-full').style.display = 'inline'; document.getElementById('2106.09825v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.09825v1-abstract-full" style="display: none;">
        Recent renewed interest in multi-agent reinforcement learning (MARL) has generated an impressive array of techniques that leverage deep reinforcement learning, primarily actor-critic architectures, and can be applied to a limited range of settings in terms of observability and communication. However, a continuing limitation of much of this work is the curse of dimensionality when it comes to representations based on joint actions, which grow exponentially with the number of agents. In this paper, we squarely focus on this challenge of scalability. We apply the key insight of action anonymity, which leads to permutation invariance of joint actions, to two recently presented deep MARL algorithms, MADDPG and IA2C, and compare these instantiations to another recent technique that leverages action anonymity, viz., mean-field MARL. We show that our instantiations can learn the optimal behavior in a broader class of agent networks than the mean-field method, using a recently introduced pragmatic domain.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.09825v1-abstract-full').style.display = 'none'; document.getElementById('2106.09825v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 17 June, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2105.14313">arXiv:2105.14313</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2105.14313">pdf</a>, <a href="https://arxiv.org/format/2105.14313">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Novel Slot Detection: A Benchmark for Discovering Unknown Slot Types in the Task-Oriented Dialogue System
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Wu%2C+Y">Yanan Wu</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Zeng%2C+Z">Zhiyuan Zeng</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=He%2C+K">Keqing He</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Xu%2C+H">Hong Xu</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Yan%2C+Y">Yuanmeng Yan</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+H">Huixing Jiang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Xu%2C+W">Weiran Xu</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2105.14313v1-abstract-short" style="display: inline;">
        Existing slot filling models can only recognize pre-defined in-domain slot types from a limited slot set. In the practical application, a reliable dialogue system should know what it does not know. In this paper, we introduce a new task, Novel Slot Detection (NSD), in the task-oriented dialogue system. NSD aims to discover unknown or out-of-domain slot types to strengthen the capability of a dialo&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.14313v1-abstract-full').style.display = 'inline'; document.getElementById('2105.14313v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2105.14313v1-abstract-full" style="display: none;">
        Existing slot filling models can only recognize pre-defined in-domain slot types from a limited slot set. In the practical application, a reliable dialogue system should know what it does not know. In this paper, we introduce a new task, Novel Slot Detection (NSD), in the task-oriented dialogue system. NSD aims to discover unknown or out-of-domain slot types to strengthen the capability of a dialogue system based on in-domain training data. Besides, we construct two public NSD datasets, propose several strong NSD baselines, and establish a benchmark for future work. Finally, we conduct exhaustive experiments and qualitative analysis to comprehend key challenges and provide new guidance for future directions.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.14313v1-abstract-full').style.display = 'none'; document.getElementById('2105.14313v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 29 May, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted by ACL2021</span>
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        ACL2021
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2105.14289">arXiv:2105.14289</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2105.14289">pdf</a>, <a href="https://arxiv.org/format/2105.14289">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Modeling Discriminative Representations for Out-of-Domain Detection with Supervised Contrastive Learning
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Zeng%2C+Z">Zhiyuan Zeng</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=He%2C+K">Keqing He</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Yan%2C+Y">Yuanmeng Yan</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Z">Zijun Liu</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Wu%2C+Y">Yanan Wu</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Xu%2C+H">Hong Xu</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+H">Huixing Jiang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Xu%2C+W">Weiran Xu</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2105.14289v1-abstract-short" style="display: inline;">
        Detecting Out-of-Domain (OOD) or unknown intents from user queries is essential in a task-oriented dialog system. A key challenge of OOD detection is to learn discriminative semantic features. Traditional cross-entropy loss only focuses on whether a sample is correctly classified, and does not explicitly distinguish the margins between categories. In this paper, we propose a supervised contrastive&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.14289v1-abstract-full').style.display = 'inline'; document.getElementById('2105.14289v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2105.14289v1-abstract-full" style="display: none;">
        Detecting Out-of-Domain (OOD) or unknown intents from user queries is essential in a task-oriented dialog system. A key challenge of OOD detection is to learn discriminative semantic features. Traditional cross-entropy loss only focuses on whether a sample is correctly classified, and does not explicitly distinguish the margins between categories. In this paper, we propose a supervised contrastive learning objective to minimize intra-class variance by pulling together in-domain intents belonging to the same class and maximize inter-class variance by pushing apart samples from different classes. Besides, we employ an adversarial augmentation mechanism to obtain pseudo diverse views of a sample in the latent space. Experiments on two public datasets prove the effectiveness of our method capturing discriminative representations for OOD detection.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.14289v1-abstract-full').style.display = 'none'; document.getElementById('2105.14289v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 29 May, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted by ACL2021</span>
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        ACL2021
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2105.07715">arXiv:2105.07715</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2105.07715">pdf</a>, <a href="https://arxiv.org/format/2105.07715">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Cross-Modality Brain Tumor Segmentation via Bidirectional Global-to-Local Unsupervised Domain Adaptation
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=He%2C+K">Kelei He</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Ji%2C+W">Wen Ji</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+T">Tao Zhou</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Li%2C+Z">Zhuoyuan Li</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Huo%2C+J">Jing Huo</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+X">Xin Zhang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Gao%2C+Y">Yang Gao</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Shen%2C+D">Dinggang Shen</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+B">Bing Zhang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+J">Junfeng Zhang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2105.07715v1-abstract-short" style="display: inline;">
        Accurate segmentation of brain tumors from multi-modal Magnetic Resonance (MR) images is essential in brain tumor diagnosis and treatment. However, due to the existence of domain shifts among different modalities, the performance of networks decreases dramatically when training on one modality and performing on another, e.g., train on T1 image while performing on T2 image, which is often required&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.07715v1-abstract-full').style.display = 'inline'; document.getElementById('2105.07715v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2105.07715v1-abstract-full" style="display: none;">
        Accurate segmentation of brain tumors from multi-modal Magnetic Resonance (MR) images is essential in brain tumor diagnosis and treatment. However, due to the existence of domain shifts among different modalities, the performance of networks decreases dramatically when training on one modality and performing on another, e.g., train on T1 image while performing on T2 image, which is often required in clinical applications. This also prohibits a network from being trained on labeled data and then transferred to unlabeled data from a different domain. To overcome this, unsupervised domain adaptation (UDA) methods provide effective solutions to alleviate the domain shift between labeled source data and unlabeled target data. In this paper, we propose a novel Bidirectional Global-to-Local (BiGL) adaptation framework under a UDA scheme. Specifically, a bidirectional image synthesis and segmentation module is proposed to segment the brain tumor using the intermediate data distributions generated for the two domains, which includes an image-to-image translator and a shared-weighted segmentation network. Further, a global-to-local consistency learning module is proposed to build robust representation alignments in an integrated way. Extensive experiments on a multi-modal brain MR benchmark dataset demonstrate that the proposed method outperforms several state-of-the-art unsupervised domain adaptation methods by a large margin, while a comprehensive ablation study validates the effectiveness of each key component. The implementation code of our method will be released at \url{https://github.com/KeleiHe/BiGL}.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.07715v1-abstract-full').style.display = 'none'; document.getElementById('2105.07715v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 17 May, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2104.14558">arXiv:2104.14558</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2104.14558">pdf</a>, <a href="https://arxiv.org/format/2104.14558">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        A Large-Scale Study on Unsupervised Spatiotemporal Representation Learning
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Feichtenhofer%2C+C">Christoph Feichtenhofer</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Fan%2C+H">Haoqi Fan</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Xiong%2C+B">Bo Xiong</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Girshick%2C+R">Ross Girshick</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=He%2C+K">Kaiming He</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2104.14558v1-abstract-short" style="display: inline;">
        We present a large-scale study on unsupervised spatiotemporal representation learning from videos. With a unified perspective on four recent image-based frameworks, we study a simple objective that can easily generalize all these methods to space-time. Our objective encourages temporally-persistent features in the same video, and in spite of its simplicity, it works surprisingly well across: (i) d&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.14558v1-abstract-full').style.display = 'inline'; document.getElementById('2104.14558v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2104.14558v1-abstract-full" style="display: none;">
        We present a large-scale study on unsupervised spatiotemporal representation learning from videos. With a unified perspective on four recent image-based frameworks, we study a simple objective that can easily generalize all these methods to space-time. Our objective encourages temporally-persistent features in the same video, and in spite of its simplicity, it works surprisingly well across: (i) different unsupervised frameworks, (ii) pre-training datasets, (iii) downstream datasets, and (iv) backbone architectures. We draw a series of intriguing observations from this study, e.g., we discover that encouraging long-spanned persistency can be effective even if the timespan is 60 seconds. In addition to state-of-the-art results in multiple benchmarks, we report a few promising cases in which unsupervised pre-training can outperform its supervised counterpart. Code is made available at https://github.com/facebookresearch/SlowFast
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.14558v1-abstract-full').style.display = 'none'; document.getElementById('2104.14558v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 29 April, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">CVPR 2021</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2104.07188">arXiv:2104.07188</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2104.07188">pdf</a>, <a href="https://arxiv.org/format/2104.07188">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Tabletop Object Rearrangement: Team ACRV&#39;s Entry to OCRTOC
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zheyu Zhang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Newbury%2C+R">Rhys Newbury</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=He%2C+K">Kerry He</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Martin%2C+S">Steven Martin</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Suddrey%2C+G">Gavin Suddrey</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Kwan%2C+J">Jun Kwan</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Corke%2C+P">Peter Corke</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Cosgun%2C+A">Akansel Cosgun</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2104.07188v1-abstract-short" style="display: inline;">
        Open Cloud Robot Table Organization Challenge (OCRTOC) is one of the most comprehensive cloud-based robotic manipulation competitions. It focuses on rearranging tabletop objects using vision as its primary sensing modality. In this extended abstract, we present our entry to the OCRTOC2020 and the key challenges the team has experienced.
        
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2104.07188v1-abstract-full" style="display: none;">
        Open Cloud Robot Table Organization Challenge (OCRTOC) is one of the most comprehensive cloud-based robotic manipulation competitions. It focuses on rearranging tabletop objects using vision as its primary sensing modality. In this extended abstract, we present our entry to the OCRTOC2020 and the key challenges the team has experienced.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.07188v1-abstract-full').style.display = 'none'; document.getElementById('2104.07188v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 14 April, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">ICRA 2021 Workshop on Cloud-Based Competitions and Benchmarks for Robotic Manipulation and Grasping</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2104.02057">arXiv:2104.02057</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2104.02057">pdf</a>, <a href="https://arxiv.org/format/2104.02057">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        An Empirical Study of Training Self-Supervised Vision Transformers
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Chen%2C+X">Xinlei Chen</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Xie%2C+S">Saining Xie</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=He%2C+K">Kaiming He</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2104.02057v4-abstract-short" style="display: inline;">
        This paper does not describe a novel method. Instead, it studies a straightforward, incremental, yet must-know baseline given the recent progress in computer vision: self-supervised learning for Vision Transformers (ViT). While the training recipes for standard convolutional networks have been highly mature and robust, the recipes for ViT are yet to be built, especially in the self-supervised scen&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.02057v4-abstract-full').style.display = 'inline'; document.getElementById('2104.02057v4-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2104.02057v4-abstract-full" style="display: none;">
        This paper does not describe a novel method. Instead, it studies a straightforward, incremental, yet must-know baseline given the recent progress in computer vision: self-supervised learning for Vision Transformers (ViT). While the training recipes for standard convolutional networks have been highly mature and robust, the recipes for ViT are yet to be built, especially in the self-supervised scenarios where training becomes more challenging. In this work, we go back to basics and investigate the effects of several fundamental components for training self-supervised ViT. We observe that instability is a major issue that degrades accuracy, and it can be hidden by apparently good results. We reveal that these results are indeed partial failure, and they can be improved when training is made more stable. We benchmark ViT results in MoCo v3 and several other self-supervised frameworks, with ablations in various aspects. We discuss the currently positive evidence as well as challenges and open questions. We hope that this work will provide useful data points and experience for future research.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.02057v4-abstract-full').style.display = 'none'; document.getElementById('2104.02057v4-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 16 August, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 5 April, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Camera-ready, ICCV 2021, Oral. Code: https://github.com/facebookresearch/moco-v3</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.15571">arXiv:2103.15571</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.15571">pdf</a>, <a href="https://arxiv.org/format/2103.15571">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Enhancing the Transferability of Adversarial Attacks through Variance Tuning
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Wang%2C+X">Xiaosen Wang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=He%2C+K">Kun He</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.15571v3-abstract-short" style="display: inline;">
        Deep neural networks are vulnerable to adversarial examples that mislead the models with imperceptible perturbations. Though adversarial attacks have achieved incredible success rates in the white-box setting, most existing adversaries often exhibit weak transferability in the black-box setting, especially under the scenario of attacking models with defense mechanisms. In this work, we propose a n&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.15571v3-abstract-full').style.display = 'inline'; document.getElementById('2103.15571v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.15571v3-abstract-full" style="display: none;">
        Deep neural networks are vulnerable to adversarial examples that mislead the models with imperceptible perturbations. Though adversarial attacks have achieved incredible success rates in the white-box setting, most existing adversaries often exhibit weak transferability in the black-box setting, especially under the scenario of attacking models with defense mechanisms. In this work, we propose a new method called variance tuning to enhance the class of iterative gradient based attack methods and improve their attack transferability. Specifically, at each iteration for the gradient calculation, instead of directly using the current gradient for the momentum accumulation, we further consider the gradient variance of the previous iteration to tune the current gradient so as to stabilize the update direction and escape from poor local optima. Empirical results on the standard ImageNet dataset demonstrate that our method could significantly improve the transferability of gradient-based adversarial attacks. Besides, our method could be used to attack ensemble models or be integrated with various input transformations. Incorporating variance tuning with input transformations on iterative gradient-based attacks in the multi-model setting, the integrated method could achieve an average success rate of 90.1% against nine advanced defense methods, improving the current best attack performance significantly by 85.1% . Code is available at https://github.com/JHL-HUST/VT.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.15571v3-abstract-full').style.display = 'none'; document.getElementById('2103.15571v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 13 August, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 29 March, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted by CVPR 2021</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.10609">arXiv:2103.10609</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.10609">pdf</a>, <a href="https://arxiv.org/format/2103.10609">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Boosting Adversarial Transferability through Enhanced Momentum
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/cs?searchtype=author&amp;query=Wang%2C+X">Xiaosen Wang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Lin%2C+J">Jiadong Lin</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Hu%2C+H">Han Hu</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=Wang%2C+J">Jingdong Wang</a>, 
      
      <a href="/search/cs?searchtype=author&amp;query=He%2C+K">Kun He</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.10609v1-abstract-short" style="display: inline;">
        Deep learning models are known to be vulnerable to adversarial examples crafted by adding human-imperceptible perturbations on benign images. Many existing adversarial attack methods have achieved great white-box attack performance, but exhibit low transferability when attacking other models. Various momentum iterative gradient-based methods are shown to be effective to improve the adversarial tra&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.10609v1-abstract-full').style.display = 'inline'; document.getElementById('2103.10609v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.10609v1-abstract-full" style="display: none;">
        Deep learning models are known to be vulnerable to adversarial examples crafted by adding human-imperceptible perturbations on benign images. Many existing adversarial attack methods have achieved great white-box attack performance, but exhibit low transferability when attacking other models. Various momentum iterative gradient-based methods are shown to be effective to improve the adversarial transferability. In what follows, we propose an enhanced momentum iterative gradient-based method to further enhance the adversarial transferability. Specifically, instead of only accumulating the gradient during the iterative process, we additionally accumulate the average gradient of the data points sampled in the gradient direction of the previous iteration so as to stabilize the update direction and escape from poor local maxima. Extensive experiments on the standard ImageNet dataset demonstrate that our method could improve the adversarial transferability of momentum-based methods by a large margin of 11.1% on average. Moreover, by incorporating with various input transformation methods, the adversarial transferability could be further improved significantly. We also attack several extra advanced defense models under the ensemble-model setting, and the enhancements are remarkable with at least 7.8% on average.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.10609v1-abstract-full').style.display = 'none'; document.getElementById('2103.10609v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 18 March, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">13 pages</span>
    </p>
    

    

    
  </li>

</ol>


  <nav class="pagination is-small is-centered breathe-horizontal" role="navigation" aria-label="pagination">
    
    <a href=""
      class="pagination-previous is-invisible">Previous
    </a>
    
    
      <a href="/search/?searchtype=author&amp;query=He%2C+K&amp;start=50"
        class="pagination-next" >Next
      </a>
    
    <ul class="pagination-list">

      <li>
        <a href="/search/?searchtype=author&amp;query=He%2C+K&amp;start=0"
          class="pagination-link is-current"
          aria-label="Goto page 1">1
        </a>
      </li>

      
        
        <li>
          <a href="/search/?searchtype=author&amp;query=He%2C+K&amp;start=50"
            class="pagination-link "
            aria-label="Page 2"
            aria-current="page">2
          </a>
        </li>
        
        <li>
          <a href="/search/?searchtype=author&amp;query=He%2C+K&amp;start=100"
            class="pagination-link "
            aria-label="Page 3"
            aria-current="page">3
          </a>
        </li>
        
        <li>
          <a href="/search/?searchtype=author&amp;query=He%2C+K&amp;start=150"
            class="pagination-link "
            aria-label="Page 4"
            aria-current="page">4
          </a>
        </li>
        
      
    </ul>
  </nav>
  

  


      <div class="is-hidden-tablet">
        <!-- feedback for mobile only -->
        <span class="help" style="display: inline-block;"><a href="https://github.com/arXiv/arxiv-search/releases">Search v0.5.6 released 2020-02-24</a>&nbsp;&nbsp;</span>
        <button class="button is-small" id="feedback-button">Feedback?</button>
      </div>
    </div>

  </main>
  <footer>
    
    <div class="columns is-desktop" role="navigation" aria-label="Secondary">
  <!-- MetaColumn 1 -->
  <div class="column">
    <div class="columns">
      <div class="column">
        <ul class="nav-spaced">
          <li><a href="https://arxiv.org/about">About</a></li>
          <li><a href="https://arxiv.org/help">Help</a></li>
        </ul>
      </div>
      <div class="column">
        <ul class="nav-spaced">
          <li>
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
            <a href="https://arxiv.org/help/contact"> Contact</a>
          </li>
          <li>
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
            <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
          </li>
        </ul>
      </div>
    </div>
  </div> <!-- end MetaColumn 1 -->
  <!-- MetaColumn 2 -->
  <div class="column">
    <div class="columns">
      <div class="column">
        <ul class="nav-spaced">
          <li><a href="https://arxiv.org/help/license">Copyright</a></li>
          <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
        </ul>
      </div>
      <div class="column sorry-app-links">
        <ul class="nav-spaced">
          <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
          <li>
            <p class="help">
              <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
              Get status notifications via
              <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
              or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
            </p>
          </li>
        </ul>
      </div>
    </div>
  </div> <!-- end MetaColumn 2 -->
</div>
    
  </footer>
  </body>
</html>