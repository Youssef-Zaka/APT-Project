<!DOCTYPE html>
<html lang="en-US">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<link rel="profile" href="http://gmpg.org/xfn/11">
<link rel="pingback" href="https://blog.gdeltproject.org/xmlrpc.php">
<title>What Google&#8217;s Cloud Video AI Sees Watching Decade Of Television News: The Visual Global Entity Graph 2.0 &#8211; The GDELT Project</title>
<meta name='robots' content='max-image-preview:large' />
<link rel='dns-prefetch' href='//fonts.googleapis.com' />
<link rel='dns-prefetch' href='//s.w.org' />
<link rel="alternate" type="application/rss+xml" title="The GDELT Project &raquo; Feed" href="https://blog.gdeltproject.org/feed/" />
<link rel="alternate" type="application/rss+xml" title="The GDELT Project &raquo; Comments Feed" href="https://blog.gdeltproject.org/comments/feed/" />
		<!-- This site uses the Google Analytics by MonsterInsights plugin v8.1.0 - Using Analytics tracking - https://www.monsterinsights.com/ -->
							<script src="//www.googletagmanager.com/gtag/js?id=UA-47450367-1"  type="text/javascript" data-cfasync="false" async></script>
			<script type="text/javascript" data-cfasync="false">
				var mi_version = '8.1.0';
				var mi_track_user = true;
				var mi_no_track_reason = '';
				
								var disableStrs = [
															'ga-disable-UA-47450367-1',
									];

				/* Function to detect opted out users */
				function __gtagTrackerIsOptedOut() {
					for ( var index = 0; index < disableStrs.length; index++ ) {
						if ( document.cookie.indexOf( disableStrs[ index ] + '=true' ) > -1 ) {
							return true;
						}
					}

					return false;
				}

				/* Disable tracking if the opt-out cookie exists. */
				if ( __gtagTrackerIsOptedOut() ) {
					for ( var index = 0; index < disableStrs.length; index++ ) {
						window[ disableStrs[ index ] ] = true;
					}
				}

				/* Opt-out function */
				function __gtagTrackerOptout() {
					for ( var index = 0; index < disableStrs.length; index++ ) {
						document.cookie = disableStrs[ index ] + '=true; expires=Thu, 31 Dec 2099 23:59:59 UTC; path=/';
						window[ disableStrs[ index ] ] = true;
					}
				}

				if ( 'undefined' === typeof gaOptout ) {
					function gaOptout() {
						__gtagTrackerOptout();
					}
				}
								window.dataLayer = window.dataLayer || [];

				window.MonsterInsightsDualTracker = {
					helpers: {},
					trackers: {},
				};
				if ( mi_track_user ) {
					function __gtagDataLayer() {
						dataLayer.push( arguments );
					}

					function __gtagTracker( type, name, parameters ) {
						if ( type === 'event' ) {
							
															parameters.send_to = monsterinsights_frontend.ua;
								__gtagDataLayer.apply( null, arguments );
													} else {
							__gtagDataLayer.apply( null, arguments );
						}
					}
					__gtagTracker( 'js', new Date() );
					__gtagTracker( 'set', {
						'developer_id.dZGIzZG' : true,
											} );
															__gtagTracker( 'config', 'UA-47450367-1', {"forceSSL":"true"} );
										window.gtag = __gtagTracker;										(
						function () {
							/* https://developers.google.com/analytics/devguides/collection/analyticsjs/ */
							/* ga and __gaTracker compatibility shim. */
							var noopfn = function () {
								return null;
							};
							var newtracker = function () {
								return new Tracker();
							};
							var Tracker = function () {
								return null;
							};
							var p = Tracker.prototype;
							p.get = noopfn;
							p.set = noopfn;
							p.send = function (){
								var args = Array.prototype.slice.call(arguments);
								args.unshift( 'send' );
								__gaTracker.apply(null, args);
							};
							var __gaTracker = function () {
								var len = arguments.length;
								if ( len === 0 ) {
									return;
								}
								var f = arguments[len - 1];
								if ( typeof f !== 'object' || f === null || typeof f.hitCallback !== 'function' ) {
									if ( 'send' === arguments[0] ) {
										var hitConverted, hitObject = false, action;
										if ( 'event' === arguments[1] ) {
											if ( 'undefined' !== typeof arguments[3] ) {
												hitObject = {
													'eventAction': arguments[3],
													'eventCategory': arguments[2],
													'eventLabel': arguments[4],
													'value': arguments[5] ? arguments[5] : 1,
												}
											}
										}
										if ( 'pageview' === arguments[1] ) {
											if ( 'undefined' !== typeof arguments[2] ) {
												hitObject = {
													'eventAction': 'page_view',
													'page_path' : arguments[2],
												}
											}
										}
										if ( typeof arguments[2] === 'object' ) {
											hitObject = arguments[2];
										}
										if ( typeof arguments[5] === 'object' ) {
											Object.assign( hitObject, arguments[5] );
										}
										if ( 'undefined' !== typeof arguments[1].hitType ) {
											hitObject = arguments[1];
											if ( 'pageview' === hitObject.hitType ) {
												hitObject.eventAction = 'page_view';
											}
										}
										if ( hitObject ) {
											action = 'timing' === arguments[1].hitType ? 'timing_complete' : hitObject.eventAction;
											hitConverted = mapArgs( hitObject );
											__gtagTracker( 'event', action, hitConverted );
										}
									}
									return;
								}

								function mapArgs( args ) {
									var arg, hit = {};
									var gaMap = {
										'eventCategory': 'event_category',
										'eventAction': 'event_action',
										'eventLabel': 'event_label',
										'eventValue': 'event_value',
										'nonInteraction': 'non_interaction',
										'timingCategory': 'event_category',
										'timingVar': 'name',
										'timingValue': 'value',
										'timingLabel': 'event_label',
										'page' : 'page_path',
										'location' : 'page_location',
										'title' : 'page_title',
									};
									for ( arg in args ) {
																				if ( ! ( ! args.hasOwnProperty(arg) || ! gaMap.hasOwnProperty(arg) ) ) {
											hit[gaMap[arg]] = args[arg];
										} else {
											hit[arg] = args[arg];
										}
									}
									return hit;
								}

								try {
									f.hitCallback();
								} catch ( ex ) {
								}
							};
							__gaTracker.create = newtracker;
							__gaTracker.getByName = newtracker;
							__gaTracker.getAll = function () {
								return [];
							};
							__gaTracker.remove = noopfn;
							__gaTracker.loaded = true;
							window['__gaTracker'] = __gaTracker;
						}
					)();
									} else {
										console.log( "" );
					( function () {
							function __gtagTracker() {
								return null;
							}
							window['__gtagTracker'] = __gtagTracker;
							window['gtag'] = __gtagTracker;
					} )();
									}
			</script>
				<!-- / Google Analytics by MonsterInsights -->
				<script type="text/javascript">
			window._wpemojiSettings = {"baseUrl":"https:\/\/s.w.org\/images\/core\/emoji\/13.1.0\/72x72\/","ext":".png","svgUrl":"https:\/\/s.w.org\/images\/core\/emoji\/13.1.0\/svg\/","svgExt":".svg","source":{"concatemoji":"https:\/\/blog.gdeltproject.org\/wp-includes\/js\/wp-emoji-release.min.js?ver=5.8.2"}};
			!function(e,a,t){var n,r,o,i=a.createElement("canvas"),p=i.getContext&&i.getContext("2d");function s(e,t){var a=String.fromCharCode;p.clearRect(0,0,i.width,i.height),p.fillText(a.apply(this,e),0,0);e=i.toDataURL();return p.clearRect(0,0,i.width,i.height),p.fillText(a.apply(this,t),0,0),e===i.toDataURL()}function c(e){var t=a.createElement("script");t.src=e,t.defer=t.type="text/javascript",a.getElementsByTagName("head")[0].appendChild(t)}for(o=Array("flag","emoji"),t.supports={everything:!0,everythingExceptFlag:!0},r=0;r<o.length;r++)t.supports[o[r]]=function(e){if(!p||!p.fillText)return!1;switch(p.textBaseline="top",p.font="600 32px Arial",e){case"flag":return s([127987,65039,8205,9895,65039],[127987,65039,8203,9895,65039])?!1:!s([55356,56826,55356,56819],[55356,56826,8203,55356,56819])&&!s([55356,57332,56128,56423,56128,56418,56128,56421,56128,56430,56128,56423,56128,56447],[55356,57332,8203,56128,56423,8203,56128,56418,8203,56128,56421,8203,56128,56430,8203,56128,56423,8203,56128,56447]);case"emoji":return!s([10084,65039,8205,55357,56613],[10084,65039,8203,55357,56613])}return!1}(o[r]),t.supports.everything=t.supports.everything&&t.supports[o[r]],"flag"!==o[r]&&(t.supports.everythingExceptFlag=t.supports.everythingExceptFlag&&t.supports[o[r]]);t.supports.everythingExceptFlag=t.supports.everythingExceptFlag&&!t.supports.flag,t.DOMReady=!1,t.readyCallback=function(){t.DOMReady=!0},t.supports.everything||(n=function(){t.readyCallback()},a.addEventListener?(a.addEventListener("DOMContentLoaded",n,!1),e.addEventListener("load",n,!1)):(e.attachEvent("onload",n),a.attachEvent("onreadystatechange",function(){"complete"===a.readyState&&t.readyCallback()})),(n=t.source||{}).concatemoji?c(n.concatemoji):n.wpemoji&&n.twemoji&&(c(n.twemoji),c(n.wpemoji)))}(window,document,window._wpemojiSettings);
		</script>
		<style type="text/css">
img.wp-smiley,
img.emoji {
	display: inline !important;
	border: none !important;
	box-shadow: none !important;
	height: 1em !important;
	width: 1em !important;
	margin: 0 .07em !important;
	vertical-align: -0.1em !important;
	background: none !important;
	padding: 0 !important;
}
</style>
	<link rel='stylesheet' id='wp-block-library-css'  href='https://blog.gdeltproject.org/wp-includes/css/dist/block-library/style.min.css?ver=5.8.2' type='text/css' media='all' />
<link rel='stylesheet' id='wp-pagenavi-css'  href='https://blog.gdeltproject.org/wp-content/themes/clean-grid-child/pagenavi-css.css?ver=2.70' type='text/css' media='all' />
<link rel='stylesheet' id='parent-style-css'  href='https://blog.gdeltproject.org/wp-content/themes/clean-grid/style.css?ver=5.8.2' type='text/css' media='all' />
<link crossorigin="anonymous" rel='stylesheet' id='wpb-google-fonts-css'  href='https://fonts.googleapis.com/css?family=Audiowide&#038;ver=5.8.2' type='text/css' media='all' />
<link rel='stylesheet' id='clean-grid-maincss-css'  href='https://blog.gdeltproject.org/wp-content/themes/clean-grid-child/style.css' type='text/css' media='all' />
<link rel='stylesheet' id='font-awesome-css'  href='https://blog.gdeltproject.org/wp-content/themes/clean-grid/assets/css/font-awesome.min.css' type='text/css' media='all' />
<link crossorigin="anonymous" rel='stylesheet' id='clean-grid-webfont-css'  href='//fonts.googleapis.com/css?family=Playfair+Display:400,400i,700,700i|Domine:400,700|Oswald:400,700' type='text/css' media='all' />
<script type='text/javascript' id='monsterinsights-frontend-script-js-extra'>
/* <![CDATA[ */
var monsterinsights_frontend = {"js_events_tracking":"true","download_extensions":"doc,pdf,ppt,zip,xls,docx,pptx,xlsx","inbound_paths":"[]","home_url":"https:\/\/blog.gdeltproject.org","hash_tracking":"false","ua":"UA-47450367-1","v4_id":""};
/* ]]> */
</script>
<script type='text/javascript' src='https://blog.gdeltproject.org/wp-content/plugins/google-analytics-for-wordpress/assets/js/frontend-gtag.min.js?ver=8.1.0' id='monsterinsights-frontend-script-js'></script>
<script type='text/javascript' src='https://blog.gdeltproject.org/wp-includes/js/jquery/jquery.min.js?ver=3.6.0' id='jquery-core-js'></script>
<script type='text/javascript' src='https://blog.gdeltproject.org/wp-includes/js/jquery/jquery-migrate.min.js?ver=3.3.2' id='jquery-migrate-js'></script>
<!--[if lt IE 9]>
<script type='text/javascript' src='https://blog.gdeltproject.org/wp-content/themes/clean-grid/assets/js/html5shiv.js' id='html5shiv-js'></script>
<![endif]-->
<!--[if lt IE 9]>
<script type='text/javascript' src='https://blog.gdeltproject.org/wp-content/themes/clean-grid/assets/js/respond.js' id='respond-js'></script>
<![endif]-->
<link rel="https://api.w.org/" href="https://blog.gdeltproject.org/wp-json/" /><link rel="alternate" type="application/json" href="https://blog.gdeltproject.org/wp-json/wp/v2/posts/9139" /><link rel="EditURI" type="application/rsd+xml" title="RSD" href="https://blog.gdeltproject.org/xmlrpc.php?rsd" />
<link rel="wlwmanifest" type="application/wlwmanifest+xml" href="https://blog.gdeltproject.org/wp-includes/wlwmanifest.xml" /> 
<meta name="generator" content="WordPress 5.8.2" />
<link rel="canonical" href="https://blog.gdeltproject.org/what-googles-cloud-video-ai-sees-watching-decade-of-television-news-the-visual-global-entity-graph-2-0/" />
<link rel='shortlink' href='https://blog.gdeltproject.org/?p=9139' />
<link rel="alternate" type="application/json+oembed" href="https://blog.gdeltproject.org/wp-json/oembed/1.0/embed?url=https%3A%2F%2Fblog.gdeltproject.org%2Fwhat-googles-cloud-video-ai-sees-watching-decade-of-television-news-the-visual-global-entity-graph-2-0%2F" />
<link rel="alternate" type="text/xml+oembed" href="https://blog.gdeltproject.org/wp-json/oembed/1.0/embed?url=https%3A%2F%2Fblog.gdeltproject.org%2Fwhat-googles-cloud-video-ai-sees-watching-decade-of-television-news-the-visual-global-entity-graph-2-0%2F&#038;format=xml" />
<style type="text/css" id="custom-background-css">
body.custom-background { background-image: url("https://blog.gdeltproject.org/wp-content/themes/clean-grid/assets/images/background.png"); background-position: left top; background-size: auto; background-repeat: repeat; background-attachment: fixed; }
</style>
	<link rel="amphtml" href="https://blog.gdeltproject.org/what-googles-cloud-video-ai-sees-watching-decade-of-television-news-the-visual-global-entity-graph-2-0/amp/"></head>

<body class="post-template-default single single-post postid-9139 single-format-standard custom-background clean-grid-animated clean-grid-fadein clean-grid-page-full-width" id="clean-grid-site-body" itemscope="itemscope" itemtype="http://schema.org/WebPage">

<div class="clean-grid-outer-wrapper-full">
<div class="clean-grid-outer-wrapper">

<div class="clean-grid-header clearfix" id="clean-grid-header" itemscope="itemscope" itemtype="http://schema.org/WPHeader" role="banner">
<div class="clean-grid-head-content clearfix" id="clean-grid-head-content">


<div class="clean-grid-header-inside clearfix">
<div class="clean-grid-logo" id="clean-grid-logo">
    <div class="site-branding">
      <h1 class="clean-grid-site-title"><a href="https://blog.gdeltproject.org/" rel="home">The GDELT Project</a></h1>
      <p class="clean-grid-site-description"></p>
    </div>
</div><!--/#clean-grid-logo -->

<div class="clean-grid-header-banner" id="clean-grid-header-banner">
</div><!--/#clean-grid-header-banner -->
</div>

</div><!--/#clean-grid-head-content -->
</div><!--/#clean-grid-header -->

<div class="clean-grid-menu-container clearfix">
<div class="clean-grid-menu-container-inside clearfix">

<nav class="clean-grid-nav-primary" id="clean-grid-primary-navigation" itemscope="itemscope" itemtype="http://schema.org/SiteNavigationElement" role="navigation">
<div class="menu-top-menu-container"><ul id="menu-primary-navigation" class="menu clean-grid-nav-menu menu-primary"><li id="menu-item-5278" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-5278"><a href="http://blog.gdeltproject.org/">The GDELT Project Blog</a></li>
<li id="menu-item-5349" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-5349"><a href="https://www.gdeltproject.org">Website</a></li>
</ul></div></nav>

<div class='clean-grid-top-social-icons'>
                                                                                                                                    <a href="http://blog.gdeltproject.org/feed/" target="_blank" class="clean-grid-social-icon-rss" title="RSS"><i class="fa fa-rss" aria-hidden="true"></i></a>    <a href="#" title="Search" class="clean-grid-social-search-icon"><i class="fa fa-search"></i></a>
</div>

<div class='clean-grid-social-search-box'>

<form role="search" method="get" class="clean-grid-search-form" action="https://blog.gdeltproject.org/">
<label>
    <span class="screen-reader-text">Search for:</span>
    <input type="search" class="clean-grid-search-field" placeholder="Search &hellip;" value="" name="s" />
</label>
<input type="submit" class="clean-grid-search-submit" value="Search" />
</form></div>

</div>
</div>


<div class="clean-grid-featured-posts-area clean-grid-top-wrapper clearfix">
</div>

<div class="clean-grid-wrapper clearfix" id="clean-grid-wrapper">
<div class="clean-grid-content-wrapper clearfix" id="clean-grid-content-wrapper">
<div class="clean-grid-main-wrapper clearfix" id="clean-grid-main-wrapper" itemscope="itemscope" itemtype="http://schema.org/Blog" role="main">
<div class="theiaStickySidebar">


<div class="clean-grid-featured-posts-area clearfix">
</div>

<div class="clean-grid-posts-wrapper" id="clean-grid-posts-wrapper">


    
<article id="post-9139" class="clean-grid-post-singular clean-grid-box post-9139 post type-post status-publish format-standard has-post-thumbnail hentry category-uncategorized wpcat-1-id">

    <header class="entry-header">
        
        <h1 class="post-title entry-title"><a href="https://blog.gdeltproject.org/what-googles-cloud-video-ai-sees-watching-decade-of-television-news-the-visual-global-entity-graph-2-0/" rel="bookmark">What Google's Cloud Video AI Sees Watching Decade Of Television News: The Visual Global Entity Graph 2.0</a></h1>
                <div class="clean-grid-entry-meta-single">
        <span class="clean-grid-entry-meta-single-date"><i class="fa fa-clock-o"></i>&nbsp;February 3, 2020</span>            </div>
        </header><!-- .entry-header -->

    <div class="entry-content clearfix">
                                        <a href="https://blog.gdeltproject.org/what-googles-cloud-video-ai-sees-watching-decade-of-television-news-the-visual-global-entity-graph-2-0/" title="Permanent Link to What Google&#039;s Cloud Video AI Sees Watching Decade Of Television News: The Visual Global Entity Graph 2.0"><img width="1064" height="410" src="https://blog.gdeltproject.org/wp-content/uploads/2020-vgeg-v2-1064x410.png" class="clean-grid-post-thumbnail-single wp-post-image" alt="" loading="lazy" srcset="https://blog.gdeltproject.org/wp-content/uploads/2020-vgeg-v2-1064x410.png 1064w, https://blog.gdeltproject.org/wp-content/uploads/2020-vgeg-v2-300x116.png 300w, https://blog.gdeltproject.org/wp-content/uploads/2020-vgeg-v2-1024x395.png 1024w, https://blog.gdeltproject.org/wp-content/uploads/2020-vgeg-v2-150x58.png 150w, https://blog.gdeltproject.org/wp-content/uploads/2020-vgeg-v2-768x296.png 768w, https://blog.gdeltproject.org/wp-content/uploads/2020-vgeg-v2-1536x592.png 1536w, https://blog.gdeltproject.org/wp-content/uploads/2020-vgeg-v2.png 1920w" sizes="(max-width: 1064px) 100vw, 1064px" /></a>
                <p><strong>UPDATE (8/7/2020): Thanks to a <a href="https://blog.gdeltproject.org/quantifying-the-covid-19-public-health-media-narrative-through-tv-radio-news-analysis/">Google Cloud COVID-19 Research Grant</a> to the Media-Data Research Consortium, this dataset has been vastly expanded to cover all of 2020 and major disease outbreaks of the past decade.</strong></p>
<p>What would it look like to have Google's state-of-the-art video understanding system <a href="https://cloud.google.com/video-intelligence/">Cloud Video AI</a> watch a decade of ABC, CBS and NBC evening television news broadcasts 2010-present and CNN from Jan. 25, 2020 to present and describe the visual objects and activities it sees second-by-second, constructing a non-consumptive chronology of the visual themes and narratives that have defined global events of the past decade? How do machines "see" the news and what does it look like to understand television news through their algorithmic eyes? What fundamentally new kinds of research and journalistic questions are possible when we for the first time have a rich non-consumptive visual index of television news?</p>
<p>Today we are incredibly excited to unveil the results: a powerful new non-consumptive visual chronology of almost 9,700 broadcasts totaling more than 18 million seconds of airtime, using Google’s <a href="https://cloud.google.com/video-intelligence/">Cloud Video API</a> to watch ten years of ABC, CBS and NBC evening news broadcasts from the Internet Archive’s <a href="https://archive.org/details/tv">Television News Archive</a> and updating every 30 minutes with a rolling 24 hour delay.</p>
<p>Despite its rich visual-first nature, television news today is primarily explored through the modality of text. The Internet Archive’s <a href="https://archive.org/details/tv">Television News Archive</a> has been a leader in this space, helping to popularize timecoded keyword search of closed captioning transcripts in the library context and exploring new <a href="https://api.gdeltproject.org/api/v2/summary/summary?d=iatv">research interfaces</a> to television. While these keyword search systems provide incredible opportunities for <a href="https://api.gdeltproject.org/api/v2/summary/summary?d=iatv">exploring coverage trends</a> and can be read by textual deep learning systems to <a href="https://blog.gdeltproject.org/a-deep-learning-powered-entity-graph-over-television-news-2009-2019/">catalog the things and themes</a> they mention, at the end of the day, the very visual world that separates television from radio and the online world is absent from such analyses.</p>
<p>At the same time, the last few years have brought profound advances in machine vision, with algorithmic visual understanding moving from the research lab to production everyday use. What would it look like to have a state-of-the-art machine learning system watch a decade of television news broadcasts across “the big three” networks and catalog their visual themes?</p>
<p>Over the past several years we've explored how AI can help us better understand the visual world of television. During the 2016 election we converted all <a href="https://blog.gdeltproject.org/computers-watching-ads-deep-learning-meets-campaign-2016/">267 campaign ads</a> monitored by the Archive into <a href="https://blog.gdeltproject.org/computers-watching-ads-deep-learning-meets-campaign-2016/">still image sequences</a> and had Google's Cloud Vision API <a href="https://www.washingtonpost.com/news/monkey-cage/wp/2016/02/08/what-does-artificial-intelligence-see-when-it-watches-political-ads/">catalog their visual narratives</a>. Last year we used Google's <a href="https://cloud.google.com/video-intelligence/">Cloud Video</a>, <a href="https://cloud.google.com/vision/">Vision</a>, <a href="https://cloud.google.com/speech-to-text/">Speech to Text</a> and <a href="https://cloud.google.com/natural-language/">Natural Language</a> APIs to <a href="https://blog.gdeltproject.org/ai-watching-television-news-deep-learning-meets-a-week-of-television/">watch a week</a> of television news from CNN, MSNBC, Fox News and the morning and evening ABC, CBS, NBC and PBS broadcasts, releasing more than <a href="https://blog.gdeltproject.org/ai-watching-television-news-deep-learning-meets-a-week-of-television/">600GB of annotations</a> that were used to <a href="https://www.forbes.com/sites/kalevleetaru/2019/09/03/a-look-back-at-how-googles-ai-sees-a-week-of-television-news-and-the-world-of-ai-video-understanding/">explore a wide range of questions</a> about just what it is we see when we turn on our televisions. We've even explored having Google's Cloud Natural Language API "watch" <a href="https://blog.gdeltproject.org/a-deep-learning-powered-entity-graph-over-television-news-2009-2019/">270,000 hours of television news</a> by reading their closed captioning spoken word transcripts and compiling the entities mentioned within. In December we released an <a href="https://blog.gdeltproject.org/machines-watching-television-news-a-visual-entity-graph-over-evening-news-broadcasts-2010-2019/">initial prototype</a> of the <a href="https://blog.gdeltproject.org/machines-watching-television-news-a-visual-entity-graph-over-evening-news-broadcasts-2010-2019/">Visual Global Entity Graph 1.0</a> and the lessons we've learned from that dataset have been used to create this massive new 2.0 release, which will also now update daily!</p>
<p>To explore what it would look like to understand a decade of television news through AI, the half-hour evening television news broadcasts of ABC, CBS and NBC from July 2010 through present and CNN from January 25, 2020 through present from the Internet Archive’s <a href="https://archive.org/details/tv">Television News Archive</a> were analyzed within a restricted access non-consumptive computational digital reference library using Google’s <a href="https://cloud.google.com/video-intelligence/">Cloud Video API</a>, including its <a href="https://cloud.google.com/video-intelligence/docs/analyze-labels">labeling feature</a> in which it visually analyzes each second of footage and assigns a list of predefined labels describing the objects and activities depicted within.</p>
<p>The end result is a list of the visual themes (primarily objects and activities) found in each broadcast by second, charting its visual narratives. Such a chronology offers a powerful and unique counterpart to the <a href="https://blog.gdeltproject.org/a-deep-learning-powered-entity-graph-over-television-news-2009-2019/">textual chronology</a> of its closed captioning, allowing researchers for the first time to consider the visual dimension of television news.</p>
<p>What are the visual themes that are associated with the key narratives and events of the past decade? Through combining with the <a href="https://blog.gdeltproject.org/a-deep-learning-powered-entity-graph-over-television-news-2009-2019/">captioning chronology</a>, it becomes possible to examine what kinds of imagery is typically depicted onscreen when a given topic is discussed and how that imagery has changed over the years. Longitudinal questions such as the amount of coverage by month over the past decade devoted to civil mobilizations like protests can also be explored for the first time. This enables an entirely new approach to understanding visual narratives by using machines to sift through vast archives of video.</p>
<p>Perhaps most importantly, this new dataset will allow researchers to explore for the first time how a better understanding of the visual dimensions of news might help combat the spread of falsehoods and better assess the diffusion of contested narratives and inorganic campaigns. What might we learn from the rich visual processes of broadcast journalism that could be applied to help increase trust in digital journalism and contextualize the news in ways that combats misunderstanding and falsehood?</p>
<p>The dataset consists of one file per broadcast, running from July 15, 2010 through present (with a 24-72 hour rolling delay). Each file is in newline delimited JSON format, with each row representing one second of broadcast airtime and containing an array of all of the visual entities identified by the Video API from that second.</p>
<p>This raw non-consumptive dataset is intended for those with data science backgrounds comfortable with processing raw JSON data. We are in the process of constructing a user-friendly interface to this data to support researchers and journalists in their explorations of it, so stay tuned!</p>
<h3>DETECTION MODEL CHANGES</h3>
<ul>
<li>All videos have been processed using the "v1" endpoint with "builtin/latest" model and "stationarycamera" false.</li>
</ul>
<p>The original dataset released on February 3, 2020 contained annotations produced through two different models. The videos annotated November 2019 through January 29, 2020 had been annotated using the "v1p3beta1" endpoint with the "builtin/stable" model and "stationarycamera" true, while videos after that were annotated with the "v1" endpoint with the "builtin/latest" model and "stationarycamera" set to false. The use of a stationary camera setting for earlier broadcasts was due to the assumption that this would provide better results since a considerable amount of television news footage is filmed either in a fixed studio setting or using a fixed stationary tripod-mounted camera in the field. Experimentally we determined that television news footage actually contains a lot more moving camera footage than expected and that the setting did not provide meaningful improvements in detection accuracy for the specific characteristics of television news. One unintended consequence of using a stationary camera setting for this earlier content is that detection labels could be propagated across brief scene changes. For example, if a scene features elephants in a landscape and then briefly cuts to a commentator for a few seconds and then back to the elephants, the results may still list "elephant" as a detected entity during that brief commentator cutover for videos annotated with this setting. This created a discontinuity with some labels showing profound changes across this boundary.</p>
<p>To address this, as of February 28, 2020 we have replaced the original dataset, including the raw and processed JSON files and the BigQuery table with a new reprocessed dataset in which the entire set of videos were all annotated using the same "v1" endpoint with "builtin/latest" model and "stationarycamera" false. All videos have now been annotated using the exact same model, so results will be continuous over the complete decade-long collection of videos.</p>
<h3>RAW VISUAL API OUTPUT</h3>
<p>For those interested in the raw visual output (includes all visual-related annotations, but not speech recognition) produced by the Cloud Video API for each video, those files are also <a href="https://blog.gdeltproject.org/visual-global-entity-graph-2-0-raw-full-resolution-api-output-now-available/">now available for download</a>. They offer annotations at the frame level recorded in nanoseconds, enabling fundamentally new kinds of analyses.</p>
<h3>TECHNICAL REFERENCE</h3>
<p>Each second of airtime appears as its own row with the following fields:</p>
<ul>
<li><strong>date</strong>. The date and time in UTC of a specific second of a given broadcast.</li>
<li><strong>showOffset</strong>. The offset in seconds of the given second since the beginning of the broadcast. For example, the moment 2 minutes and 4 seconds into a broadcast would have a value of 124 here.</li>
<li><strong>iaShowId</strong>. The unique identifier assigned by the Internet Archive to this broadcast.</li>
<li><strong>station</strong>. The station on which this broadcast aired.</li>
<li><strong>showName</strong>. The human-readable name of the show.</li>
<li><strong>iaClipUrl</strong>. The URL of the Internet Archive's Television News Archive page to view a one-minute clip of this broadcast that begins with this second of airtime. Note that seconds within the last 10 seconds of the end of a broadcast may require manual adjustment to an early timecode in some cases due to limitations of the Archive's online clip player.</li>
<li><strong>iaThumbnailUrl</strong>. The URL of a 320 x 240 pixel (actual height adjusted to maintain aspect ratio) thumbnail image of the opening frame of this second of airtime. Note that this frame may not be representative of the <a href="https://blog.gdeltproject.org/video-ai-the-trade-offs-of-translating-frame-level-annotations-into-per-second-aggregations/">full range of visual narratives</a> present in the given second of airtime and thus users should consult the thumbnail images before and after a given frame for further information and utilize the iaClipURL above for dead reckoning. For those interested in the technical details, thumbnails are created using ffmpeg using the command "cat VIDEO | ffmpeg -hide_banner -loglevel panic -f mp4 -i pipe: -vf "fps=1,scale=320:-1" -start_number 0 ./FILENAME-%6d.jpg".</li>
<li><strong>processedDate</strong>. The date and time in UTC that the clip was processed through Google's Cloud Video API. Like all AI systems, Google's Video API is constantly improving, meaning that the same video might yield slightly different results when run at a later time due to improvements in the underlying models. In particular, since we are using the "v1/latest" model, the results here will reflect the API's steady stream of improvements. To assist users in understanding whether an unexpected change over a given time period could be the result of underlying model changes, we include the processing date of each video that can be reconciled against the Video API's model updates.</li>
<li><strong>numOCRChars</strong>. The total number of characters of text identified through OCR. The Video API performs <a href="https://cloud.google.com/video-intelligence/docs/text-detection">per-frame OCR</a>, which for the purposes of simplification we collapse to the second level, in keeping with the Archive's chyron data.</li>
<li><strong>OCRText</strong>. The complete inventory of all onscreen text recognized by the Video API. Unlike the chyrons dataset, this field contains not just "lower third" text but rather the totality of all onscreen text. Note that this text may include words in multiple languages, including languages not ordinarily expected in the broadcast, such as <a href="https://blog.gdeltproject.org/multilingual-ocr-from-evening-television-news-arabic-on-abc/">Arabic text</a> in the midst of an ABC broadcast.</li>
<li><strong>numShotChanges</strong>. The Video API identifies the number of <a href="https://cloud.google.com/video-intelligence/docs/analyze-shots">scene/camera transitions</a>.</li>
<li><strong>shotID</strong>. The Video API identifies each scene/camera transition. We assign a unique identifier to each scene, incremented with each transition, allowing you to group together all of the seconds that make up a given "shot".</li>
<li><strong>numSpeakerChanges</strong>. Using the Video API’s “video” speech transcription model with <a href="https://cloud.google.com/video-intelligence/docs/transcription">speaker diarization</a> enabled, we count the number of speaker transitions each minute.</li>
<li><strong>numSpokenWords</strong>. Using the Video API’s “video” speech transcription model, we count the total number of <a href="https://cloud.google.com/video-intelligence/docs/transcription">words spoken</a> each minute.</li>
<li><strong>numDistinctEntities</strong>. The total number of unique <a href="https://cloud.google.com/video-intelligence/docs/analyze-labels">visual entities</a> (called “<a href="https://cloud.google.com/video-intelligence/docs/analyze-labels">labels</a>” in the Video API’s parlance) identified during the given second of airtime. Multiple appearances of a given entity in the given second of airtime will be recorded as a single entry.</li>
<li><strong>entities</strong>. A JSON array containing the list of distinct visual entities identified by the API for this minute of this broadcast. Multiple appearances of the same entity during this minute will be recorded as a single entry.
<ul>
<li><strong>name</strong>. The human name of this visual entity such as “land vehicle” or “city.”</li>
<li><strong>mid</strong>. Provides the unique Google-assigned ID of this visual entity. More information about these can be requested from the <a href="https://developers.google.com/knowledge-graph/">Google Knowledge Graph Search API</a>.</li>
<li><strong>confidence</strong>. The "confidence" score the API assigned to this entity being seen in this second of airtime.</li>
<li><strong>categories</strong>. An optional JSON array containing a list of distinct visual entities that represent the parent category headings for this entity in the overall visual taxonomy used by the Video API. For example, the entity “circle” will have “shape” in its categories list, representing that under Google’s taxonomy, a “circle” is a kind of “shape.” Not all entities have corresponding parent categories and some may have multiple parents categories.
<ul>
<li><strong>name</strong>. The human name of this visual entity such as “land vehicle” or “city.”</li>
<li><strong>mid</strong>. Provides the unique Google-assigned ID of this visual entity.</li>
</ul>
</li>
</ul>
</li>
<li><strong>numDistinctPresenceEntities</strong>. The total number of unique "presence" entities. This field is only present for videos processed after January 30, 2020. According to Google's <a href="https://cloud.google.com/video-intelligence/docs/reference/rest/v1/AnnotateVideoResponse">documentation</a>, "Compared to the existing topical shotLabelAnnotations, this field presents more fine-grained, shot-level labels detected in video content."
<ul>
<li><strong>name</strong>. The human name of this visual entity such as “land vehicle” or “city.”</li>
<li><strong>mid</strong>. Provides the unique Google-assigned ID of this visual entity. More information about these can be requested from the <a href="https://developers.google.com/knowledge-graph/">Google Knowledge Graph Search API</a>.</li>
<li><strong>confidence</strong>. The "confidence" score the API assigned to this entity being seen in this second of airtime.</li>
<li><strong>categories</strong>. An optional JSON array containing a list of distinct visual entities that represent the parent category headings for this entity in the overall visual taxonomy used by the Video API. For example, the entity “circle” will have “shape” in its categories list, representing that under Google’s taxonomy, a “circle” is a kind of “shape.” Not all entities have corresponding parent categories and some may have multiple parents categories.
<ul>
<li><strong>name</strong>. The human name of this visual entity such as “land vehicle” or “city.”</li>
<li><strong>mid</strong>. Provides the unique Google-assigned ID of this visual entity.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3>DOWNLOAD</h3>
<p>To determine which shows are available, a daily inventory file is available in the format YYYYMMDD from July 1, 2009 through present that lists all of the files for that day. For example, for June 1, 2020 the file would be:</p>
<ul>
<li>http://data.gdeltproject.org/gdeltv3/iatv/vgegv2/20200601.txt</li>
</ul>
<p>The inventory files for the most recent 72 hours are updated throughout the day as shows complete processing.</p>
<p>The complete dataset is also available in BigQuery:</p>
<ul>
<li><a href="https://console.cloud.google.com/bigquery?project=gdelt-bq&amp;folder&amp;organizationId&amp;p=gdelt-bq&amp;d=gdeltv2&amp;t=vgegv2_iatv&amp;page=table">gdelt-bq.gdeltv2.vgegv2_iatv</a></li>
</ul>
<p>The <a href="https://blog.gdeltproject.org/visual-global-entity-graph-2-0-raw-full-resolution-api-output-now-available/">complete raw visual API output</a> is also available, with the files listed in the daily inventory files above.</p>
<p>Note that this is a preliminary dataset that may be missing some shows or have null or incomplete values for some fields. We are excited to explore this dataset alongside of you to learn how we can use machines to peer for the first time into the visual world of the news. Remember that this dataset was constructed entirely by machine, so you will undoubtedly encounter errors and all labels are the result of algorithmic decision, not human editorialization.</p>
<p>Stay tuned for a series of analyses and a human-friendly research interface to this data coming shortly!</p>
<p>We’re tremendously excited to see the kinds of advanced multimodal visual analyses you’re able to do with this powerful new non-consumptive dataset!</p>
    </div><!-- .entry-content -->

    <footer class="entry-footer">
            </footer><!-- .entry-footer -->

    
</article>
    
	<nav class="navigation post-navigation" role="navigation" aria-label="Posts">
		<h2 class="screen-reader-text">Post navigation</h2>
		<div class="nav-links"><div class="nav-previous"><a href="https://blog.gdeltproject.org/washpost-fox-news-begins-and-ends-its-super-bowl-coverage-the-same-way-getting-trumps-back/" rel="prev">&larr; WashPost: Fox News Begins And Ends Its Super Bowl Coverage The Same Way: Getting Trump's Back</a></div><div class="nav-next"><a href="https://blog.gdeltproject.org/bluedots-alerting-system-sent-one-of-the-earliest-coronavirus-alerts/" rel="next">BlueDot's Alerting System Sent One Of The Earliest Coronavirus Alerts &rarr;</a></div></div>
	</nav>
    
<div class="clear"></div>

</div><!--/#clean-grid-posts-wrapper -->


<div class="clean-grid-featured-posts-area clearfix">
</div>

</div>
</div><!-- /#clean-grid-main-wrapper -->


<div class="clean-grid-sidebar-wrapper clearfix" id="clean-grid-sidebar-wrapper" itemscope="itemscope" itemtype="http://schema.org/WPSideBar" role="complementary">
<div class="theiaStickySidebar">


</div>
</div><!-- /#clean-grid-sidebar-wrapper-->

</div><!--/#clean-grid-content-wrapper -->
</div><!--/#clean-grid-wrapper -->



<div class='clean-grid-footer-blocks clearfix' id='clean-grid-footer-blocks' itemscope='itemscope' itemtype='http://schema.org/WPFooter' role='contentinfo'>
<div class='clearfix'>

<div class='clean-grid-footer-block-1'>
<div id="archives-8" class="clean-grid-footer-widget widget widget_archive"><h2 class="clean-grid-widget-title"><span>Archives</span></h2>		<label class="screen-reader-text" for="archives-dropdown-8">Archives</label>
		<select id="archives-dropdown-8" name="archive-dropdown">
			
			<option value="">Select Month</option>
				<option value='https://blog.gdeltproject.org/2021/12/'> December 2021 </option>
	<option value='https://blog.gdeltproject.org/2021/11/'> November 2021 </option>
	<option value='https://blog.gdeltproject.org/2021/10/'> October 2021 </option>
	<option value='https://blog.gdeltproject.org/2021/09/'> September 2021 </option>
	<option value='https://blog.gdeltproject.org/2021/08/'> August 2021 </option>
	<option value='https://blog.gdeltproject.org/2021/07/'> July 2021 </option>
	<option value='https://blog.gdeltproject.org/2021/06/'> June 2021 </option>
	<option value='https://blog.gdeltproject.org/2021/05/'> May 2021 </option>
	<option value='https://blog.gdeltproject.org/2021/04/'> April 2021 </option>
	<option value='https://blog.gdeltproject.org/2021/03/'> March 2021 </option>
	<option value='https://blog.gdeltproject.org/2021/02/'> February 2021 </option>
	<option value='https://blog.gdeltproject.org/2021/01/'> January 2021 </option>
	<option value='https://blog.gdeltproject.org/2020/12/'> December 2020 </option>
	<option value='https://blog.gdeltproject.org/2020/11/'> November 2020 </option>
	<option value='https://blog.gdeltproject.org/2020/10/'> October 2020 </option>
	<option value='https://blog.gdeltproject.org/2020/09/'> September 2020 </option>
	<option value='https://blog.gdeltproject.org/2020/08/'> August 2020 </option>
	<option value='https://blog.gdeltproject.org/2020/07/'> July 2020 </option>
	<option value='https://blog.gdeltproject.org/2020/06/'> June 2020 </option>
	<option value='https://blog.gdeltproject.org/2020/05/'> May 2020 </option>
	<option value='https://blog.gdeltproject.org/2020/04/'> April 2020 </option>
	<option value='https://blog.gdeltproject.org/2020/03/'> March 2020 </option>
	<option value='https://blog.gdeltproject.org/2020/02/'> February 2020 </option>
	<option value='https://blog.gdeltproject.org/2020/01/'> January 2020 </option>
	<option value='https://blog.gdeltproject.org/2019/12/'> December 2019 </option>
	<option value='https://blog.gdeltproject.org/2019/11/'> November 2019 </option>
	<option value='https://blog.gdeltproject.org/2019/10/'> October 2019 </option>
	<option value='https://blog.gdeltproject.org/2019/09/'> September 2019 </option>
	<option value='https://blog.gdeltproject.org/2019/08/'> August 2019 </option>
	<option value='https://blog.gdeltproject.org/2019/07/'> July 2019 </option>
	<option value='https://blog.gdeltproject.org/2019/06/'> June 2019 </option>
	<option value='https://blog.gdeltproject.org/2019/05/'> May 2019 </option>
	<option value='https://blog.gdeltproject.org/2019/04/'> April 2019 </option>
	<option value='https://blog.gdeltproject.org/2019/03/'> March 2019 </option>
	<option value='https://blog.gdeltproject.org/2019/02/'> February 2019 </option>
	<option value='https://blog.gdeltproject.org/2019/01/'> January 2019 </option>
	<option value='https://blog.gdeltproject.org/2018/12/'> December 2018 </option>
	<option value='https://blog.gdeltproject.org/2018/11/'> November 2018 </option>
	<option value='https://blog.gdeltproject.org/2018/10/'> October 2018 </option>
	<option value='https://blog.gdeltproject.org/2018/09/'> September 2018 </option>
	<option value='https://blog.gdeltproject.org/2018/08/'> August 2018 </option>
	<option value='https://blog.gdeltproject.org/2018/07/'> July 2018 </option>
	<option value='https://blog.gdeltproject.org/2018/06/'> June 2018 </option>
	<option value='https://blog.gdeltproject.org/2018/05/'> May 2018 </option>
	<option value='https://blog.gdeltproject.org/2018/04/'> April 2018 </option>
	<option value='https://blog.gdeltproject.org/2018/03/'> March 2018 </option>
	<option value='https://blog.gdeltproject.org/2018/02/'> February 2018 </option>
	<option value='https://blog.gdeltproject.org/2018/01/'> January 2018 </option>
	<option value='https://blog.gdeltproject.org/2017/12/'> December 2017 </option>
	<option value='https://blog.gdeltproject.org/2017/11/'> November 2017 </option>
	<option value='https://blog.gdeltproject.org/2017/10/'> October 2017 </option>
	<option value='https://blog.gdeltproject.org/2017/09/'> September 2017 </option>
	<option value='https://blog.gdeltproject.org/2017/08/'> August 2017 </option>
	<option value='https://blog.gdeltproject.org/2017/07/'> July 2017 </option>
	<option value='https://blog.gdeltproject.org/2017/06/'> June 2017 </option>
	<option value='https://blog.gdeltproject.org/2017/05/'> May 2017 </option>
	<option value='https://blog.gdeltproject.org/2017/04/'> April 2017 </option>
	<option value='https://blog.gdeltproject.org/2017/03/'> March 2017 </option>
	<option value='https://blog.gdeltproject.org/2017/02/'> February 2017 </option>
	<option value='https://blog.gdeltproject.org/2017/01/'> January 2017 </option>
	<option value='https://blog.gdeltproject.org/2016/12/'> December 2016 </option>
	<option value='https://blog.gdeltproject.org/2016/11/'> November 2016 </option>
	<option value='https://blog.gdeltproject.org/2016/10/'> October 2016 </option>
	<option value='https://blog.gdeltproject.org/2016/09/'> September 2016 </option>
	<option value='https://blog.gdeltproject.org/2016/08/'> August 2016 </option>
	<option value='https://blog.gdeltproject.org/2016/07/'> July 2016 </option>
	<option value='https://blog.gdeltproject.org/2016/06/'> June 2016 </option>
	<option value='https://blog.gdeltproject.org/2016/05/'> May 2016 </option>
	<option value='https://blog.gdeltproject.org/2016/04/'> April 2016 </option>
	<option value='https://blog.gdeltproject.org/2016/03/'> March 2016 </option>
	<option value='https://blog.gdeltproject.org/2016/02/'> February 2016 </option>
	<option value='https://blog.gdeltproject.org/2016/01/'> January 2016 </option>
	<option value='https://blog.gdeltproject.org/2015/12/'> December 2015 </option>
	<option value='https://blog.gdeltproject.org/2015/11/'> November 2015 </option>
	<option value='https://blog.gdeltproject.org/2015/10/'> October 2015 </option>
	<option value='https://blog.gdeltproject.org/2015/09/'> September 2015 </option>
	<option value='https://blog.gdeltproject.org/2015/08/'> August 2015 </option>
	<option value='https://blog.gdeltproject.org/2015/07/'> July 2015 </option>
	<option value='https://blog.gdeltproject.org/2015/06/'> June 2015 </option>
	<option value='https://blog.gdeltproject.org/2015/05/'> May 2015 </option>
	<option value='https://blog.gdeltproject.org/2015/04/'> April 2015 </option>
	<option value='https://blog.gdeltproject.org/2015/03/'> March 2015 </option>
	<option value='https://blog.gdeltproject.org/2015/02/'> February 2015 </option>
	<option value='https://blog.gdeltproject.org/2015/01/'> January 2015 </option>
	<option value='https://blog.gdeltproject.org/2014/12/'> December 2014 </option>
	<option value='https://blog.gdeltproject.org/2014/11/'> November 2014 </option>
	<option value='https://blog.gdeltproject.org/2014/10/'> October 2014 </option>
	<option value='https://blog.gdeltproject.org/2014/09/'> September 2014 </option>
	<option value='https://blog.gdeltproject.org/2014/08/'> August 2014 </option>
	<option value='https://blog.gdeltproject.org/2014/07/'> July 2014 </option>
	<option value='https://blog.gdeltproject.org/2014/06/'> June 2014 </option>
	<option value='https://blog.gdeltproject.org/2014/05/'> May 2014 </option>
	<option value='https://blog.gdeltproject.org/2014/04/'> April 2014 </option>
	<option value='https://blog.gdeltproject.org/2014/03/'> March 2014 </option>
	<option value='https://blog.gdeltproject.org/2014/02/'> February 2014 </option>
	<option value='https://blog.gdeltproject.org/2014/01/'> January 2014 </option>
	<option value='https://blog.gdeltproject.org/2013/12/'> December 2013 </option>
	<option value='https://blog.gdeltproject.org/2013/11/'> November 2013 </option>
	<option value='https://blog.gdeltproject.org/2013/10/'> October 2013 </option>
	<option value='https://blog.gdeltproject.org/2013/09/'> September 2013 </option>
	<option value='https://blog.gdeltproject.org/2013/08/'> August 2013 </option>
	<option value='https://blog.gdeltproject.org/2013/07/'> July 2013 </option>
	<option value='https://blog.gdeltproject.org/2013/06/'> June 2013 </option>
	<option value='https://blog.gdeltproject.org/2013/05/'> May 2013 </option>
	<option value='https://blog.gdeltproject.org/2013/04/'> April 2013 </option>
	<option value='https://blog.gdeltproject.org/2013/03/'> March 2013 </option>
	<option value='https://blog.gdeltproject.org/2013/02/'> February 2013 </option>
	<option value='https://blog.gdeltproject.org/2013/01/'> January 2013 </option>
	<option value='https://blog.gdeltproject.org/2012/12/'> December 2012 </option>
	<option value='https://blog.gdeltproject.org/2012/11/'> November 2012 </option>
	<option value='https://blog.gdeltproject.org/2012/10/'> October 2012 </option>
	<option value='https://blog.gdeltproject.org/2012/09/'> September 2012 </option>
	<option value='https://blog.gdeltproject.org/2012/08/'> August 2012 </option>
	<option value='https://blog.gdeltproject.org/2012/07/'> July 2012 </option>
	<option value='https://blog.gdeltproject.org/2012/06/'> June 2012 </option>
	<option value='https://blog.gdeltproject.org/2012/05/'> May 2012 </option>
	<option value='https://blog.gdeltproject.org/2012/04/'> April 2012 </option>
	<option value='https://blog.gdeltproject.org/2011/12/'> December 2011 </option>
	<option value='https://blog.gdeltproject.org/2011/11/'> November 2011 </option>
	<option value='https://blog.gdeltproject.org/2011/10/'> October 2011 </option>
	<option value='https://blog.gdeltproject.org/2011/09/'> September 2011 </option>
	<option value='https://blog.gdeltproject.org/2011/08/'> August 2011 </option>
	<option value='https://blog.gdeltproject.org/2011/07/'> July 2011 </option>
	<option value='https://blog.gdeltproject.org/2011/05/'> May 2011 </option>
	<option value='https://blog.gdeltproject.org/2011/04/'> April 2011 </option>
	<option value='https://blog.gdeltproject.org/2011/03/'> March 2011 </option>
	<option value='https://blog.gdeltproject.org/2010/11/'> November 2010 </option>
	<option value='https://blog.gdeltproject.org/2010/09/'> September 2010 </option>
	<option value='https://blog.gdeltproject.org/2010/08/'> August 2010 </option>
	<option value='https://blog.gdeltproject.org/2010/06/'> June 2010 </option>
	<option value='https://blog.gdeltproject.org/2010/03/'> March 2010 </option>
	<option value='https://blog.gdeltproject.org/2009/11/'> November 2009 </option>
	<option value='https://blog.gdeltproject.org/2009/10/'> October 2009 </option>
	<option value='https://blog.gdeltproject.org/2009/07/'> July 2009 </option>
	<option value='https://blog.gdeltproject.org/2009/05/'> May 2009 </option>
	<option value='https://blog.gdeltproject.org/2009/01/'> January 2009 </option>
	<option value='https://blog.gdeltproject.org/2008/11/'> November 2008 </option>
	<option value='https://blog.gdeltproject.org/2008/10/'> October 2008 </option>
	<option value='https://blog.gdeltproject.org/2008/07/'> July 2008 </option>
	<option value='https://blog.gdeltproject.org/2008/04/'> April 2008 </option>
	<option value='https://blog.gdeltproject.org/2008/01/'> January 2008 </option>
	<option value='https://blog.gdeltproject.org/2007/10/'> October 2007 </option>
	<option value='https://blog.gdeltproject.org/2007/07/'> July 2007 </option>
	<option value='https://blog.gdeltproject.org/2006/06/'> June 2006 </option>
	<option value='https://blog.gdeltproject.org/2006/05/'> May 2006 </option>
	<option value='https://blog.gdeltproject.org/2006/01/'> January 2006 </option>
	<option value='https://blog.gdeltproject.org/2005/12/'> December 2005 </option>
	<option value='https://blog.gdeltproject.org/2005/09/'> September 2005 </option>
	<option value='https://blog.gdeltproject.org/2005/05/'> May 2005 </option>
	<option value='https://blog.gdeltproject.org/2005/01/'> January 2005 </option>
	<option value='https://blog.gdeltproject.org/2004/07/'> July 2004 </option>
	<option value='https://blog.gdeltproject.org/2004/06/'> June 2004 </option>

		</select>

<script type="text/javascript">
/* <![CDATA[ */
(function() {
	var dropdown = document.getElementById( "archives-dropdown-8" );
	function onSelectChange() {
		if ( dropdown.options[ dropdown.selectedIndex ].value !== '' ) {
			document.location.href = this.options[ this.selectedIndex ].value;
		}
	}
	dropdown.onchange = onSelectChange;
})();
/* ]]> */
</script>
			</div></div>

<div class='clean-grid-footer-block-2'>
</div>

<div class='clean-grid-footer-block-3'>
</div>

<div class='clean-grid-footer-block-4'>
</div>

</div>
</div><!--/#clean-grid-footer-blocks-->


<div class='clean-grid-footer clearfix' id='clean-grid-footer'>
<div class='clean-grid-foot-wrap clearfix'>
  <p class='clean-grid-copyright'>The Official GDELT Project Blog</p>
</div>
</div><!--/#clean-grid-footer -->

</div>
</div>

<script type='text/javascript' src='https://blog.gdeltproject.org/wp-content/themes/clean-grid/assets/js/jquery.fitvids.js' id='fitvids-js'></script>
<script type='text/javascript' src='https://blog.gdeltproject.org/wp-content/themes/clean-grid/assets/js/ResizeSensor.js' id='ResizeSensor-js'></script>
<script type='text/javascript' src='https://blog.gdeltproject.org/wp-content/themes/clean-grid/assets/js/theia-sticky-sidebar.js' id='theia-sticky-sidebar-js'></script>
<script type='text/javascript' id='clean-grid-customjs-js-extra'>
/* <![CDATA[ */
var clean_grid_ajax_object = {"ajaxurl":"https:\/\/blog.gdeltproject.org\/wp-admin\/admin-ajax.php","sticky_menu":"1","sticky_sidebar":"1"};
/* ]]> */
</script>
<script type='text/javascript' src='https://blog.gdeltproject.org/wp-content/themes/clean-grid/assets/js/custom.js' id='clean-grid-customjs-js'></script>
<script type='text/javascript' src='https://blog.gdeltproject.org/wp-includes/js/wp-embed.min.js?ver=5.8.2' id='wp-embed-js'></script>
</body>
</html>
<!-- Dynamic page generated in 0.049 seconds. -->
<!-- Cached page generated by WP-Super-Cache on 2021-12-03 22:34:27 -->

<!-- Compression = gzip -->
<!-- super cache -->